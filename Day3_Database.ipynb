{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/welovecherry/00-AI-Study/blob/main/Day3_Database.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWZ9UXTpFcxw"
      },
      "source": [
        " # 1교시: 데이터베이스 첫 만남: AI에서의 역할과 기본 SQL\n",
        "\n",
        "\n",
        "\n",
        " ## 🎯 1교시 수업 목표\n",
        "\n",
        "\n",
        "\n",
        " 오늘 수업을 통해 여러분은 다음을 할 수 있게 됩니다:\n",
        "\n",
        "\n",
        "\n",
        " 1.  파일 시스템과 비교하여 **데이터베이스 사용의 주요 이점** 3가지 이상 설명하기. 🤔\n",
        "\n",
        " 2.  **관계형(RDB), NoSQL, 벡터(Vector) DB**의 기본 개념과 각 DB가 **AI 서비스에서 어떤 데이터를 저장**하는 데 적합한지 예시 들기. 🗂️🧠\n",
        "\n",
        " 3.  **SQL**이 무엇인지 정의하고, 기본적인 데이터 조작 명령어(**`SELECT`, `INSERT`, `UPDATE`, `DELETE`**)의 기능을 설명하기. ⌨️\n",
        "\n",
        " 4.  **`WHERE` 절**을 사용하여 조건에 맞는 데이터를 필터링하는 **`SELECT`** 쿼리 작성 및 실행하기. ✨\n",
        "\n",
        " 5.  Python **`sqlite3`** 라이브러리를 사용하여 DB에 연결하고, 기본적인 SQL 쿼리를 실행하여 데이터를 조작(추가, 수정, 삭제, 조회)하고 **`pandas`** 로 결과 확인하기. 🐍📊\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-kOvPyeFcxy"
      },
      "source": [
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ## 📚 개념 설명 (핵심 요약)\n",
        "\n",
        "\n",
        "\n",
        " ### 1. 데이터베이스(DB): 왜 필요할까? 🤔\n",
        "\n",
        "\n",
        "\n",
        " * **정의**: 체계적으로 구조화하여 저장된 데이터의 집합. (단순 파일 저장 ❌ → **효율적 관리 시스템** 🔵)\n",
        "\n",
        " * **필요성**: 파일 시스템의 한계 (중복, 불일치, 느린 검색, 동시 접근/복구 어려움 🔴) 극복.\n",
        "\n",
        "\n",
        "\n",
        " #### 📊 파일 시스템 vs. 데이터베이스 비교 (핵심 이점)\n",
        "\n",
        "\n",
        "\n",
        " | 기능             | 파일 시스템          | 데이터베이스                      |\n",
        " | :--------------- | :------------------- | :------------------------------ |\n",
        " | **데이터 구조화** | ❌ 제한적          | ✅ **체계적** (테이블, 관계)     |\n",
        " | **검색 성능** | ❌ 느림              | ✅ **빠름** (인덱스 활용)        |\n",
        " | **동시 접근** | ❌ 충돌 위험        | ✅ **안정적** (동시성 제어)      |\n",
        " | **일관성/무결성** | ❌ 보장 어려움        | ✅ **높음** (제약조건, 트랜잭션) |\n",
        " | **확장성** | ❌ 수작업 관리        | ✅ **용이** (Scale-up/out)       |\n",
        " | **신뢰성/복구** | ❌ 복구 어려움        | ✅ **지원** (트랜잭션, 백업)     |\n",
        "\n",
        "\n",
        "\n",
        " * ➡️ **결론**: 데이터의 양, 사용자 수, 정확성, 안정성이 중요하다면 **DB 사용 필수!** 🔵"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wp_oCvvFcxy"
      },
      "source": [
        " ### 2. 데이터베이스 종류와 AI에서의 역할 🤖\n",
        "\n",
        "\n",
        "\n",
        " AI 프로젝트의 다양한 데이터 특성에 맞는 DB 선택이 중요합니다.\n",
        "\n",
        "\n",
        "\n",
        " #### 📊 주요 데이터베이스 유형별 요약\n",
        "\n",
        "\n",
        "\n",
        " | 유형             | 핵심 개념                    | 주요 특징                       | AI 활용 예시 (저장 데이터)                        | 대표 기술              |\n",
        " | :--------------- | :--------------------------- | :------------------------------ | :------------------------------------------------ | :--------------------- |\n",
        " | **관계형 (RDB)** | **표(Table)** 와 **관계** | 정형 데이터, SQL, ACID, 무결성 | 사용자 정보, 모델 메타데이터, 정형 학습 데이터       | MySQL, PostgreSQL, SQLite |\n",
        " | **NoSQL** | **관계형 외** 다양한 모델     | 유연한 스키마, 확장성, 속도     | 로그, 캐싱, 실시간 데이터, 사용자 프로필             | MongoDB, Redis, Cassandra |\n",
        " | **Vector DB** | **벡터 유사도 검색** 최적화 | 임베딩 저장, 의미 기반 검색      | **문서/이미지 임베딩 (RAG)**, 추천 정보, 검색 인덱스 | Milvus, Pinecone, FAISS |\n",
        "\n",
        "\n",
        "\n",
        " * **핵심 역할**:\n",
        "\n",
        "     * **RDB**: **구조화된 데이터**의 **정확하고 일관된** 관리. (예: 사용자 계정)\n",
        "\n",
        "     * **NoSQL**: **대규모/비정형 데이터**의 **유연하고 빠른** 처리, **확장성** 확보. (예: 서비스 로그)\n",
        "\n",
        "     * **Vector DB**: AI **임베딩 벡터**의 효율적 저장 및 **의미 기반 유사도 검색**. (예: RAG 문서 검색)\n",
        "\n",
        "\n",
        "\n",
        " ![시각 자료 삽입: RDB, NoSQL, Vector DB 개념 비교도](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FLVaIr%2FbtrGKxqb3H5%2F0PvYFKR3GjppeOg55yb2f0%2Fimg.jpg)\n",
        "\n",
        "\n",
        "\n",
        " * **AI 프로젝트 활용**:\n",
        "\n",
        "     * 학습/결과 데이터 관리, 서비스 운영 데이터 저장, 최신 AI 기술(RAG 등) 구현 기반. 🔵\n",
        "\n",
        "     * **실무 Tip**: 목적에 맞게 여러 DB **조합 사용** (Hybrid Architecture)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUsGK8LLFcxy"
      },
      "source": [
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ## ❓ 퀴즈 1: DB 필요성 및 종류별 역할\n",
        "\n",
        "\n",
        "\n",
        " ### 🧐 객관식 문제 1 (난이도: ⭐️⭐️)\n",
        "\n",
        "\n",
        "\n",
        " 파일 시스템 대신 데이터베이스를 사용하는 주요 이점으로 **가장 거리가 먼** 것을 고르세요.\n",
        "\n",
        "\n",
        "\n",
        " 1.  인덱스를 활용하여 특정 조건의 데이터를 빠르게 검색할 수 있다.\n",
        "\n",
        " 2.  여러 사용자가 동시에 데이터에 접근하여 작업할 때 데이터의 안정성을 보장한다.\n",
        "\n",
        " 3.  어떤 종류의 데이터베이스든 데이터 구조(스키마)를 매우 유연하게 변경할 수 있다.\n",
        "\n",
        " 4.  데이터의 중복을 줄이고, 일관성 및 무결성을 유지하는 데 도움이 된다.\n",
        "\n",
        " 5.  데이터 간의 관계를 정의하여 체계적으로 관리할 수 있다.\n",
        "\n",
        "\n",
        "\n",
        " ### <h3>정답 및 해설</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFD-vLDQFcxz"
      },
      "source": [
        " **정답: 3번**\n",
        "\n",
        "\n",
        "\n",
        " **해설:**\n",
        "\n",
        " 데이터 구조(스키마)의 유연성은 주로 **NoSQL** 데이터베이스의 특징입니다. 🔵 관계형 데이터베이스(RDB)는 오히려 **엄격한 스키마**를 가지며 데이터 일관성을 강조합니다. 🔴 따라서 \"어떤 종류의 데이터베이스든\" 구조 변경이 매우 유연하다는 설명은 틀렸습니다.\n",
        "\n",
        " 1, 2, 4, 5번은 데이터베이스 사용의 대표적인 이점입니다. ✨\n",
        "\n",
        "\n",
        "\n",
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ### ↔️ 매칭형 문제 2 (난이도: ⭐️⭐️⭐️)\n",
        "\n",
        "\n",
        "\n",
        " 다음 AI 관련 데이터/시나리오와 이를 저장하고 관리하기에 **가장 적합한** 데이터베이스 유형 (보기에서 선택)을 연결하세요.\n",
        "\n",
        "\n",
        "\n",
        " | 데이터 / 시나리오                                           | 가장 적합한 DB 유형 |\n",
        " | :---------------------------------------------------------- | :------------------ |\n",
        " | (A) RAG 시스템에서 문서 내용의 의미 벡터 저장 및 유사 문서 검색 | `[       ]`         |\n",
        " | (B) AI 모델 학습 실험 결과 (모델 버전, 학습률, 정확도 등 구조화된 정보) | `[       ]`         |\n",
        " | (C) 웹 서비스에서 발생하는 대규모 실시간 사용자 클릭 로그 저장      | `[       ]`         |\n",
        "\n",
        "\n",
        "\n",
        " **<보기>**\n",
        "\n",
        " (가) 관계형 데이터베이스 (RDB)\n",
        "\n",
        " (나) NoSQL 데이터베이스\n",
        "\n",
        " (다) Vector 데이터베이스\n",
        "\n",
        "\n",
        "\n",
        " ### <h3>정답 및 해설</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUzzPcu8Fcxz"
      },
      "source": [
        " **정답:**\n",
        "\n",
        " * (A) - **(다) Vector 데이터베이스**\n",
        "\n",
        " * (B) - **(가) 관계형 데이터베이스 (RDB)**\n",
        "\n",
        " * (C) - **(나) NoSQL 데이터베이스**\n",
        "\n",
        "\n",
        "\n",
        " **해설:**\n",
        "\n",
        " * (A) **의미 벡터**를 저장하고 **유사도 검색**을 하는 것은 Vector DB의 핵심 기능입니다. 🚀\n",
        "\n",
        " * (B) 모델 실험 결과처럼 **구조가 명확**하고 **관계 설정**(예: 어떤 데이터셋으로 실험했는지)이 필요할 수 있는 **정형 데이터**는 RDB가 적합합니다. 📊\n",
        "\n",
        " * (C) 대량으로 빠르게 발생하고, 때로는 형식이 일정하지 않을 수 있으며, **확장성**이 중요한 **로그 데이터**는 NoSQL(특히 Key-Value 또는 Document DB)이 유리합니다. 🌊\n",
        "\n",
        "\n",
        "\n",
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ### ✍️ 서술형 문제 3 (난이도: ⭐️⭐️⭐️)\n",
        "\n",
        "\n",
        "\n",
        " AI 기반 상품 추천 시스템을 개발한다고 가정해 봅시다. 이 시스템에서는 (1) 각 상품의 상세 정보(ID, 이름, 가격, 카테고리 등)와 (2) 사용자의 행동(클릭, 구매)을 기반으로 계산된 사용자 취향 벡터(Embedding) 데이터를 저장해야 합니다.\n",
        "\n",
        "\n",
        "\n",
        " 이 두 종류의 데이터를 저장하기 위해 각각 어떤 종류의 데이터베이스(RDB, NoSQL, Vector DB)를 사용하는 것이 적합할지 선택하고, 그 이유를 간략히 설명하세요.\n",
        "\n",
        "\n",
        "\n",
        " ### <h3>정답 및 해설</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxnLNJqjFcxz"
      },
      "source": [
        " **정답 예시:**\n",
        "\n",
        "\n",
        "\n",
        " * **(1) 상품 상세 정보:** **RDB (관계형 데이터베이스)** 가 적합합니다.\n",
        "\n",
        "     * **이유:** 상품 정보는 ID, 이름, 가격, 카테고리 등 **구조가 명확**하고 **정형화**되어 있습니다. 또한 상품 ID를 기본 키로 하여 다른 데이터(예: 주문 내역)와의 **관계**를 맺거나 데이터의 **일관성**을 유지하는 것이 중요하기 때문입니다. ✨\n",
        "\n",
        " * **(2) 사용자 취향 벡터:** **Vector DB (벡터 데이터베이스)** 가 적합합니다.\n",
        "\n",
        "     * **이유:** 사용자 취향을 나타내는 **벡터 임베딩**을 저장하고, 특정 사용자와 **유사한 취향의 다른 사용자**를 찾거나, 사용자의 취향 벡터와 **유사한 상품 벡터**를 찾는 등 **유사도 검색**을 효율적으로 수행해야 하기 때문입니다. 이는 Vector DB의 핵심 기능입니다. 🚀"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nyx5r8PUFcxz"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "# 실습에 필요한 라이브러리 import\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "\n",
        "# 이전 실습의 conn 객체가 있다면 닫아줍니다. (셀 반복 실행 시 오류 방지)\n",
        "try:\n",
        "    # 'conn' 변수가 현재 스코프에 존재하고, None이 아닌지 확인\n",
        "    if 'conn' in locals() and conn is not None:\n",
        "        try:\n",
        "            # 간단한 쿼리로 연결 상태 확인 (ProgrammingError 발생 시 이미 닫힌 것)\n",
        "            cursor = conn.cursor()\n",
        "            cursor.execute(\"SELECT 1\")\n",
        "            conn.close()\n",
        "            print(\"이전 SQLite 연결을 닫았습니다.\")\n",
        "        except sqlite3.ProgrammingError:\n",
        "            print(\"이전 SQLite 연결이 이미 닫혔거나 유효하지 않습니다.\")\n",
        "        except Exception as e: # 다른 예외 처리\n",
        "             print(f\"이전 연결 닫기 중 오류: {e}\")\n",
        "except NameError:\n",
        "    pass # conn 정의 안된 경우\n",
        "except Exception as e:\n",
        "    print(f\"이전 연결 처리 중 오류: {e}\")\n",
        "\n",
        "\n",
        "# 데이터베이스 연결 (메모리)\n",
        "conn = sqlite3.connect(':memory:')\n",
        "cursor = conn.cursor()\n",
        "print(\"SQLite 데이터베이스에 성공적으로 연결되었습니다 (in-memory).\")\n",
        "\n",
        "# 실습용 테이블 생성 (ai_models)\n",
        "cursor.execute(\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS ai_models (\n",
        "    model_id INTEGER PRIMARY KEY,\n",
        "    model_name TEXT NOT NULL,\n",
        "    task TEXT,\n",
        "    framework TEXT\n",
        ")\n",
        "\"\"\")\n",
        "print(\"`ai_models` 테이블이 준비되었습니다.\")\n",
        "\n",
        "# 실습용 초기 데이터 삽입 (테이블 비어있을 경우)\n",
        "cursor.execute(\"SELECT COUNT(*) FROM ai_models\")\n",
        "if cursor.fetchone()[0] == 0:\n",
        "    initial_models = [\n",
        "        (1, 'ResNet', 'Image Classification', 'PyTorch'),\n",
        "        (2, 'BERT', 'Natural Language Processing', 'TensorFlow'),\n",
        "        (3, 'LSTM', 'Sequence Modeling', 'PyTorch')\n",
        "    ]\n",
        "    cursor.executemany(\"INSERT INTO ai_models (model_id, model_name, task, framework) VALUES (?, ?, ?, ?)\", initial_models)\n",
        "    conn.commit() # INSERT 후 commit!\n",
        "    print(f\"{len(initial_models)}개의 초기 모델 데이터가 삽입되었습니다.\")\n",
        "else:\n",
        "    print(\"테이블에 이미 데이터가 존재하여 초기 데이터 삽입을 건너<0xEB><0x9A><0x8D>니다.\")\n",
        "\n",
        "# 초기 데이터 확인\n",
        "print(\"\\n--- 초기 ai_models 테이블 데이터 ---\")\n",
        "print(pd.read_sql(\"SELECT * FROM ai_models\", conn))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nA3U1YAyFcx0"
      },
      "source": [
        " ### 1. `SELECT`: 데이터 조회 👀\n",
        "\n",
        "\n",
        "\n",
        " 테이블에서 원하는 데이터를 가져오는 명령어입니다.\n",
        "\n",
        " * `SELECT *`: 테이블의 모든 열(*) 데이터를 가져옵니다.\n",
        "\n",
        " * `SELECT column1, column2`: 특정 열(column1, column2)의 데이터만 가져옵니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FHVD56jFcx0"
      },
      "source": [
        " #### 📜 `SELECT *` 예제 코드\n",
        "\n",
        " `ai_models` 테이블의 모든 열과 행을 조회하는 예시입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_q-vlcPFcx0"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "# 예제: 모든 데이터 조회\n",
        "example_select_all_sql = \"SELECT * FROM ai_models;\"\n",
        "try:\n",
        "    print(\"--- SELECT * 예제 실행 결과 ---\")\n",
        "    example_df = pd.read_sql(example_select_all_sql, conn)\n",
        "    print(example_df)\n",
        "except Exception as e:\n",
        "    print(f\"SELECT 예제 실행 중 오류: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6k3nuYAFcx0"
      },
      "source": [
        " #### ✨ `SELECT *` 기본 연습 ✨\n",
        "\n",
        " `ai_models` 테이블에서 **모든 데이터**를 조회하는 SQL문을 아래 셀에 직접 작성하고 실행해보세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EI837YdyFcx0"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "# TODO: ai_models 테이블의 모든 데이터를 조회하는 SELECT 쿼리를 작성하고 실행하여 결과를 확인하세요.\n",
        "# 결과는 pandas DataFrame으로 출력됩니다.\n",
        "\n",
        "# 여기에 코드를 작성하세요\n",
        "try:\n",
        "    my_select_all_sql = \"YOUR_SQL_HERE\" # 이 부분을 수정하세요!\n",
        "    # my_select_all_sql = \"SELECT * FROM ai_models;\" # 솔루션 참고\n",
        "\n",
        "    result_df = pd.read_sql(my_select_all_sql, conn)\n",
        "    print(\"--- 나의 SELECT * 실행 결과 ---\")\n",
        "    print(result_df)\n",
        "\n",
        "except Exception as e:\n",
        "    # 쿼리 실행 중 오류가 발생하면 메시지를 출력합니다.\n",
        "    # SQL 문법 오류 등이 있을 수 있습니다.\n",
        "    print(f\"쿼리 실행 중 오류 발생: {e}\")\n",
        "    # pass # 오류 발생 시 아무것도 안하고 넘어갈 수도 있습니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmtnyB5eFcx0"
      },
      "source": [
        " ### 💡 솔루션 코드 (SELECT *)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ISHJp2xFcx0"
      },
      "source": [
        " ```python\n",
        "\n",
        " # ai_models 테이블의 모든 데이터를 조회하는 SELECT 쿼리\n",
        "\n",
        " select_all_sql = \"SELECT * FROM ai_models;\"\n",
        "\n",
        "\n",
        "\n",
        " try:\n",
        "\n",
        "     print(\"--- SELECT * 결과 ---\")\n",
        "\n",
        "     all_models_df = pd.read_sql(select_all_sql, conn)\n",
        "\n",
        "     print(all_models_df)\n",
        "\n",
        " except Exception as e:\n",
        "\n",
        "     print(f\"SELECT * 실행 중 오류: {e}\")\n",
        "\n",
        " ```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "me7I2V2AFcx0"
      },
      "source": [
        " #### 📜 `SELECT 특정 열` 예제 코드\n",
        "\n",
        " `ai_models` 테이블에서 `model_id`가 2인 모델의 `model_name`만 선택하여 조회하는 예시입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6d1Y0qVFcx0"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "# 예제: 특정 열(model_name) 및 특정 행(model_id=2) 조회\n",
        "example_select_col_sql = \"SELECT model_name FROM ai_models WHERE model_id = 2;\"\n",
        "try:\n",
        "    print(\"--- SELECT 특정 열 예제 실행 결과 ---\")\n",
        "    example_df = pd.read_sql(example_select_col_sql, conn)\n",
        "    print(example_df)\n",
        "except Exception as e:\n",
        "    print(f\"SELECT 특정 열 예제 실행 중 오류: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYCIbA3iFcx0"
      },
      "source": [
        " #### ✨ `SELECT 특정 열` 연습 ✨\n",
        "\n",
        " `ai_models` 테이블에서 모든 모델의 **모델 이름(`model_name`)과 작업(`task`)** 만 조회하는 SQL문을 아래 셀에 직접 작성하고 실행해보세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uqwE9FIrFcx0"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "# TODO: ai_models 테이블에서 model_name과 task 열만 조회하는 SELECT 쿼리를 작성하고 실행하세요.\n",
        "\n",
        "# 여기에 코드를 작성하세요\n",
        "try:\n",
        "    my_select_cols_sql = \"YOUR_SQL_HERE\" # 이 부분을 수정하세요!\n",
        "    # my_select_cols_sql = \"SELECT model_name, task FROM ai_models;\" # 솔루션 참고\n",
        "\n",
        "    result_df = pd.read_sql(my_select_cols_sql, conn)\n",
        "    print(\"--- 나의 SELECT 특정 열 실행 결과 ---\")\n",
        "    print(result_df)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"쿼리 실행 중 오류 발생: {e}\")\n",
        "    # pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwDFazKPFcx0"
      },
      "source": [
        " ### 💡 솔루션 코드 (SELECT 특정 열)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAn22h_sFcx0"
      },
      "source": [
        " ```python\n",
        "\n",
        " # ai_models 테이블에서 model_name과 task 열만 조회\n",
        "\n",
        " select_cols_sql = \"SELECT model_name, task FROM ai_models;\"\n",
        "\n",
        "\n",
        "\n",
        " try:\n",
        "\n",
        "     print(\"\\n--- SELECT model_name, task 결과 ---\")\n",
        "\n",
        "     specific_cols_df = pd.read_sql(select_cols_sql, conn)\n",
        "\n",
        "     print(specific_cols_df)\n",
        "\n",
        " except Exception as e:\n",
        "\n",
        "     print(f\"SELECT 특정 열 실행 중 오류: {e}\")\n",
        "\n",
        " ```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIO_QPfpFcx0"
      },
      "source": [
        " ### 2. `INSERT`: 데이터 추가 ➕\n",
        "\n",
        "\n",
        "\n",
        " 테이블에 새로운 데이터 행(Row)을 추가합니다.\n",
        "\n",
        " * `INSERT INTO table_name (column1, column2, ...) VALUES (value1, value2, ...);`\n",
        "\n",
        " * **주의**: 데이터 변경 후에는 `conn.commit()`을 호출하여 변경 사항을 DB에 최종 반영해야 합니다. ✨"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CU0UA4V-Fcx0"
      },
      "source": [
        " #### 📜 `INSERT` 예제 코드\n",
        "\n",
        " `ai_models` 테이블에 `model_id`=5, `model_name`='Transformer', `task`='Machine Translation', `framework`='PyTorch' 인 데이터를 추가하는 예시입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZhNTfYkSFcx0"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "# 예제: 새로운 데이터 삽입\n",
        "example_insert_sql = \"\"\"\n",
        "INSERT INTO ai_models (model_id, model_name, task, framework)\n",
        "VALUES (5, 'Transformer', 'Machine Translation', 'PyTorch');\n",
        "\"\"\"\n",
        "try:\n",
        "    print(\"--- INSERT 예제 실행 전 데이터 ---\")\n",
        "    print(pd.read_sql(\"SELECT * FROM ai_models WHERE model_id=5\", conn)) # 아직 데이터 없음\n",
        "\n",
        "    cursor.execute(example_insert_sql)\n",
        "    conn.commit() # <<<< COMMIT!\n",
        "    print(\"\\n--- INSERT 예제 실행 성공 ---\")\n",
        "\n",
        "    print(\"\\n--- INSERT 예제 실행 후 데이터 (model_id=5) ---\")\n",
        "    print(pd.read_sql(\"SELECT * FROM ai_models WHERE model_id=5\", conn)) # 추가된 데이터 확인\n",
        "\n",
        "except sqlite3.IntegrityError:\n",
        "    print(\"\\n오류: model_id=5 데이터가 이미 존재합니다. (예제 반복 실행 시)\")\n",
        "    conn.rollback() # 오류 시 롤백\n",
        "except Exception as e:\n",
        "    print(f\"INSERT 예제 실행 중 오류: {e}\")\n",
        "    conn.rollback()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DX-HyjznFcx1"
      },
      "source": [
        " #### ✨ `INSERT` 연습 ✨\n",
        "\n",
        " `ai_models` 테이블에 `model_id`: 4, `model_name`: 'GPT-3', `task`: 'Natural Language Processing', `framework`: 'OpenAI' 인 데이터를 **추가**하는 SQL문을 아래 셀에 직접 작성하고 실행해보세요. 실행 후 `SELECT *` 쿼리로 전체 테이블을 조회하여 확인하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uf_9rqfkFcx1"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "# TODO: model_id=4, 'GPT-3', 'NLP', 'OpenAI' 데이터를 추가하는 INSERT 쿼리 작성/실행\n",
        "#       실행 후 SELECT * FROM ai_models; 로 전체 테이블 확인\n",
        "\n",
        "# 여기에 INSERT 쿼리를 작성하세요\n",
        "try:\n",
        "    my_insert_sql = \"\"\"\n",
        "    YOUR_SQL_HERE\n",
        "    \"\"\"\n",
        "\n",
        "    cursor.execute(my_insert_sql)\n",
        "    conn.commit() # <<<< COMMIT!\n",
        "    print(\"--- 나의 INSERT 실행 성공 ---\")\n",
        "\n",
        "    # 결과 확인\n",
        "    print(\"\\n--- INSERT 작업 후 전체 테이블 ---\")\n",
        "    print(pd.read_sql(\"SELECT * FROM ai_models\", conn))\n",
        "\n",
        "except sqlite3.IntegrityError:\n",
        "     print(f\"\\nINSERT 실행 중 오류: 이미 해당 ID(4)가 존재할 수 있습니다.\")\n",
        "     conn.rollback()\n",
        "except Exception as e:\n",
        "    print(f\"쿼리 실행 중 오류 발생: {e}\")\n",
        "    conn.rollback()\n",
        "    # pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oxyoPEYFcx1"
      },
      "source": [
        " ### 💡 솔루션 코드 (INSERT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCl2KwshFcx1"
      },
      "source": [
        " ```python\n",
        "\n",
        " # model_id=4, 'GPT-3', 'NLP', 'OpenAI' 데이터 추가\n",
        "\n",
        "\n",
        "\n",
        " try:\n",
        "\n",
        "     cursor.execute(insert_sql)\n",
        "\n",
        "     conn.commit()\n",
        "\n",
        "     print(\"\\nINSERT 작업 성공!\")\n",
        "\n",
        "\n",
        "\n",
        "     print(\"\\n--- INSERT 실행 후 데이터 ---\")\n",
        "\n",
        "     print(pd.read_sql(\"SELECT * FROM ai_models\", conn))\n",
        "\n",
        "\n",
        "\n",
        " except sqlite3.IntegrityError as ie:\n",
        "\n",
        "      print(f\"\\nINSERT 실행 중 오류: {ie}. 이미 해당 ID가 존재할 수 있습니다.\")\n",
        "\n",
        "      conn.rollback()\n",
        "\n",
        " except Exception as e:\n",
        "\n",
        "     print(f\"INSERT 실행 중 오류: {e}\")\n",
        "\n",
        "     conn.rollback()\n",
        "\n",
        " ```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLZuI0PmFcx1"
      },
      "source": [
        " ### 3. `UPDATE`: 데이터 수정 ✏️\n",
        "\n",
        "\n",
        "\n",
        " 테이블에 있는 기존 데이터 행의 값을 변경합니다.\n",
        "\n",
        " * `UPDATE table_name SET column1 = new_value1 WHERE condition;`\n",
        "\n",
        " * **주의**: `WHERE` 절로 변경 대상을 명확히 지정하지 않으면 큰일 날 수 있습니다! ⚠️🔴\n",
        "\n",
        " * **주의**: 데이터 변경 후에는 `conn.commit()`을 호출해야 합니다. ✨"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nZiVxmSFcx1"
      },
      "source": [
        " #### 📜 `UPDATE` 예제 코드\n",
        "\n",
        " `model_id`가 2인 모델('BERT')의 `task`를 'Language Modeling'으로 변경하는 예시입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_6VMFgUFcx1"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "# 예제: 데이터 수정\n",
        "example_update_sql = \"\"\"\n",
        "UPDATE ai_models\n",
        "SET task = 'Language Modeling'\n",
        "WHERE model_id = 2;\n",
        "\"\"\"\n",
        "try:\n",
        "    print(\"--- UPDATE 예제 실행 전 데이터 (model_id=2) ---\")\n",
        "    print(pd.read_sql(\"SELECT * FROM ai_models WHERE model_id=2\", conn))\n",
        "\n",
        "    rows_affected = cursor.execute(example_update_sql).rowcount\n",
        "    conn.commit() # <<<< COMMIT!\n",
        "    print(f\"\\n--- UPDATE 예제 실행 성공 ({rows_affected}개 행 변경) ---\")\n",
        "\n",
        "    print(\"\\n--- UPDATE 예제 실행 후 데이터 (model_id=2) ---\")\n",
        "    print(pd.read_sql(\"SELECT * FROM ai_models WHERE model_id=2\", conn)) # 변경 결과 확인\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"UPDATE 예제 실행 중 오류: {e}\")\n",
        "    conn.rollback()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kX5Keq7oFcx1"
      },
      "source": [
        " #### ✨ `UPDATE` 연습 ✨\n",
        "\n",
        " `model_id`가 3인 모델('LSTM')의 `framework`를 'TensorFlow'로 **수정**하는 SQL문을 아래 셀에 직접 작성하고 실행해보세요. 실행 후 `model_id`=3인 행을 조회하여 확인하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJlIVgDJFcx1"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "# TODO: model_id=3 모델의 framework를 'TensorFlow'로 변경하는 UPDATE 쿼리 작성/실행\n",
        "#       실행 후 SELECT * FROM ai_models WHERE model_id = 3; 로 확인\n",
        "\n",
        "# 여기에 UPDATE 쿼리를 작성하세요\n",
        "try:\n",
        "    my_update_sql = \"\"\"\n",
        "    YOUR_SQL_HERE\n",
        "    \"\"\"\n",
        "\n",
        "    rows_affected = cursor.execute(my_update_sql).rowcount\n",
        "    conn.commit() # <<<< COMMIT!\n",
        "    print(f\"--- 나의 UPDATE 실행 성공 ({rows_affected}개 행 변경) ---\")\n",
        "\n",
        "    # 결과 확인\n",
        "    print(\"\\n--- UPDATE 작업 후 데이터 (model_id=3) ---\")\n",
        "    print(pd.read_sql(\"SELECT * FROM ai_models WHERE model_id = 3\", conn))\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"쿼리 실행 중 오류 발생: {e}\")\n",
        "    conn.rollback()\n",
        "    # pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRcLj9taFcx1"
      },
      "source": [
        " ### 💡 솔루션 코드 (UPDATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASg2khMhFcx1"
      },
      "source": [
        " ```python\n",
        "\n",
        " # model_id=3 모델의 framework를 'TensorFlow'로 변경\n",
        "\n",
        " try:\n",
        "\n",
        "     rows_affected = cursor.execute(update_sql).rowcount\n",
        "\n",
        "     conn.commit()\n",
        "\n",
        "     print(f\"\\nUPDATE 작업 성공! ({rows_affected}개 행 변경)\")\n",
        "\n",
        "\n",
        "\n",
        "     print(\"\\n--- UPDATE 실행 후 데이터 (model_id=3) ---\")\n",
        "\n",
        "     print(pd.read_sql(\"SELECT * FROM ai_models WHERE model_id = 3\", conn))\n",
        "\n",
        "\n",
        "\n",
        " except Exception as e:\n",
        "\n",
        "     print(f\"UPDATE 실행 중 오류: {e}\")\n",
        "\n",
        "     conn.rollback()\n",
        "\n",
        " ```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAmd5nvQFcx1"
      },
      "source": [
        " ### 4. `DELETE`: 데이터 삭제 🗑️\n",
        "\n",
        "\n",
        "\n",
        " 테이블에서 특정 데이터 행을 삭제합니다.\n",
        "\n",
        " * `DELETE FROM table_name WHERE condition;`\n",
        "\n",
        " * **주의**: `WHERE` 절로 삭제 대상을 명확히 지정하지 않으면 큰일 날 수 있습니다! ⚠️🔴\n",
        "\n",
        " * **주의**: 데이터 변경 후에는 `conn.commit()`을 호출해야 합니다. ✨"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0qfWF4aFcx2"
      },
      "source": [
        " #### 📜 `DELETE` 예제 코드\n",
        "\n",
        " `model_id`가 5인 모델('Transformer') 데이터를 삭제하는 예시입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ie4q7V4qFcx2"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "# 예제: 데이터 삭제\n",
        "# 먼저 삭제할 데이터가 있는지 확인 (이전 예제에서 추가됨)\n",
        "print(\"--- DELETE 예제 실행 전 데이터 (model_id=5) ---\")\n",
        "print(pd.read_sql(\"SELECT * FROM ai_models WHERE model_id=5\", conn))\n",
        "\n",
        "example_delete_sql = \"DELETE FROM ai_models WHERE model_id = 5;\"\n",
        "try:\n",
        "    rows_affected = cursor.execute(example_delete_sql).rowcount\n",
        "    conn.commit() # <<<< COMMIT!\n",
        "    print(f\"\\n--- DELETE 예제 실행 성공 ({rows_affected}개 행 삭제) ---\")\n",
        "\n",
        "    print(\"\\n--- DELETE 예제 실행 후 데이터 (model_id=5) ---\")\n",
        "    print(pd.read_sql(\"SELECT * FROM ai_models WHERE model_id=5\", conn)) # 삭제되었는지 확인 (결과 없음)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"DELETE 예제 실행 중 오류: {e}\")\n",
        "    conn.rollback()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-NWFfW6Fcx2"
      },
      "source": [
        " #### ✨ `DELETE` 연습 ✨\n",
        "\n",
        " `model_id`가 1인 모델('ResNet') 데이터를 **삭제**하는 SQL문을 아래 셀에 직접 작성하고 실행해보세요. 실행 후 전체 테이블을 조회하여 확인하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X5M1oRW4Fcx2"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "# TODO: model_id=1 모델 데이터를 삭제하는 DELETE 쿼리 작성/실행\n",
        "#       실행 후 SELECT * FROM ai_models; 로 전체 테이블 확인\n",
        "\n",
        "# 여기에 DELETE 쿼리를 작성하세요\n",
        "try:\n",
        "    my_delete_sql = \"\"\"\n",
        "    YOUR_SQL_HERE\n",
        "    \"\"\"\n",
        "\n",
        "    rows_affected = cursor.execute(my_delete_sql).rowcount\n",
        "    conn.commit() # <<<< COMMIT!\n",
        "    print(f\"--- 나의 DELETE 실행 성공 ({rows_affected}개 행 삭제) ---\")\n",
        "\n",
        "    # 결과 확인\n",
        "    print(\"\\n--- DELETE 작업 후 전체 테이블 ---\")\n",
        "    print(pd.read_sql(\"SELECT * FROM ai_models\", conn))\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"쿼리 실행 중 오류 발생: {e}\")\n",
        "    conn.rollback()\n",
        "    # pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYlzzwOUFcx3"
      },
      "source": [
        " ### 💡 솔루션 코드 (DELETE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iqV45iTFcx3"
      },
      "source": [
        " ```python\n",
        "\n",
        " # model_id=1 모델 데이터 삭제\n",
        "\n",
        " try:\n",
        "\n",
        "     rows_affected = cursor.execute(delete_sql).rowcount\n",
        "\n",
        "     conn.commit()\n",
        "\n",
        "     print(f\"\\nDELETE 작업 성공! ({rows_affected}개 행 삭제)\")\n",
        "\n",
        "\n",
        "\n",
        "     print(\"\\n--- DELETE 실행 후 데이터 ---\")\n",
        "\n",
        "     print(pd.read_sql(\"SELECT * FROM ai_models\", conn))\n",
        "\n",
        "\n",
        "\n",
        " except Exception as e:\n",
        "\n",
        "     print(f\"DELETE 실행 중 오류: {e}\")\n",
        "\n",
        "     conn.rollback()\n",
        "\n",
        " ```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1ldGf9TFcx3"
      },
      "source": [
        " ### 5. `WHERE` 절: 조건 필터링 🔍\n",
        "\n",
        "\n",
        "\n",
        " `SELECT`, `UPDATE`, `DELETE` 구문에서 처리할 데이터를 특정 **조건**으로 제한합니다.\n",
        "\n",
        " * 비교 연산자 (`=`, `>`, `<`, `>=`, `<=`, `!=`), 논리 연산자 (`AND`, `OR`, `NOT`) 사용."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuJP8qZYFcx3"
      },
      "source": [
        " #### 📜 `WHERE` 예제 코드\n",
        "\n",
        " `framework`가 'PyTorch'인 모델들의 `model_name`과 `task`를 조회하는 예시입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xv1GNQZGFcx3"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "# 예제: WHERE 절 사용\n",
        "example_where_sql = \"\"\"\n",
        "SELECT model_name, task\n",
        "FROM ai_models\n",
        "WHERE framework = 'PyTorch';\n",
        "\"\"\"\n",
        "try:\n",
        "    print(\"--- WHERE 예제 실행 결과 ---\")\n",
        "    example_df = pd.read_sql(example_where_sql, conn)\n",
        "    print(example_df)\n",
        "except Exception as e:\n",
        "    print(f\"WHERE 예제 실행 중 오류: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLBo9hzzFcx3"
      },
      "source": [
        " #### ✨ `WHERE` 연습 ✨\n",
        "\n",
        " `task`가 'Natural Language Processing'인 모델들의 `model_name`과 `framework`를 조회하는 SQL문을 아래 셀에 직접 작성하고 실행해보세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cxiZpS4uFcx3"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "# TODO: task='Natural Language Processing'인 모델의 model_name, framework 조회 (SELECT...WHERE)\n",
        "\n",
        "# 여기에 코드를 작성하세요\n",
        "try:\n",
        "    my_where_sql = \"\"\"\n",
        "    YOUR_SQL_HERE\n",
        "    \"\"\"\n",
        "\n",
        "    result_df = pd.read_sql(my_where_sql, conn)\n",
        "    print(\"--- 나의 WHERE 실행 결과 ---\")\n",
        "    print(result_df)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"쿼리 실행 중 오류 발생: {e}\")\n",
        "    # pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pay07zCbFcx3"
      },
      "source": [
        " ### 💡 솔루션 코드 (WHERE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEBk6EWpFcx3"
      },
      "source": [
        " ```python\n",
        "\n",
        " # task가 'Natural Language Processing'인 모델의 model_name, framework 조회\n",
        "\n",
        " try:\n",
        "\n",
        "     print(\"\\n--- WHERE 연습 결과 ---\")\n",
        "\n",
        "     where_df = pd.read_sql(select_where_sql, conn)\n",
        "\n",
        "     print(where_df)\n",
        "\n",
        " except Exception as e:\n",
        "\n",
        "     print(f\"WHERE 연습 실행 중 오류: {e}\")\n",
        "\n",
        " ```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZR3cnzEaFcx3"
      },
      "source": [
        " #### ✨ `WHERE` + `AND` 연습 ✨\n",
        "\n",
        " `task`가 'Natural Language Processing' **이면서(AND)** `framework`가 'TensorFlow' 인 모델의 `model_name` 만 조회하는 SQL문을 아래 셀에 직접 작성하고 실행해보세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNSbRPecFcx3"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "# TODO: task='NLP' AND framework='TensorFlow'인 모델의 model_name 조회 (SELECT...WHERE...AND)\n",
        "\n",
        "# 여기에 코드를 작성하세요\n",
        "try:\n",
        "    my_where_and_sql = \"\"\"\n",
        "    YOUR_SQL_HERE\n",
        "    \"\"\"\n",
        "\n",
        "    result_df = pd.read_sql(my_where_and_sql, conn)\n",
        "    print(\"--- 나의 WHERE + AND 실행 결과 ---\")\n",
        "    print(result_df)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"쿼리 실행 중 오류 발생: {e}\")\n",
        "    # pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhiIrMkNFcx3"
      },
      "source": [
        " ### 💡 솔루션 코드 (WHERE + AND)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NY7SIQjfFcx4"
      },
      "source": [
        " ```python\n",
        "\n",
        " # task='NLP' AND framework='TensorFlow'인 모델의 model_name 조회\n",
        "\n",
        " try:\n",
        "\n",
        "     print(\"\\n--- WHERE + AND 연습 결과 ---\")\n",
        "\n",
        "     where_and_df = pd.read_sql(select_where_and_sql, conn)\n",
        "\n",
        "     print(where_and_df)\n",
        "\n",
        " except Exception as e:\n",
        "\n",
        "     print(f\"WHERE + AND 연습 실행 중 오류: {e}\")\n",
        "\n",
        " ```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z142NkHeFcx4"
      },
      "source": [
        " ### 6. `COUNT()` 함수: 개수 세기 🔢\n",
        "\n",
        "\n",
        "\n",
        " 조건 만족 행의 **개수**를 계산합니다 (`COUNT(*)`).\n",
        "\n",
        " * `SELECT COUNT(*) AS alias FROM table WHERE condition;` (`AS`로 별칭 지정)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbPBx9fzFcx4"
      },
      "source": [
        " #### 📜 `COUNT` 예제 코드\n",
        "\n",
        " `ai_models` 테이블에 있는 전체 모델의 개수를 세는 예시입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zcaPrQDTFcx4"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "# 예제: 전체 행 개수 세기\n",
        "example_count_sql = \"SELECT COUNT(*) AS total_models FROM ai_models;\"\n",
        "try:\n",
        "    print(\"--- COUNT 예제 실행 결과 ---\")\n",
        "    example_df = pd.read_sql(example_count_sql, conn)\n",
        "    print(example_df)\n",
        "except Exception as e:\n",
        "    print(f\"COUNT 예제 실행 중 오류: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayRdiTl1Fcx4"
      },
      "source": [
        " #### ✨ `COUNT` 연습 ✨\n",
        "\n",
        " `framework`가 'TensorFlow'인 모델이 **몇 개**인지 세어 보세요. 결과 컬럼 이름은 `tf_count`로 지정하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SpcyFjWiFcx4"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "# TODO: framework='TensorFlow' 모델 개수 세기 (SELECT COUNT...WHERE, AS tf_count)\n",
        "\n",
        "# 여기에 코드를 작성하세요\n",
        "try:\n",
        "    my_count_sql = \"\"\"\n",
        "    YOUR_SQL_HERE\n",
        "    \"\"\"\n",
        "\n",
        "    result_df = pd.read_sql(my_count_sql, conn)\n",
        "    print(\"--- 나의 COUNT 실행 결과 ---\")\n",
        "    print(result_df)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"쿼리 실행 중 오류 발생: {e}\")\n",
        "    # pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxhT0ZejFcx4"
      },
      "source": [
        " ### 💡 솔루션 코드 (COUNT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3bNoyjcFcx4"
      },
      "source": [
        " ```python\n",
        "\n",
        " # framework가 'TensorFlow'인 모델 개수 세기 (AS tf_count 사용)\n",
        "\n",
        " try:\n",
        "\n",
        "     print(\"\\n--- COUNT 연습 결과 ---\")\n",
        "\n",
        "     count_df = pd.read_sql(count_sql, conn)\n",
        "\n",
        "     print(count_df)\n",
        "\n",
        " except Exception as e:\n",
        "\n",
        "     print(f\"COUNT 연습 실행 중 오류: {e}\")\n",
        "\n",
        " ```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiVNWoLRFcx4"
      },
      "source": [
        " ### 7. `LIMIT` 절: 결과 수 제한 ✋\n",
        "\n",
        "\n",
        "\n",
        " `SELECT` 조회 결과의 **개수**를 제한합니다 (상위 N개).\n",
        "\n",
        " * `SELECT ... FROM ... WHERE ... LIMIT N;`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaLo4nYaFcx4"
      },
      "source": [
        " #### 📜 `LIMIT` 예제 코드\n",
        "\n",
        " `ai_models` 테이블의 모든 데이터를 조회하되, **처음 1개**의 행만 가져오는 예시입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VfmxxarAFcx4"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "# 예제: 결과 개수 제한\n",
        "example_limit_sql = \"SELECT * FROM ai_models LIMIT 1;\"\n",
        "try:\n",
        "    print(\"--- LIMIT 예제 실행 결과 ---\")\n",
        "    example_df = pd.read_sql(example_limit_sql, conn)\n",
        "    print(example_df)\n",
        "except Exception as e:\n",
        "    print(f\"LIMIT 예제 실행 중 오류: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlLpzzNIFcx4"
      },
      "source": [
        " #### ✨ `LIMIT` 연습 ✨\n",
        "\n",
        " `ai_models` 테이블의 데이터 중 **처음 2개**의 행만 조회하는 SQL문을 아래 셀에 직접 작성하고 실행해보세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ss_efqbgFcx4"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "# TODO: ai_models 테이블 처음 2개 행 조회 (SELECT...LIMIT)\n",
        "\n",
        "# 여기에 코드를 작성하세요\n",
        "try:\n",
        "    my_limit_sql = \"\"\"\n",
        "    YOUR_SQL_HERE\n",
        "    \"\"\"\n",
        "    result_df = pd.read_sql(my_limit_sql, conn)\n",
        "    print(\"--- 나의 LIMIT 실행 결과 ---\")\n",
        "    print(result_df)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"쿼리 실행 중 오류 발생: {e}\")\n",
        "    # pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWMdGbqIFcx4"
      },
      "source": [
        " ### 💡 솔루션 코드 (LIMIT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACvaAotaFcx4"
      },
      "source": [
        " ```python\n",
        "\n",
        " # ai_models 테이블에서 처음 2개의 행만 조회\n",
        "\n",
        " try:\n",
        "\n",
        "     print(\"\\n--- LIMIT 연습 결과 ---\")\n",
        "\n",
        "     limit_df = pd.read_sql(limit_sql, conn)\n",
        "\n",
        "     print(limit_df)\n",
        "\n",
        " except Exception as e:\n",
        "\n",
        "     print(f\"LIMIT 연습 실행 중 오류: {e}\")\n",
        "\n",
        " ```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXFGXEk3Fcx4"
      },
      "source": [
        " ### 📊 기본 SQL 명령어 (DML + α) 요약표\n",
        "\n",
        "\n",
        "\n",
        " | 명령어        | 주요 기능                       | 기본 사용법 (예시)                                       | 비고                   |\n",
        " | :------------ | :------------------------------ | :------------------------------------------------------- | :--------------------- |\n",
        " | `SELECT`      | 데이터 **조회** | `SELECT col1, col2 FROM tbl;`                            | 가장 기본, 중요        |\n",
        " | `INSERT`      | 데이터 **추가** | `INSERT INTO tbl (col1) VALUES (val1);`                  | `commit()` 필요       |\n",
        " | `UPDATE`      | 데이터 **수정** | `UPDATE tbl SET col1 = val1 WHERE condition;`            | `WHERE`, `commit()` 중요 |\n",
        " | `DELETE`      | 데이터 **삭제** | `DELETE FROM tbl WHERE condition;`                       | `WHERE`, `commit()` 중요 |\n",
        " | `WHERE`       | 조회/수정/삭제 **조건 지정** | `... WHERE col1 > 10 AND col2 = 'val';`                  | 필터링 핵심          |\n",
        " | `COUNT()`     | 조건 만족 행 **개수 계산** | `SELECT COUNT(*) AS cnt FROM tbl WHERE condition;`       | 집계 함수 기초       |\n",
        " | `LIMIT`       | 조회 결과 **개수 제한** | `SELECT * FROM tbl LIMIT N;`                             | 미리보기 등 활용       |\n",
        " | `CREATE TABLE`| 새로운 **테이블 생성** (DDL)    | `CREATE TABLE tbl (col1 type, col2 type);`               | 데이터 구조 정의     |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QoNP5dyFcx4"
      },
      "source": [
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ## ❓ 퀴즈 2: 기본 SQL 명령어 기능\n",
        "\n",
        "\n",
        "\n",
        " ### 🧐 객관식 문제 2 (난이도: ⭐️⭐️)\n",
        "\n",
        "\n",
        "\n",
        " 다음 SQL 명령어와 그 기능이 **잘못** 짝지어진 것은 무엇인가요?\n",
        "\n",
        "\n",
        "\n",
        " 1.  `SELECT` - 테이블에서 데이터를 조회한다.\n",
        "\n",
        " 2.  `INSERT` - 테이블에 새로운 데이터를 추가한다.\n",
        "\n",
        " 3.  `WHERE` - 조회할 테이블을 지정한다.\n",
        "\n",
        " 4.  `UPDATE` - 테이블의 기존 데이터를 수정한다.\n",
        "\n",
        " 5.  `DELETE` - 테이블에서 데이터를 삭제한다.\n",
        "\n",
        "\n",
        "\n",
        " ### <h3>정답 및 해설</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pw-xOuP5Fcx4"
      },
      "source": [
        " **정답: 3번**\n",
        "\n",
        "\n",
        "\n",
        " **해설:**\n",
        "\n",
        " `WHERE` 절은 `SELECT`, `UPDATE`, `DELETE` 구문에서 처리할 행의 **조건**을 지정하는 데 사용됩니다.\n",
        "\n",
        " 조회할 테이블을 지정하는 것은 `SELECT` 구문의 `FROM` 절입니다.\n",
        "\n",
        " 나머지 명령어와 기능 설명은 올바르게 짝지어져 있습니다.\n",
        "\n",
        "\n",
        "\n",
        " ### 🚀 더 나아가기 (생각해보기)\n",
        "\n",
        "\n",
        "\n",
        " * `UPDATE` 나 `DELETE` 문에서 `WHERE` 절을 실수로 빠뜨리면 어떤 일이 발생할까요?\n",
        "\n",
        "   실제 운영 환경에서 이런 실수를 방지하기 위한 방법에는 무엇이 있을까요?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikeDGwW6Fcx4"
      },
      "source": [
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ## ❓ F.A.Q (자주 묻는 질문)\n",
        "\n",
        "\n",
        "\n",
        " * **Q1: RDB vs NoSQL, 언제 뭘 써야 할지 헷갈려요.**\n",
        "\n",
        "     * **A1**: **데이터 구조와 요구사항**이 핵심입니다.\n",
        "\n",
        "         * **구조 명확, 관계/일관성 중요? → RDB** 🔵 (예: 사용자 계정, 거래 내역)\n",
        "\n",
        "         * **구조 유연, 대량 데이터, 확장성/속도 중요? → NoSQL** 🔵 (예: 로그, 실시간 채팅, 캐시)\n",
        "\n",
        "         * 절대적인 우위는 없고, **상황에 맞는 선택**이 중요합니다. (Trade-off 존재)\n",
        "\n",
        "\n",
        "\n",
        " * **Q2: SQL은 RDB 전용인가요?**\n",
        "\n",
        "     * **A2**: **주로 RDB**에서 표준으로 쓰지만, 일부 NoSQL이나 빅데이터 시스템(Spark SQL 등)도 **SQL 또는 유사 구문**을 지원합니다. 🔵 데이터 처리의 사실상 표준 언어입니다.\n",
        "\n",
        "\n",
        "\n",
        " * **Q3: Vector DB는 꼭 써야 하나요?**\n",
        "\n",
        "     * **A3**: **의미 기반 검색/추천**이 필요하다면 강력 추천합니다. 🔵 하지만 일반적인 데이터 관리는 RDB/NoSQL로도 충분합니다. Vector DB는 기존 DB를 **보완**하는 역할입니다.\n",
        "\n",
        "\n",
        "\n",
        " * **Q4: `commit()` 꼭 해야 하나요?**\n",
        "\n",
        "     * **A4**: **네, `INSERT`, `UPDATE`, `DELETE` 후에는 필수입니다.** ✨ `commit()` 없이는 변경 사항이 DB에 **영구 저장되지 않고** 사라질 수 있습니다. 🔴 데이터 변경 작업을 최종 확정하는 중요한 명령입니다.\n",
        "\n",
        "\n",
        "\n",
        " * **Q5: SQL에서 '같다'는 `=` 인가요, `==` 인가요?**\n",
        "\n",
        "     * **A5**: SQL에서는 **`=`** 입니다. 🔵 (Python 등 프로그래밍 언어는 `==`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUuMXIHNFcx4"
      },
      "source": [
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ## 🔑 1교시 핵심 정리\n",
        "\n",
        "\n",
        "\n",
        " * **DB 필요성**: 파일 한계 극복 (체계적 관리, 빠른 검색, 동시성 제어, 신뢰성, 확장성). AI 필수 기반. 🔵\n",
        "\n",
        " * **DB 유형**:\n",
        "\n",
        "     * **RDB**: 구조화 데이터, 관계/일관성 중시. (SQL 사용)\n",
        "\n",
        "     * **NoSQL**: 유연한 구조, 확장성/속도 중시.\n",
        "\n",
        "     * **Vector DB**: AI 임베딩, 의미 기반 유사도 검색 특화.\n",
        "\n",
        " * **SQL 기초 (DML)**: DB 소통 언어.\n",
        "\n",
        "     * `SELECT`: 조회 👀\n",
        "\n",
        "     * `INSERT`: 추가 ➕ (`commit` 필요)\n",
        "\n",
        "     * `UPDATE`: 수정 ✏️ (`WHERE`, `commit` 중요!)\n",
        "\n",
        "     * `DELETE`: 삭제 🗑️ (`WHERE`, `commit` 중요!)\n",
        "\n",
        " * **쿼리 정제**: `WHERE`(조건🔍), `COUNT()`(개수🔢), `LIMIT`(개수 제한✋).\n",
        "\n",
        " * **실습 도구**: `sqlite3`, `pandas`. 🐍📊 (`commit()` 잊지 말기!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdHlwSTqFcx5"
      },
      "source": [
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ## 💭 1교시 마무리\n",
        "\n",
        "\n",
        "\n",
        " 이번 시간에는 데이터베이스의 기본 개념과 AI 분야에서의 중요성, 주요 DB 종류를 **핵심 위주로 비교하고 정리**했습니다. SQL 기본 명령어(`SELECT`, `INSERT`, `UPDATE`, `DELETE`, `WHERE`, `COUNT`, `LIMIT`) 사용법을 배우고 **간단한 실습**으로 익혔습니다. **FAQ**를 통해 궁금증을 해소하고 **핵심 내용을 요약**하며 마무리했습니다.\n",
        "\n",
        "\n",
        "\n",
        " AI 개발에서 DB 활용 능력은 필수입니다. 오늘 배운 기초가 다음 학습의 든든한 발판이 되길 바랍니다.\n",
        "\n",
        "\n",
        "\n",
        " **다음 2교시에는 관계형 데이터베이스(RDB)의 테이블 설계, 키(Key), 정규화 기초에 대해 더 깊이 알아보겠습니다.**\n",
        "\n",
        "\n",
        "\n",
        " ### 🚀 더 나아가기 (1교시 복습)\n",
        "\n",
        "\n",
        "\n",
        " * 오늘 만든 `ai_models` 테이블에 `creation_date` (모델 생성일, TEXT 타입) 컬럼을 추가하는 `ALTER TABLE` 명령어를 검색해보고 실행해 보세요. (DDL 맛보기!)\n",
        "\n",
        " * `ai_models` 테이블에서 `framework`가 'PyTorch' **이거나(OR)** 'TensorFlow'인 모델들을 조회하는 `SELECT` 쿼리를 작성해보세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NphzsFfmFcx5"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "# 실습 종료 후 데이터베이스 연결 해제\n",
        "try:\n",
        "    if 'conn' in locals() and conn:\n",
        "        conn.close()\n",
        "        print(\"\\nSQLite 데이터베이스 연결이 해제되었습니다.\")\n",
        "except Exception as e:\n",
        "     print(f\"연결 해제 중 오류: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiCUfw0wFcx5"
      },
      "source": [
        " # 2교시: 관계형 DB 설계 기초 - 테이블, 키, 정규화\n",
        "\n",
        "\n",
        "\n",
        " ## 🎯 2교시 수업 목표\n",
        "\n",
        "\n",
        "\n",
        " 오늘 수업을 통해 여러분은 다음을 할 수 있게 됩니다:\n",
        "\n",
        "\n",
        "\n",
        " 1.  관계형 데이터베이스의 기본 구성 요소(**테이블, 행, 열**)를 설명하기. 🤔\n",
        "\n",
        " 2.  **기본 키(Primary Key)** 와 **외래 키(Foreign Key)** 의 개념과 **데이터 무결성**을 위한 역할을 설명하기. 🔑🔗\n",
        "\n",
        " 3.  SQL DDL(**`CREATE TABLE`**)을 사용하여 원하는 구조의 **테이블을 정의**하고, 데이터 타입을 지정하기. ⌨️🧱\n",
        "\n",
        " 4.  **정규화(Normalization)** 의 기본 개념(1NF, 2NF, 3NF)과 **필요성**(중복 최소화, 일관성 유지)을 설명하기. ✨📉\n",
        "\n",
        " 5.  간단한 비정규화된 테이블 예시를 보고 **정규화 과정**을 적용하여 스키마를 개선하는 방법을 설명하기 (개념적). 🎨\n",
        "\n",
        "\n",
        "\n",
        " > ✨ **심화 목표**\n",
        "\n",
        " >\n",
        "\n",
        " > * ER 다이어그램(ERD)이 무엇이며, DB 설계에서 어떻게 활용되는지 이해하기.\n",
        "\n",
        " > * 다양한 데이터 타입(정수, 문자열, 날짜 등)의 특징과 언제 사용해야 하는지 구별하기.\n",
        "\n",
        " > * `ALTER TABLE`을 사용하여 기존 테이블 구조를 수정하는 방법 알아보기."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brzSF_AHFcx5"
      },
      "source": [
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ## 📚 개념 설명 (핵심 요약)\n",
        "\n",
        "\n",
        "\n",
        " ### 1. 관계형 모델: 데이터를 '표'로 구조화하기 📊\n",
        "\n",
        "\n",
        "\n",
        " 1교시에서 배운 관계형 데이터베이스(RDB)는 데이터를 어떻게 구조화할까요?\n",
        "\n",
        " 바로 **테이블(Table)** 이라는 형식을 사용합니다. 엑셀 시트를 생각하면 이해하기 쉽습니다.\n",
        "\n",
        "\n",
        "\n",
        " * **테이블 (Table)**: 관계형 데이터베이스에서 데이터를 저장하는 기본 단위. 행과 열로 구성된 2차원 구조. (≒ 릴레이션 Relation)\n",
        "\n",
        "     ![시각 자료 삽입: 간단한 '사용자' 테이블 예시 그림](https://velog.velcdn.com/images%2Fodh0112%2Fpost%2F25fe3299-2b8d-4f07-ab11-c741e4dd6f4a%2F%EA%B7%B8%EB%A6%BC1.png)\n",
        "\n",
        " * **행 (Row)**: 테이블에서 하나의 데이터 단위를 나타냄. (≒ 레코드 Record, 튜플 Tuple)\n",
        "\n",
        "     * 예: 특정 사용자 한 명의 정보 (ID: 1, 이름: '민수', 나이: 25)\n",
        "\n",
        " * **열 (Column)**: 테이블에서 데이터의 특정 속성(Attribute)을 나타냄. 각 열은 정해진 **데이터 타입**(Data Type)을 가짐. (≒ 필드 Field, 속성 Attribute)\n",
        "\n",
        "     * 예: `사용자 ID`, `이름`, `나이` 등.\n",
        "\n",
        "     * **데이터 타입**: 해당 열에 저장될 데이터의 종류를 지정 (예: `INTEGER`, `TEXT`, `REAL`, `DATE`). 데이터의 일관성과 저장 효율성을 위해 중요. 🔵\n",
        "\n",
        "\n",
        "\n",
        " #### 테이블 설계: 왜 중요할까? 🤔\n",
        "\n",
        "\n",
        "\n",
        " * 데이터를 **체계적으로** 저장하고 관리하기 위한 **청사진**. 🏗️\n",
        "\n",
        " * 데이터 **중복**을 막고 **일관성**을 유지하는 기반. ✨\n",
        "\n",
        " * 나중에 데이터를 **효율적으로 검색**하고 활용하는 데 큰 영향. 🔍\n",
        "\n",
        "\n",
        "\n",
        " * **AI 앱 스키마 설계 예시 (이미지 분류 모델용 메타데이터)**\n",
        "\n",
        "     * **상황**: 이미지 분류 AI 모델 학습을 위해 이미지 파일 경로와 해당 이미지의 레이블(정답)을 저장해야 함.\n",
        "\n",
        "     * **테이블 설계 (예: `image_metadata` 테이블)**:\n",
        "\n",
        "| Column Name | Data Type | Description              | PK? |\n",
        "| :---------- | :-------- | :----------------------- | :-- |\n",
        "| `image_id`  | INTEGER   | 이미지 고유 ID           | ✅  |\n",
        "| `file_path` | TEXT      | 이미지 파일 저장 경로    |     |\n",
        "| `label`     | TEXT      | 이미지 정답 레이블 (예: 'cat') |     |\n",
        "| `dataset_source` | TEXT | 데이터셋 출처 (예: 'ImageNet') |   |\n",
        "\n",
        "\n",
        "\n",
        "     ➡️ 이렇게 테이블 구조를 미리 정의하면, 어떤 정보가 저장되는지 명확히 알 수 있고,\n",
        "\n",
        "        나중에 특정 레이블의 이미지 경로만 찾거나, 특정 데이터셋 이미지만 필터링하는 등\n",
        "\n",
        "        체계적인 데이터 관리가 가능해집니다. 🔵"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FQvPNSmFcx5"
      },
      "source": [
        " ### 2. 키(Key): 데이터 구별과 연결의 열쇠 🔑\n",
        "\n",
        "\n",
        "\n",
        " 테이블에서 **행을 고유하게 식별**하거나 **테이블 간의 관계**를 맺는 데 사용되는 특별한 열(들)입니다.\n",
        "\n",
        "\n",
        "\n",
        " 데이터의 **무결성(Integrity)** 을 지키는 데 핵심적인 역할을 합니다.\n",
        "\n",
        "\n",
        "\n",
        " 무결성이란 데이터가 정확하고 일관되게 유지되는 것을 의미하며, 잘못된 데이터나 중복된 데이터가 없도록 보장하는 것입니다.\n",
        "\n",
        " ![시각 자료 삽입: users 테이블(PK)과 orders 테이블(FK) 관계 예시 그림](https://velog.velcdn.com/images/so_oyv/post/28d649d9-fe1c-4c2d-8173-2bb76e549f72/image.jpeg)\n",
        "\n",
        " * **기본 키 (Primary Key, PK)** ✨\n",
        "\n",
        "     * **개념**: 테이블에서 각 행을 **고유하게 식별**할 수 있는 하나 이상의 열.\n",
        "\n",
        "     * **특징**:\n",
        "\n",
        "         * **유일성 (Uniqueness)**: PK 값은 테이블 내에서 **중복될 수 없음**. ❌ (예: 모든 사용자는 고유한 ID를 가짐)\n",
        "\n",
        "         * **최소성 (Minimality)**: 꼭 필요한 최소한의 열로 구성됨.\n",
        "\n",
        "         * **NULL 값 불가 (Not Null)**: PK 값은 비어 있을 수 없음. ❌\n",
        "\n",
        "     * **역할**: 특정 데이터를 정확하게 찾아 수정하거나 삭제하는 기준. 다른 테이블과의 관계 설정 기준. 🔵\n",
        "\n",
        "     * **예**: `users` 테이블의 `user_id`, `products` 테이블의 `product_code`.\n",
        "\n",
        "\n",
        "\n",
        " * **외래 키 (Foreign Key, FK)** 🔗\n",
        "\n",
        "     * **개념**: 한 테이블의 열(들)이 다른 테이블의 **기본 키(PK)** 를 참조하는 것. 테이블 간의 **관계(Relationship)** 를 표현.\n",
        "\n",
        "     * **특징**:\n",
        "\n",
        "         * 참조하는 테이블(부모 테이블)의 PK에 **존재하는 값**만 허용 (또는 NULL).\n",
        "\n",
        "         * 이를 통해 **참조 무결성(Referential Integrity)** 을 보장. → 잘못된 데이터 연결 방지 🔵\n",
        "\n",
        "     * **역할**: 여러 테이블에 분산된 정보를 **연결**하여 의미 있는 데이터 조회 가능 (JOIN의 기반).\n",
        "\n",
        "     * **예**: `orders` 테이블의 `user_id` 열은 `users` 테이블의 `user_id`(PK)를 참조 (FK). 주문 정보와 사용자 정보를 연결 가능.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " #### 📊 키(Key) 요약\n",
        "\n",
        "\n",
        "\n",
        " | 종류     | 역할                      | 특징                      | 예시 (orders 테이블 기준)          |\n",
        " | :------- | :------------------------ | :------------------------ | :----------------------------- |\n",
        " | **기본 키 (PK)** | 행 고유 식별              | 유일성, 최소성, Not Null  | `order_id` (주문 번호)         |\n",
        " | **외래 키 (FK)** | 다른 테이블 PK 참조 (관계) | 참조 무결성               | `user_id` (users 테이블 참조) |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vainqHLFcx5"
      },
      "source": [
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ## ❓ 퀴즈 1: 테이블, 키 개념 확인\n",
        "\n",
        "\n",
        "\n",
        " ### ✍️ 단답형/매칭형 문제 1 (난이도: ⭐️⭐️⭐️)\n",
        "\n",
        "\n",
        "\n",
        " 다음 설명을 보고 빈칸에 알맞은 용어 (테이블, 행, 열, 기본 키, 외래 키)를 채우거나 연결하세요.\n",
        "\n",
        "\n",
        "\n",
        " 1.  관계형 데이터베이스에서 데이터를 저장하는 기본 단위로, 행과 열로 구성된 2차원 구조는? `[ 빈칸 ]`\n",
        "\n",
        " 2.  테이블에서 하나의 완전한 데이터 단위를 나타내는 가로줄은? `[ 빈칸 ]`\n",
        "\n",
        " 3.  테이블에서 데이터의 특정 속성을 나타내는 세로줄은? `[ 빈칸 ]`\n",
        "\n",
        " 4.  테이블 내 각 행을 유일하게 구별하며 NULL 값을 가질 수 없는 키는? `[ 빈칸 ]`\n",
        "\n",
        " 5.  한 테이블의 값이 다른 테이블의 기본 키 값을 참조하여 테이블 간 관계를 맺는 키는? `[ 빈칸 ]`\n",
        "\n",
        "\n",
        "\n",
        " ---\n",
        "\n",
        "\n",
        "\n",
        " * (A) 테이블의 각 행을 고유하게 식별\n",
        "\n",
        " * (B) 다른 테이블의 기본 키를 참조하여 관계 설정\n",
        "\n",
        "\n",
        "\n",
        " * (가) 기본 키 (Primary Key)\n",
        "\n",
        " * (나) 외래 키 (Foreign Key)\n",
        "\n",
        "\n",
        "\n",
        " * 매칭: (A) - `[ 빈칸 ]`, (B) - `[ 빈칸 ]`\n",
        "\n",
        "\n",
        "\n",
        " ### <h3>정답 및 해설</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7C0FIhtFcx5"
      },
      "source": [
        " 1.  **정답:** 테이블\n",
        "\n",
        " 2.  **정답:** 행 (Row)\n",
        "\n",
        " 3.  **정답:** 열 (Column)\n",
        "\n",
        " 4.  **정답:** 기본 키 (Primary Key)\n",
        "\n",
        " 5.  **정답:** 외래 키 (Foreign Key)\n",
        "\n",
        "\n",
        "\n",
        " ---\n",
        "\n",
        "\n",
        "\n",
        " * **매칭 정답:** (A) - (가), (B) - (나)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wbjlg6TBFcx5"
      },
      "source": [
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ## 📚 개념 설명: SQL DDL - 테이블 구조 정의하기\n",
        "\n",
        "\n",
        "\n",
        " **DDL (Data Definition Language)**: 데이터베이스의 **구조**를 정의, 수정, 삭제하는 SQL 명령어.\n",
        "\n",
        " 대표적으로 `CREATE`, `ALTER`, `DROP` 이 있습니다.\n",
        "\n",
        "\n",
        "\n",
        " * **`CREATE TABLE`**: 새로운 테이블을 생성. 🧱\n",
        "\n",
        "     * **기본 구문**:\n",
        "\n",
        "       ```sql\n",
        "\n",
        "       CREATE TABLE table_name (\n",
        "\n",
        "           column1 datatype [constraints],\n",
        "\n",
        "           column2 datatype [constraints],\n",
        "\n",
        "           ...\n",
        "\n",
        "           [table_constraints]\n",
        "\n",
        "       );\n",
        "\n",
        "       ```\n",
        "\n",
        "     * `table_name`: 생성할 테이블 이름.\n",
        "\n",
        "     * `column_name`: 열 이름.\n",
        "\n",
        "     * `datatype`: 열의 데이터 타입 (예: `INTEGER`, `TEXT`, `REAL`, `BLOB`, `DATE`, `VARCHAR(n)` 등 DB마다 지원 타입 상이).\n",
        "\n",
        "     * `[constraints]`: 열에 적용될 제약 조건 (선택 사항).\n",
        "\n",
        "         * `NOT NULL`: 해당 열에 NULL 값 입력 방지. ❌\n",
        "\n",
        "         * `UNIQUE`: 해당 열의 모든 값이 고유해야 함 (중복 방지). ✨\n",
        "\n",
        "         * `PRIMARY KEY`: 기본 키로 지정. (자동으로 `NOT NULL` + `UNIQUE` 포함) 🔑\n",
        "\n",
        "         * `FOREIGN KEY REFERENCES referenced_table(referenced_column)`: 외래 키로 지정. 🔗\n",
        "\n",
        "         * `DEFAULT default_value`: 값 미입력 시 기본값 설정.\n",
        "\n",
        "\n",
        "\n",
        " * **`ALTER TABLE`**: 기존 테이블의 구조를 **수정**. (예: 열 추가/삭제/변경, 제약 조건 추가/삭제) 🔧\n",
        "\n",
        "     * 예: `ALTER TABLE users ADD COLUMN email TEXT;` (users 테이블에 email 열 추가)\n",
        "\n",
        "     * 예: `ALTER TABLE products DROP COLUMN description;` (products 테이블에서 description 열 삭제)\n",
        "\n",
        "\n",
        "\n",
        " * **`DROP TABLE`**: 기존 테이블을 **완전히 삭제**. 🗑️ (⚠️ 주의: 테이블의 모든 데이터도 함께 사라짐!) 🔴🔴🔴\n",
        "\n",
        "     * 예: `DROP TABLE temp_users;`\n",
        "\n",
        "\n",
        "\n",
        " 오늘은 이 중 `CREATE TABLE`을 중점적으로 실습합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCP3CbNoFcx5"
      },
      "source": [
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ## 💻 코드 실습 1: `CREATE TABLE` 로 테이블 만들기\n",
        "\n",
        "\n",
        "\n",
        " Python `sqlite3`를 사용하여 AI 프로젝트용 테이블(`image_metadata`)을 직접 생성해 봅시다.\n",
        "\n",
        " 키(PK)와 데이터 타입을 정확히 지정하는 것이 중요합니다.\n",
        "\n",
        "\n",
        "\n",
        " **요구사항:**\n",
        "\n",
        "\n",
        "\n",
        " * 테이블 이름: `image_metadata`\n",
        "\n",
        " * 열(Columns):\n",
        "\n",
        "     * `image_id`: 정수(INTEGER), 기본 키(PRIMARY KEY), 자동으로 1씩 증가(AUTOINCREMENT - SQLite 특정 기능).\n",
        "\n",
        "     * `file_path`: 텍스트(TEXT), NULL 값 허용 안 함(NOT NULL).\n",
        "\n",
        "     * `label`: 텍스트(TEXT), NULL 값 허용 안 함(NOT NULL).\n",
        "\n",
        "     * `confidence`: 실수(REAL), 값 없으면 기본값 0.0 설정(DEFAULT).\n",
        "\n",
        "     * `annotation_date`: 날짜/시간 (TEXT 타입으로 저장 - SQLite는 DATE 타입 별도 없음)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvOkKuZmFcx5"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "# 실습에 필요한 라이브러리 import 및 DB 연결 (1교시 코드 재활용)\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "\n",
        "# 이전 실습의 conn 객체가 있다면 닫아줍니다.\n",
        "try:\n",
        "    if 'conn' in locals() and conn is not None:\n",
        "        try:\n",
        "            conn.execute(\"SELECT 1\")\n",
        "            conn.close()\n",
        "            print(\"이전 SQLite 연결을 닫았습니다.\")\n",
        "        except sqlite3.ProgrammingError:\n",
        "            print(\"이전 SQLite 연결이 이미 닫혔거나 유효하지 않습니다.\")\n",
        "except NameError:\n",
        "    pass\n",
        "except Exception as e:\n",
        "    print(f\"이전 연결 처리 중 오류: {e}\")\n",
        "\n",
        "# 데이터베이스 연결 (메모리)\n",
        "conn = sqlite3.connect(':memory:')\n",
        "cursor = conn.cursor()\n",
        "print(\"SQLite 데이터베이스에 성공적으로 연결되었습니다 (in-memory).\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjvUSytVFcx5"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "# TODO: image_metadata 테이블을 생성하는 CREATE TABLE 쿼리를 작성하고 실행하세요.\n",
        "\n",
        "# 힌트 1: 각 컬럼명 뒤에 데이터 타입과 제약 조건을 명시합니다.\n",
        "# 힌트 2: SQLite에서 PK 이면서 자동 증가는 INTEGER PRIMARY KEY AUTOINCREMENT 로 지정합니다.\n",
        "# 힌트 3: 기본값 설정은 DEFAULT 키워드를 사용합니다.\n",
        "\n",
        "create_image_table_sql = \"\"\"\n",
        "CREATE TABLE image_metadata (\n",
        "    image_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    file_path TEXT NOT NULL,\n",
        "    label TEXT NOT NULL,\n",
        "    confidence REAL DEFAULT 0.0,\n",
        "    annotation_date TEXT\n",
        ");\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    cursor.execute(create_image_table_sql)\n",
        "    conn.commit() # DDL도 commit 필요 (SQLite 경우, 다른 DB는 Auto-commit될 수도 있음)\n",
        "    print(\"`image_metadata` 테이블 생성 성공!\")\n",
        "\n",
        "    # 생성된 테이블 구조 확인\n",
        "    print(\"\\n--- 생성된 image_metadata 테이블 구조 ---\")\n",
        "    # PRAGMA table_info: SQLite에서 테이블 구조 보는 명령어\n",
        "    table_info = pd.read_sql(\"PRAGMA table_info(image_metadata);\", conn)\n",
        "    print(table_info)\n",
        "\n",
        "    # 생성된 테이블 목록 확인 (선택적)\n",
        "    # print(\"\\n--- 현재 DB의 테이블 목록 ---\")\n",
        "    # tables = pd.read_sql(\"SELECT name FROM sqlite_master WHERE type='table';\", conn)\n",
        "    # print(tables)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"테이블 생성 중 오류 발생: {e}\")\n",
        "    conn.rollback()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HK0Xu6ljFcx5"
      },
      "source": [
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ## 📚 개념 설명: 정규화 (Normalization) - 좋은 테이블 설계하기 ✨\n",
        "\n",
        "\n",
        "\n",
        " 테이블 설계를 잘 못하면 데이터 **중복**이 발생하고, 수정/삭제 시 **문제가 생길 수 있습니다 (이상 현상 Anomalies)**. 🔴\n",
        "\n",
        " **정규화(Normalization)** 는 이러한 문제를 해결하기 위해, **데이터 중복을 최소화**하고 **데이터 일관성 및 무결성**을 높이는 방향으로 테이블 구조를 **분해(Decomposition)** 하는 과정입니다.\n",
        "\n",
        "\n",
        "\n",
        " * **목표**: 잘 구조화된(Well-structured) 관계 스키마(테이블 구조)를 만드는 것. 🔵\n",
        "\n",
        " * **핵심 원리**: \"하나의 데이터는 한 곳에만 저장한다.\" (정보 중복 배제)\n",
        "\n",
        " * **주요 정규형 (Normal Forms)**: 단계별 규칙 집합. 차수가 높아질수록 제약 조건이 엄격해짐.\n",
        "\n",
        "     * **제1정규형 (1NF - First Normal Form)**\n",
        "\n",
        "     * **제2정규형 (2NF - Second Normal Form)**\n",
        "\n",
        "     * **제3정규형 (3NF - Third Normal Form)**\n",
        "\n",
        "     * BCNF, 4NF, 5NF 등 더 높은 차수도 있지만, 보통 **3NF** 까지 만족하면 실무에서 충분한 경우가 많음.\n",
        "\n",
        "\n",
        "\n",
        " * **왜 필요할까? (정규화의 장점)**\n",
        "\n",
        "     * **데이터 중복 최소화** → 저장 공간 효율화 💾\n",
        "\n",
        "     * **데이터 일관성 향상** → 정보 불일치 가능성 감소 ✨\n",
        "\n",
        "     * **데이터 수정/삭제 시 이상 현상(Anomaly) 방지** → 데이터 무결성 강화 💪\n",
        "\n",
        "         * **삽입 이상**: 불필요한 정보 없이는 데이터 삽입 불가.\n",
        "\n",
        "         * **갱신 이상**: 중복 데이터 중 일부만 수정되어 불일치 발생.\n",
        "\n",
        "         * **삭제 이상**: 필요한 정보까지 함께 삭제되는 문제.\n",
        "\n",
        "     * 테이블 구조 단순화 → **이해 및 관리 용이** 👀\n",
        "\n",
        "\n",
        "\n",
        " * **정규화 단계 요약**:\n",
        "\n",
        "\n",
        "\n",
        "     #### 📊 정규화 단계별 조건\n",
        "\n",
        "\n",
        "\n",
        "| 정규형 | 조건                                                    | 목표                       |\n",
        "| :----- | :------------------------------------------------------ | :------------------------- |\n",
        "| **1NF** | 모든 열의 값이 **원자값(Atomic Value)** 이어야 함.         | 다중값 속성 제거           |\n",
        "| **2NF** | 1NF 만족 + **부분 함수 종속 제거**. (PK 전체에 완전 종속) | 부분 종속 속성 분리        |\n",
        "| **3NF** | 2NF 만족 + **이행 함수 종속 제거**. (PK 외 일반 열 간 종속 X) | 이행 종속 속성 분리        |\n",
        "\n",
        "\n",
        "\n",
        "     * **함수 종속(Functional Dependency)**: X → Y (X 값이 정해지면 Y 값이 **유일하게** 정해짐). 정규화의 핵심 개념. (예: `학번` → `이름`, `학번` → `학과`)\n",
        "\n",
        "     * **부분 함수 종속**: 복합 PK의 **일부**에만 종속. (2NF 위반)\n",
        "\n",
        "![](https://velog.velcdn.com/images/wisdom-one/post/287cc94a-aed1-42f2-b9a5-aaa64c62e9be/image.png)\n",
        "\n",
        "![](https://velog.velcdn.com/images/wisdom-one/post/7dfb58dc-70d9-4fea-8663-823c6e165cc2/image.png)\n",
        "\n",
        "     * **이행 함수 종속**: PK → 일반속성1 → 일반속성2 형태의 종속. (3NF 위반)\n",
        "\n",
        "![](https://velog.velcdn.com/images/wisdom-one/post/1953d93d-5120-4d71-af80-4bd6b3f350df/image.png)\n",
        "\n",
        "![](https://velog.velcdn.com/images/wisdom-one/post/7f0bfbd9-46da-429c-bf07-60c66642bd02/image.png)\n",
        "\n",
        " * **주의**: 과도한 정규화는 테이블 수가 너무 많아져 JOIN 연산 비용 증가 → 성능 저하 가능성 🔴.\n",
        "\n",
        "   상황에 따라 **반정규화(Denormalization)** 를 고려하기도 함 (성능 최적화 목적). Trade-off 존재!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rn05KoWCFcx5"
      },
      "source": [
        " ### ER 다이어그램 (ERD) 소개 🗺️\n",
        "\n",
        "\n",
        "\n",
        " * **ERD (Entity-Relationship Diagram)**: 데이터베이스 구조를 **시각적으로 표현**하는 도구.\n",
        "\n",
        " * **구성 요소**:\n",
        "\n",
        "     * **개체 (Entity)**: 저장할 데이터 대상 (≒ 테이블). 사각형으로 표현. (예: `사용자`, `주문`)\n",
        "\n",
        "     * **속성 (Attribute)**: 개체의 특성 (≒ 열). 타원형 또는 개체 내부에 표기. (예: `이름`, `주문일자`)\n",
        "\n",
        "     * **관계 (Relationship)**: 개체 간의 연결. 마름모 또는 선으로 표현. (예: 사용자가 주문을 한다)\n",
        "\n",
        " * **활용**: DB 설계를 **직관적으로 이해**하고, 다른 사람과 **의사소통**하는 데 유용. 🔵\n",
        "\n",
        "   ![시각 자료 삽입: 간단한 사용자-주문 관계 ERD 예시](https://attachments.datarian.io/production-ce478fb4-e040-41d8-8f11-a9332f58dc07-agrRNvzr0CcX_nekT1mPtqxfrBIaSjNyEDnQfX4f8U0.png?spaceId=d3a6155a-29fd-4398-a837-fa7ff01c7a4a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VV2tfEsaFcx5"
      },
      "source": [
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ## 💻 실습 2: 정규화 개념 적용 (비정규 테이블 개선)\n",
        "\n",
        "\n",
        "\n",
        " 아래는 학생의 수강 정보를 담은 비정규화된 테이블 예시입니다.\n",
        "\n",
        " 이 테이블의 문제점을 파악하고, 1NF, 2NF, 3NF 과정을 거쳐 정규화된 테이블 구조로 개선하는 과정을 **개념적으로 설명**해 보세요. (코딩 X)\n",
        "\n",
        "\n",
        "\n",
        " **비정규화된 수강 테이블 (수강정보)**\n",
        "\n",
        "\n",
        "\n",
        " | **<u>학번</u>** | **<u>과목코드</u>** | 학생이름 | 학과     | 과목명 | 담당교수 | 연락처 | 수강료 |\n",
        " | :------- | :------- | :------- | :------- | :----- | :------- | :----- | :----- |\n",
        " | 1001     | CS101    | 김민수   | 컴퓨터공학 | 자료구조 | 이교수   | 010-111 | 300000 |\n",
        " | 1001     | CS102    | 김민수   | 컴퓨터공학 | 운영체제 | 박교수   | 010-222 | 350000 |\n",
        " | 1002     | CS101    | 박지영   | 컴퓨터공학 | 자료구조 | 이교수   | 010-111 | 300000 |\n",
        " | 1003     | EE201    | 최철수   | 전자공학 | 회로이론 | 최교수   | 010-333 | 400000 |\n",
        "\n",
        "\n",
        "\n",
        " **기본 키 (PK)**: `(학번, 과목코드)` - 복합 키\n",
        "\n",
        "\n",
        "\n",
        " **함수 종속 관계 파악:**\n",
        "\n",
        " * `학번` → `학생이름`, `학과`\n",
        "\n",
        " * `과목코드` → `과목명`, `담당교수`, `연락처`, `수강료`\n",
        "\n",
        " * `담당교수` → `연락처` (이행 종속 가능성)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1AkLQ89Fcx6"
      },
      "source": [
        " ### 🤔 문제점 분석\n",
        "\n",
        "\n",
        "\n",
        " 위 테이블에는 어떤 문제점(이상 현상 발생 가능성, 데이터 중복)이 있을까요?\n",
        "\n",
        "\n",
        "\n",
        " ### 💡 정규화 과정 (개념 설명)\n",
        "\n",
        "\n",
        "\n",
        " 1.  **제1정규형 (1NF) 적용**: 현재 테이블은 모든 값이 원자값인가요? (만약 한 칸에 여러 값이 있다면 분리 필요)\n",
        "\n",
        " 2.  **제2정규형 (2NF) 적용**: 부분 함수 종속이 있나요? 있다면 어떻게 분리해야 할까요?\n",
        "\n",
        "     * PK(`학번`, `과목코드`)의 일부(`학번`)에만 종속된 열: `학생이름`, `학과`\n",
        "\n",
        "     * PK(`학번`, `과목코드`)의 일부(`과목코드`)에만 종속된 열: `과목명`, `담당교수`, `연락처`, `수강료`\n",
        "\n",
        " 3.  **제3정규형 (3NF) 적용**: 이행 함수 종속이 있나요? 있다면 어떻게 분리해야 할까요?\n",
        "\n",
        "     * `과목코드` → `담당교수` → `연락처` ? (담당교수가 정해지면 연락처가 정해짐)\n",
        "\n",
        "\n",
        "\n",
        " ### 🎨 개선된 테이블 구조 (결과 스케치)\n",
        "\n",
        "\n",
        "\n",
        " 정규화를 통해 최종적으로 어떤 테이블들로 분리될지 구조를 그려보세요. (테이블명, 컬럼명, PK/FK 표시)\n",
        "\n",
        "\n",
        "\n",
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ### <h3>정답 및 해설 (개념적 설명)</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SOduj8jFcx6"
      },
      "source": [
        " ### 🤔 문제점 분석\n",
        "\n",
        "\n",
        "\n",
        " * **데이터 중복**:\n",
        "\n",
        "     * 학생 정보(이름, 학과)가 수강 과목마다 반복 저장됨. (1001 학생 정보 2번 중복)\n",
        "\n",
        "     * 과목 정보(과목명, 담당교수, 연락처, 수강료)가 수강 학생마다 반복 저장됨. (CS101 과목 정보 2번 중복)\n",
        "\n",
        " * **이상 현상 발생 가능성**:\n",
        "\n",
        "     * **갱신 이상**: '이교수'의 연락처가 바뀌면, CS101을 수강하는 모든 학생의 행에서 연락처를 변경해야 함. 누락 시 불일치 발생. 🔴\n",
        "\n",
        "     * **삽입 이상**: 아직 수강 신청을 하지 않은 신규 과목 정보(과목명, 담당교수 등)를 등록할 수 없음 (학번, 과목코드가 PK인데 학번 없이 등록 불가). 🔴\n",
        "\n",
        "     * **삭제 이상**: '최철수' 학생이 수강을 취소하여 해당 행을 삭제하면, '회로이론' 과목 정보까지 함께 사라질 수 있음 (만약 최철수가 유일한 수강생이라면). 🔴\n",
        "\n",
        "\n",
        "\n",
        " ### 💡 정규화 과정 (개념 설명)\n",
        "\n",
        "\n",
        "\n",
        " 1.  **1NF 적용**: 현재 테이블은 각 컬럼에 하나의 값만 가지고 있으므로 **1NF는 만족**합니다. 🔵\n",
        "\n",
        "\n",
        "\n",
        " 2.  **2NF 적용 (부분 함수 종속 제거)**: PK(`학번`, `과목코드`)에 완전 종속되지 않은 열들을 분리합니다.\n",
        "\n",
        "     * `학번`에 종속된 (`학생이름`, `학과`) → **`학생` 테이블** 분리\n",
        "\n",
        "     * `과목코드`에 종속된 (`과목명`, `담당교수`, `연락처`, `수강료`) → **`과목` 테이블** 분리\n",
        "\n",
        "     * 원래 테이블에는 PK(`학번`, `과목코드`)만 남김 → **`수강` 테이블**\n",
        "\n",
        "     * `[시각 자료 삽입: 2NF 분리 결과 테이블 구조 그림]`\n",
        "\n",
        "\n",
        "\n",
        " 3.  **3NF 적용 (이행 함수 종속 제거)**: 2NF 결과 테이블들에서 PK 외 일반 속성 간의 종속을 제거합니다.\n",
        "\n",
        "     * `과목` 테이블에서 `과목코드` → `담당교수` 이고, `담당교수` → `연락처` 라는 종속 관계가 있다면, `연락처`는 `담당교수`에 이행적으로 종속됩니다. (만약 교수가 여러 과목 담당 가능해도, 교수가 정해지면 연락처는 하나).\n",
        "\n",
        "     * 이행 종속 제거 → `연락처` 열을 `과목` 테이블에서 분리하여 **`교수` 테이블** 생성 (`담당교수` PK, `연락처` 속성).\n",
        "\n",
        "     * `과목` 테이블에는 `담당교수` 열만 남겨 `교수` 테이블을 참조하는 FK로 설정. (수강료는 과목 자체의 속성으로 가정)\n",
        "\n",
        "     * `[시각 자료 삽입: 3NF 분리 결과 테이블 구조 그림]`\n",
        "\n",
        "\n",
        "\n",
        " ### 🎨 개선된 테이블 구조 (3NF 결과)\n",
        "\n",
        "\n",
        "\n",
        " * **학생 (<u>학번</u>, 학생이름, 학과)**\n",
        "\n",
        "     * PK: `학번`\n",
        "\n",
        " * **교수 (<u>담당교수</u>, 연락처)**\n",
        "\n",
        "     * PK: `담당교수`\n",
        "\n",
        " * **과목 (<u>과목코드</u>, 과목명, *담당교수*, 수강료)**\n",
        "\n",
        "     * PK: `과목코드`\n",
        "\n",
        "     * FK: `담당교수` (교수 테이블 참조)\n",
        "\n",
        " * **수강 (<u>*학번*</u>, <u>*과목코드*</u>)**\n",
        "\n",
        "     * PK: (`학번`, `과목코드`) - 복합키\n",
        "\n",
        "     * FK1: `학번` (학생 테이블 참조)\n",
        "\n",
        "     * FK2: `과목코드` (과목 테이블 참조)\n",
        "\n",
        "\n",
        "\n",
        " ➡️ 이렇게 테이블을 분리하면 데이터 중복이 제거되고, 각 정보는 해당 테이블에서만 관리되어 이상 현상 발생 가능성이 크게 줄어듭니다. 🔵"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJkpUxr5Fcx6"
      },
      "source": [
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ## ❓ 퀴즈 2: 정규화의 목적\n",
        "\n",
        "\n",
        "\n",
        " ### 🧐 객관식 문제 2 (난이도: ⭐️⭐️⭐️)\n",
        "\n",
        "\n",
        "\n",
        " 데이터베이스 설계에서 정규화(Normalization)를 수행하는 주된 목적으로 **가장 적절한** 것은 무엇인가요?\n",
        "\n",
        "\n",
        "\n",
        " 1.  테이블 수를 최대한 줄여 관리를 용이하게 하기 위해.\n",
        "\n",
        " 2.  SQL 쿼리 작성 속도를 빠르게 하기 위해.\n",
        "\n",
        " 3.  데이터의 중복성을 최소화하고 데이터 무결성을 향상시키기 위해.\n",
        "\n",
        " 4.  데이터베이스의 물리적 저장 공간 크기를 늘리기 위해.\n",
        "\n",
        " 5.  모든 테이블에 기본 키(Primary Key)를 반드시 하나만 설정하기 위해.\n",
        "\n",
        "\n",
        "\n",
        " ### <h3>정답 및 해설</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWhUP4GWFcx6"
      },
      "source": [
        " **정답: 3번**\n",
        "\n",
        "\n",
        "\n",
        " **해설:**\n",
        "\n",
        " 정규화의 가장 핵심적인 목표는 테이블 구조를 재구성하여 **데이터 중복을 줄이고**, 이로 인해 발생할 수 있는 **갱신/삽입/삭제 이상 현상을 방지**하여 **데이터의 일관성과 무결성을 높이는 것**입니다.\n",
        "\n",
        " 1. 정규화는 오히려 테이블 수가 늘어나는 경우가 많습니다. 🔴\n",
        "\n",
        " 2. 정규화된 테이블은 JOIN 연산이 필요해져 쿼리가 복잡해지거나 느려질 수 있습니다. 🔴 (성능 vs. 정규화 Trade-off)\n",
        "\n",
        " 4. 중복 제거로 저장 공간이 효율화(감소)되는 경우가 많습니다. 🔴\n",
        "\n",
        " 5. 기본 키 설정은 중요하지만, 정규화의 직접적인 '목적'이라기보다는 잘 설계된 테이블의 '특성'에 가깝습니다. 정규화 과정에서 키 구조가 변경될 수 있습니다.\n",
        "\n",
        "\n",
        "\n",
        " ### 🚀 더 나아가기 (생각해보기)\n",
        "\n",
        "\n",
        "\n",
        " * 정규화는 항상 좋은 것일까요? 정규화를 하지 않거나 일부러 정규화 단계를 낮추는 **반정규화(Denormalization)** 는 어떤 경우에 고려해볼 수 있을까요? (힌트: 성능)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2H9Fs8yFcx6"
      },
      "source": [
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ## ❓ F.A.Q (2교시 궁금증 해소)\n",
        "\n",
        "\n",
        "\n",
        " * **Q1: 기본 키(PK)랑 외래 키(FK)가 아직도 헷갈려요.**\n",
        "\n",
        "     * **A1**: 쉽게 생각하세요! 🔑 **PK**는 각 테이블에서 **'이 행은 누구인가?'** 를 딱 알려주는 **주민등록번호** 같은 고유 식별자입니다. 테이블 당 보통 하나만 존재합니다. 🔗 **FK**는 다른 테이블의 PK(주민등록번호)를 **참조**해서, **'이 주문은 어떤 고객의 것인가?'** 처럼 테이블 간의 **관계**를 이어주는 **연결 고리**입니다. 한 테이블에 여러 개 있을 수 있습니다.\n",
        "\n",
        "\n",
        "\n",
        " * **Q2: 테이블 설계할 때 정규화는 꼭 해야 하나요?**\n",
        "\n",
        "     * **A2**: **대부분의 경우 하는 것이 좋습니다.** 🔵 데이터 중복과 이상 현상을 막아 데이터 품질을 높이는 가장 기본적인 방법입니다. 하지만, **JOIN이 너무 많아져서 조회 성능이 심각하게 저하되는 경우** 등 특정 상황에서는 의도적으로 정규화 수준을 낮추는 **반정규화**를 고려하기도 합니다. (성능 <-> 데이터 무결성 Trade-off)\n",
        "\n",
        "\n",
        "\n",
        " * **Q3: DDL이랑 DML은 뭐가 다른 건가요?**\n",
        "\n",
        "     * **A3**: **DDL (Data Definition Language)** 은 데이터베이스의 **구조(뼈대)** 를 만들거나(CREATE), 바꾸거나(ALTER), 없애는(DROP) 명령어입니다. 🏗️ 반면, **DML (Data Manipulation Language)** 은 그 구조 안에 있는 **실제 데이터**를 다루는 명령어입니다(SELECT, INSERT, UPDATE, DELETE). ✍️ 오늘 주로 배운 `CREATE TABLE`은 DDL이고, 1교시의 SQL 명령어들은 DML입니다.\n",
        "\n",
        "\n",
        "\n",
        " * **Q4: 테이블 구조를 만들었는데, 나중에 바꿀 수 있나요?**\n",
        "\n",
        "     * **A4**: **네, 가능합니다!** 🔵 `ALTER TABLE` 명령어를 사용하면 테이블에 **열을 추가하거나 삭제**하고, **데이터 타입을 변경**하거나, **제약 조건을 추가/삭제**하는 등 기존 테이블 구조를 수정할 수 있습니다. 하지만 운영 중인 서비스의 테이블 구조 변경은 데이터 유실 위험 등이 있을 수 있어 신중하게 접근해야 합니다. ⚠️\n",
        "\n",
        "\n",
        "\n",
        " * **Q5: ERD는 꼭 그려야 하나요?**\n",
        "\n",
        "     * **A5**: 필수는 아니지만, **그리는 것이 매우 도움됩니다.** 🔵 특히 테이블이 여러 개이고 관계가 복잡해지면, ERD는 전체 구조를 한눈에 파악하고 설계 오류를 미리 발견하는 데 유용합니다. 팀원들과 설계를 공유하고 논의할 때도 효과적인 의사소통 도구입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JP1k6QEqFcx6"
      },
      "source": [
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ## 🔑 2교시 핵심 정리\n",
        "\n",
        "\n",
        "\n",
        " * **관계형 모델**: 데이터를 **테이블**(행/열) 형태로 구조화. 📊\n",
        "\n",
        " * **키 (Key)**: 데이터 무결성의 핵심.\n",
        "\n",
        "     * **기본 키 (PK)**: 행의 **고유 식별자** (주민등록번호 역할). 🔑 (Unique, Not Null)\n",
        "\n",
        "     * **외래 키 (FK)**: 다른 테이블 PK 참조 → 테이블 간 **관계 연결**. 🔗 (참조 무결성)\n",
        "\n",
        " * **SQL DDL (Data Definition Language)**: DB **구조** 정의/수정/삭제.\n",
        "\n",
        "     * **`CREATE TABLE`**: 테이블 생성 (열 이름, 데이터 타입, 제약 조건 지정). 🧱\n",
        "\n",
        "     * `ALTER TABLE`: 테이블 구조 수정. 🔧\n",
        "\n",
        "     * `DROP TABLE`: 테이블 삭제. 🗑️ (주의!)\n",
        "\n",
        " * **정규화 (Normalization)**: 테이블 구조 개선 과정. ✨\n",
        "\n",
        "     * **목표**: **데이터 중복 최소화**, **데이터 일관성/무결성 향상**. 📉💪\n",
        "\n",
        "     * **주요 단계**: 1NF (원자값) → 2NF (부분 종속 제거) → 3NF (이행 종속 제거).\n",
        "\n",
        "     * **효과**: 이상 현상(Anomaly) 방지. 🔵\n",
        "\n",
        "     * **주의**: 과도하면 성능 저하 가능성 (반정규화 고려). 🔴\n",
        "\n",
        " * **ER 다이어그램 (ERD)**: DB 구조 **시각화** 도구. 설계 이해 및 소통에 유용. 🗺️"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcrLL3WYFcx7"
      },
      "source": [
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ## 💭 2교시 마무리\n",
        "\n",
        "\n",
        "\n",
        " 이번 시간에는 관계형 데이터베이스의 데이터를 구조화하는 **테이블, 행, 열**의 개념을 배우고, 데이터의 무결성을 지키는 **기본 키(PK)와 외래 키(FK)** 의 중요성을 이해했습니다.\n",
        "\n",
        "\n",
        "\n",
        " SQL DDL 명령어인 **`CREATE TABLE`** 을 사용하여 직접 테이블 구조를 정의하는 실습을 진행했으며, 좋은 테이블 설계를 위한 **정규화(Normalization)** 의 기본 개념과 필요성, 그리고 간단한 예시를 통해 개념적으로 적용하는 연습을 했습니다.\n",
        "\n",
        "\n",
        "\n",
        " 잘 설계된 데이터베이스 구조는 AI 모델 학습 데이터 관리부터 서비스 운영까지 모든 과정의 효율성과 안정성을 높이는 기반이 됩니다. 오늘 배운 내용을 바탕으로 앞으로 데이터를 어떻게 효과적으로 구조화할지 고민해보는 계기가 되기를 바랍니다.\n",
        "\n",
        "\n",
        "\n",
        " **다음 3교시에는 여러 테이블에 나뉘어 저장된 데이터를 연결하여 조회하는 `JOIN`과, 데이터를 그룹별로 분석하는 `GROUP BY` 등 더 강력한 SQL 활용법에 대해 알아보겠습니다.**\n",
        "\n",
        "\n",
        "\n",
        " ### 🚀 더 나아가기 (2교시 복습)\n",
        "\n",
        "\n",
        "\n",
        " * 1교시에서 만든 `ai_models` 테이블과 2교시에서 만든 `image_metadata` 테이블 간에 어떤 관계를 설정할 수 있을지 생각해보고, 이를 위해 어떤 테이블에 어떤 FK를 추가해야 할지 구상해보세요. (예: 특정 모델이 어떤 이미지 데이터로 학습되었는지 연결)\n",
        "\n",
        " * SQLite에서 지원하는 다른 데이터 타입들(예: `BLOB`, 날짜/시간 함수)을 검색해보고, 어떤 종류의 데이터를 저장하는 데 사용할 수 있을지 알아보세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IldjcPUfFcx7"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "# 실습 종료 후 데이터베이스 연결 해제\n",
        "try:\n",
        "    if 'conn' in locals() and conn:\n",
        "        conn.close()\n",
        "        print(\"\\nSQLite 데이터베이스 연결이 해제되었습니다.\")\n",
        "except Exception as e:\n",
        "     print(f\"연결 해제 중 오류: {e}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ys4lPKspFcx7"
      },
      "source": [
        " # 3교시: 고급 SQL 활용 - 데이터 연결(JOIN) 및 그룹 분석(GROUP BY)\n",
        "\n",
        "\n",
        "\n",
        " ## 🎯 3교시 수업 목표\n",
        "\n",
        "\n",
        "\n",
        " 오늘 수업을 통해 여러분은 다음을 할 수 있게 됩니다:\n",
        "\n",
        "\n",
        "\n",
        " 1.  **`JOIN`** 의 필요성을 이해하고, **`INNER JOIN`** 과 **`LEFT JOIN`** 을 사용하여 **두 개 이상의 테이블 데이터를 연결**하여 조회하기. 🔗📊\n",
        "\n",
        " 2.  **서브쿼리(Subquery)** 의 기본 개념을 이해하고, 간단한 예시를 통해 활용 방법 파악하기. 🤔\n",
        "\n",
        " 3.  **집계 함수 (`COUNT`, `AVG`, `SUM`, `MAX`, `MIN`)** 를 사용하여 데이터의 **요약 정보**를 계산하기. 🧮\n",
        "\n",
        " 4.  **`GROUP BY`** 절을 사용하여 특정 열 기준으로 데이터를 **그룹화**하고, 그룹별 집계 결과 얻기. 👥📈\n",
        "\n",
        " 5.  **`HAVING`** 절을 사용하여 **그룹화된 결과**에 대한 **조건**을 적용하여 필터링하기. ✨\n",
        "\n",
        " 6.  **인덱싱(Indexing)** 이 **쿼리 성능 개선**에 왜 중요한지 설명하기 (개념적). ⚡️\n",
        "\n",
        "\n",
        "\n",
        " > ✨ **심화 목표**\n",
        "\n",
        " >\n",
        "\n",
        " > * `RIGHT JOIN`, `FULL OUTER JOIN` 등 다른 JOIN 유형의 차이점 이해하기.\n",
        "\n",
        " > * 다양한 집계 함수를 조합하여 복잡한 분석 쿼리 작성해보기.\n",
        "\n",
        " > * 인덱스의 종류와 생성 방법에 대해 알아보기."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaqaeQWOFcx7"
      },
      "source": [
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ## 📚 개념 설명 및 코드 실습: 여러 테이블 데이터 활용하기\n",
        "\n",
        "\n",
        "\n",
        " 이전 시간에는 주로 하나의 테이블 내에서 데이터를 다뤘습니다.\n",
        "\n",
        " 하지만 실제 데이터는 여러 테이블에 **정규화**되어 나뉘어 저장되는 경우가 많습니다.\n",
        "\n",
        " 이번 시간에는 이렇게 나뉜 데이터를 **연결(JOIN)** 하고, **그룹으로 묶어 분석(GROUP BY)** 하는 방법을 배웁니다.\n",
        "\n",
        "\n",
        "\n",
        " ### ✅ 실습 준비: 관련 있는 두 테이블 생성 및 데이터 삽입\n",
        "\n",
        "\n",
        "\n",
        " `JOIN`과 `GROUP BY` 실습을 위해, 사용자 정보(`users`) 테이블과 사용자 활동 로그(`user_logs`) 테이블을 생성하고 샘플 데이터를 넣겠습니다.\n",
        "\n",
        " (`user_logs` 테이블의 `user_id`는 `users` 테이블의 `id`를 참조하는 **외래 키(FK)** 관계입니다.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGco_lz-Fcx7"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "# 실습에 필요한 라이브러리 import 및 DB 연결 (이전 코드 재활용)\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "\n",
        "# 이전 실습의 conn 객체가 있다면 닫아줍니다.\n",
        "try:\n",
        "    if 'conn' in locals() and conn is not None:\n",
        "        try:\n",
        "            conn.execute(\"SELECT 1\") # 간단한 쿼리로 연결 상태 확인\n",
        "            conn.close()\n",
        "            print(\"이전 SQLite 연결을 닫았습니다.\")\n",
        "        except sqlite3.ProgrammingError:\n",
        "            print(\"이전 SQLite 연결이 이미 닫혔거나 유효하지 않습니다.\")\n",
        "except NameError:\n",
        "    pass # conn 객체가 정의되지 않은 경우 무시\n",
        "except Exception as e:\n",
        "    print(f\"이전 연결 처리 중 오류: {e}\")\n",
        "\n",
        "# 데이터베이스 연결 (메모리)\n",
        "conn = sqlite3.connect(':memory:')\n",
        "cursor = conn.cursor()\n",
        "print(\"SQLite 데이터베이스에 성공적으로 연결되었습니다 (in-memory).\")\n",
        "\n",
        "# 테이블 생성: users (사용자 정보)\n",
        "cursor.execute(\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS users (\n",
        "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    name TEXT NOT NULL,\n",
        "    age INTEGER,\n",
        "    country TEXT\n",
        ")\n",
        "\"\"\")\n",
        "print(\"`users` 테이블 준비 완료.\")\n",
        "\n",
        "# 테이블 생성: user_logs (사용자 활동 로그)\n",
        "cursor.execute(\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS user_logs (\n",
        "    log_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    user_id INTEGER,\n",
        "    action TEXT,\n",
        "    timestamp TEXT,\n",
        "    FOREIGN KEY (user_id) REFERENCES users (id) -- 외래 키 설정!\n",
        ")\n",
        "\"\"\")\n",
        "print(\"`user_logs` 테이블 준비 완료. (user_id는 users.id 참조)\")\n",
        "\n",
        "# 샘플 데이터 삽입: users\n",
        "users_data = [\n",
        "    ('민수', 25, 'Korea'), ('지우', 30, 'USA'), ('철수', 22, 'Korea'),\n",
        "    ('Alice', 28, 'USA'), ('Bob', 35, 'UK'), ('준호', 25, 'Korea') # 준호 추가\n",
        "]\n",
        "cursor.executemany(\"INSERT INTO users (name, age, country) VALUES (?, ?, ?)\", users_data)\n",
        "conn.commit()\n",
        "print(f\"{len(users_data)}명의 사용자 데이터 삽입 완료.\")\n",
        "\n",
        "# 샘플 데이터 삽입: user_logs (일부러 users 테이블에 없는 user_id(99) 포함)\n",
        "logs_data = [\n",
        "    (1, 'login', '2025-04-16 09:00:00'), (2, 'view', '2025-04-16 09:05:00'),\n",
        "    (1, 'post', '2025-04-16 09:10:00'), (3, 'login', '2025-04-16 09:15:00'),\n",
        "    (4, 'view', '2025-04-16 09:20:00'), (1, 'logout', '2025-04-16 09:25:00'),\n",
        "    (2, 'comment', '2025-04-16 09:30:00'), (5, 'login', '2025-04-16 09:35:00'),\n",
        "    (6, 'login', '2025-04-16 09:40:00'), # 준호(id=6) 로그\n",
        "    (99, 'error', '2025-04-16 09:50:00') # users 테이블에 없는 user_id\n",
        "]\n",
        "cursor.executemany(\"INSERT INTO user_logs (user_id, action, timestamp) VALUES (?, ?, ?)\", logs_data)\n",
        "conn.commit()\n",
        "print(f\"{len(logs_data)}개의 사용자 로그 데이터 삽입 완료.\")\n",
        "\n",
        "# 생성된 데이터 확인\n",
        "print(\"\\n--- users 테이블 데이터 ---\")\n",
        "print(pd.read_sql(\"SELECT * FROM users\", conn))\n",
        "print(\"\\n--- user_logs 테이블 데이터 ---\")\n",
        "print(pd.read_sql(\"SELECT * FROM user_logs\", conn))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QVuaPrHFcx7"
      },
      "source": [
        " ### 1. `JOIN`: 테이블 연결하기 🔗\n",
        "\n",
        "\n",
        "\n",
        " 정규화를 통해 여러 테이블로 분리된 데이터를 필요에 따라 **연결**하여 함께 조회해야 할 때 사용합니다.\n",
        "\n",
        " 두 테이블 간의 **관련 있는 열(보통 PK-FK 관계)** 을 기준으로 데이터를 합칩니다.\n",
        "\n",
        "\n",
        "\n",
        " * **필요성**: 분산된 정보를 모아 의미 있는 데이터셋 생성.\n",
        "\n",
        "     * 예: `user_logs`의 `user_id`만으로는 어떤 사용자인지 알기 어려움 → `users` 테이블과 연결(JOIN)하여 사용자 이름, 국가 등 정보 함께 조회 필요. 🔵\n",
        "\n",
        " * **JOIN 종류**: 기준 테이블과 연결 방식에 따라 여러 종류가 있음. (`INNER`, `LEFT`, `RIGHT`, `FULL OUTER` 등)\n",
        "\n",
        " * ![시각 자료 삽입: JOIN 종류별 Venn Diagram 비교](https://www.devkuma.com/docs/sql/sql_join1.png)\n",
        "\n",
        "\n",
        "\n",
        " #### `INNER JOIN` (내부 조인)\n",
        "\n",
        "\n",
        "\n",
        " * **개념**: 두 테이블 모두에 **연결 조건이 일치하는 행만** 결과에 포함. 가장 흔히 사용. 🤝\n",
        "\n",
        " * **구문**:\n",
        "\n",
        "   ```sql\n",
        "\n",
        "   SELECT t1.col1, t2.col2, ...\n",
        "\n",
        "   FROM table1 t1\n",
        "\n",
        "   INNER JOIN table2 t2 ON t1.linking_column = t2.linking_column; -- 연결 조건\n",
        "\n",
        "   ```\n",
        "\n",
        "   * `t1`, `t2`: 테이블 별칭(Alias). 테이블 이름이 길거나 같은 열 이름 구분 시 유용.\n",
        "\n",
        "   * `ON`: 두 테이블을 연결할 **조건**을 명시. (보통 `테이블1.FK = 테이블2.PK`)\n",
        "\n",
        " * **결과**: 양쪽 테이블에 모두 매칭되는 데이터만 나옴. 한쪽에만 있는 데이터는 제외. 🚫\n",
        "\n",
        "\n",
        "\n",
        " #### `LEFT JOIN` (왼쪽 외부 조인, LEFT OUTER JOIN)\n",
        "\n",
        "\n",
        "\n",
        " * **개념**: **왼쪽 테이블(FROM 절에 먼저 명시된 테이블)** 의 모든 행을 결과에 포함시키고, 오른쪽 테이블은 연결 조건이 일치하는 경우에만 데이터를 가져옴. 일치하는 데이터가 없으면 오른쪽 테이블의 열은 **NULL**로 표시. ⬅️ + 🤝\n",
        "\n",
        " * **구문**:\n",
        "\n",
        "   ```sql\n",
        "\n",
        "   SELECT t1.col1, t2.col2, ...\n",
        "\n",
        "   FROM table1 t1 -- 왼쪽 테이블\n",
        "\n",
        "   LEFT JOIN table2 t2 ON t1.linking_column = t2.linking_column;\n",
        "\n",
        "   ```\n",
        "\n",
        " * **결과**: 왼쪽 테이블 기준 모든 행 + 매칭되는 오른쪽 테이블 데이터 (없으면 NULL). 왼쪽 테이블에 없는 데이터는 제외.\n",
        "\n",
        " * **활용**: 기준 테이블의 모든 데이터를 유지하면서 연관 정보를 붙이고 싶을 때. (예: 모든 사용자의 로그 기록 조회, 로그 없으면 NULL) 🔵"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbELm2e1Fcx7"
      },
      "source": [
        " #### ✨ `INNER JOIN` 연습 ✨\n",
        "\n",
        "\n",
        "\n",
        " `user_logs` 테이블과 `users` 테이블을 **`INNER JOIN`** 하여, **로그 기록이 있는 사용자**의 **로그 ID(`log_id`), 사용자 이름(`name`), 활동(`action`)** 을 조회하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zo_Rt07FFcx7"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "# TODO: user_logs와 users 테이블을 user_id 기준으로 INNER JOIN하여\n",
        "#       log_id, name, action을 조회하는 쿼리를 작성하고 실행하세요.\n",
        "# 힌트: FROM user_logs INNER JOIN users ON user_logs.user_id = users.id\n",
        "inner_join_sql = \"\"\"\n",
        "    SQL 쿼리를 작성하세요.\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    print(\"\\n--- INNER JOIN 결과 (로그 기록 있는 사용자) ---\")\n",
        "    inner_join_df = pd.read_sql(inner_join_sql, conn)\n",
        "    print(inner_join_df)\n",
        "    # 결과 해석: user_logs에 user_id=99 로그는 있었지만, users 테이블에 id=99가 없으므로 결과에서 제외됨.\n",
        "except Exception as e:\n",
        "    print(f\"INNER JOIN 실행 중 오류: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTqISH9uFcx7"
      },
      "source": [
        " ### 코드예시"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T812iRhUFcx7"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "inner_join_sql = \"\"\"\n",
        "SELECT l.log_id, u.name, l.action\n",
        "FROM user_logs l -- user_logs 테이블 별칭 l\n",
        "INNER JOIN users u ON l.user_id = u.id; -- users 테이블 별칭 u, 연결 조건\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    print(\"\\n--- INNER JOIN 결과 (로그 기록 있는 사용자) ---\")\n",
        "    inner_join_df = pd.read_sql(inner_join_sql, conn)\n",
        "    print(inner_join_df)\n",
        "    # 결과 해석: user_logs에 user_id=99 로그는 있었지만, users 테이블에 id=99가 없으므로 결과에서 제외됨.\n",
        "except Exception as e:\n",
        "    print(f\"INNER JOIN 실행 중 오류: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__SK9MpUFcx7"
      },
      "outputs": [],
      "source": [
        "# %%\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEhVIjX9Fcx7"
      },
      "source": [
        " #### ✨ `LEFT JOIN` 연습 ✨\n",
        "\n",
        "\n",
        "\n",
        " **모든 사용자**의 정보(`id`, `name`)와, 각 사용자의 **로그 기록 ID(`log_id`) 및 활동(`action`)** 을 **`LEFT JOIN`** 으로 조회하세요.\n",
        "\n",
        " (로그 기록이 없는 사용자도 결과에 포함되어야 하며, 로그 정보는 NULL로 표시됩니다.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AsjX9NCuFcx7"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "# TODO: users 테이블을 기준으로 user_logs 테이블을 LEFT JOIN하여\n",
        "#       users.id, users.name, user_logs.log_id, user_logs.action 을 조회하세요.\n",
        "# 힌트: FROM users LEFT JOIN user_logs ON users.id = user_logs.user_id\n",
        "left_join_sql = \"\"\"\n",
        "    SQL 쿼리를 작성하세요.\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    print(\"\\n--- LEFT JOIN 결과 (모든 사용자 + 로그 정보) ---\")\n",
        "    left_join_df = pd.read_sql(left_join_sql, conn)\n",
        "    print(left_join_df)\n",
        "    # 결과 해석: users 테이블의 모든 사용자(id 1~6)가 나옴.\n",
        "    # 로그가 없는 사용자(예: 만약 있었다면)나 특정 로그가 없는 경우 log_id, action이 None (NULL)으로 표시됨.\n",
        "    # users 테이블에 없는 user_id=99 로그는 결과에 포함되지 않음.\n",
        "except Exception as e:\n",
        "    print(f\"LEFT JOIN 실행 중 오류: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x88qOGCDFcx7"
      },
      "source": [
        " ### 코드예시"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7IXuE1gqFcx7"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "left_join_sql = \"\"\"\n",
        "SELECT u.id, u.name, l.log_id, l.action\n",
        "FROM users u -- 왼쪽 테이블 users (별칭 u)\n",
        "LEFT JOIN user_logs l ON u.id = l.user_id; -- 오른쪽 테이블 user_logs (별칭 l)\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    print(\"\\n--- LEFT JOIN 결과 (모든 사용자 + 로그 정보) ---\")\n",
        "    left_join_df = pd.read_sql(left_join_sql, conn)\n",
        "    print(left_join_df)\n",
        "    # 결과 해석: users 테이블의 모든 사용자(id 1~6)가 나옴.\n",
        "    # 로그가 없는 사용자(예: 만약 있었다면)나 특정 로그가 없는 경우 log_id, action이 None (NULL)으로 표시됨.\n",
        "    # users 테이블에 없는 user_id=99 로그는 결과에 포함되지 않음.\n",
        "except Exception as e:\n",
        "    print(f\"LEFT JOIN 실행 중 오류: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExQzG8DzFcx7"
      },
      "source": [
        " ### 2. 서브쿼리 (Subquery) 🤔\n",
        "\n",
        "\n",
        "\n",
        " * **개념**: **다른 SQL 쿼리 내부에 포함된 또 다른 `SELECT` 쿼리**. 괄호 `()` 로 감싸서 사용. \"쿼리 안의 쿼리\".\n",
        "\n",
        " * **활용**:\n",
        "\n",
        "     * `WHERE` 절에서 비교 값으로 사용 (예: 평균 나이보다 많은 사용자 조회).\n",
        "\n",
        "     * `FROM` 절에서 임시 테이블처럼 사용 (인라인 뷰 Inline View).\n",
        "\n",
        "     * `SELECT` 절에서 스칼라 값(단일 값) 조회.\n",
        "\n",
        " * **예시 (`WHERE` 절 활용)**: 전체 사용자 평균 나이보다 많은 사용자의 이름 조회\n",
        "\n",
        "   ```sql\n",
        "\n",
        "   SELECT name\n",
        "\n",
        "   FROM users\n",
        "\n",
        "   WHERE age > (SELECT AVG(age) FROM users); -- 서브쿼리: 평균 나이 계산\n",
        "\n",
        "   ```\n",
        "\n",
        " * **장점**: 복잡한 로직을 단계적으로 표현 가능. 🔵\n",
        "\n",
        " * **단점**: 너무 복잡하거나 비효율적으로 사용 시 성능 저하 가능성. JOIN으로 해결 가능하면 JOIN이 더 나을 수도 있음. 🔴"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pX4TIGv2Fcx8"
      },
      "source": [
        " #### ✨ 서브쿼리 연습 (개념 이해) ✨\n",
        "\n",
        "\n",
        "\n",
        " 위 예시 쿼리(`WHERE` 절에 서브쿼리 사용)를 실행하여 평균 나이보다 많은 사용자를 찾아보세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HgBf6j-uFcx8"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "# TODO: 전체 사용자 평균 나이보다 나이가 많은 사용자의 이름과 나이를 조회하는 쿼리를\n",
        "#       서브쿼리를 사용하여 작성하고 실행하세요.\n",
        "subquery_sql = \"\"\"\n",
        "    SQL 쿼리를 작성하세요.\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    print(\"\\n--- 서브쿼리 연습 결과 (평균 나이 이상 사용자) ---\")\n",
        "    avg_age_users_df = pd.read_sql(subquery_sql, conn)\n",
        "    print(avg_age_users_df)\n",
        "\n",
        "    # 참고: 평균 나이 계산\n",
        "    # avg_age = pd.read_sql(\"SELECT AVG(age) FROM users\", conn).iloc[0,0]\n",
        "    # print(f\"(참고: 전체 평균 나이 = {avg_age:.2f})\")\n",
        "except Exception as e:\n",
        "    print(f\"서브쿼리 실행 중 오류: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v089R5jBFcx8"
      },
      "source": [
        " ### 코드예시"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tw8SAXinFcx8"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "subquery_sql = \"\"\"\n",
        "SELECT name\n",
        "FROM users\n",
        "WHERE age > (SELECT AVG(age) FROM users);\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    print(\"\\n--- 서브쿼리 연습 결과 (평균 나이 이상 사용자) ---\")\n",
        "    avg_age_users_df = pd.read_sql(subquery_sql, conn)\n",
        "    print(avg_age_users_df)\n",
        "\n",
        "    # 참고: 평균 나이 계산\n",
        "    # avg_age = pd.read_sql(\"SELECT AVG(age) FROM users\", conn).iloc[0,0]\n",
        "    # print(f\"(참고: 전체 평균 나이 = {avg_age:.2f})\")\n",
        "except Exception as e:\n",
        "    print(f\"서브쿼리 실행 중 오류: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1qRNY85Fcx8"
      },
      "source": [
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ## ❓ 퀴즈 1: JOIN 과 서브쿼리\n",
        "\n",
        "\n",
        "\n",
        " ### ✍️ 단답형/서술형 문제 1 (난이도: ⭐️⭐️⭐️)\n",
        "\n",
        "\n",
        "\n",
        " 1.  두 테이블 모두에 연결 조건이 일치하는 행만 결과에 포함시키는 JOIN은 무엇인가요? (단답형)\n",
        "\n",
        " 2.  `LEFT JOIN`과 `INNER JOIN`의 주요 차이점은 무엇인지, 어떤 기준으로 결과 행이 결정되는지 설명하세요. (서술형)\n",
        "\n",
        "\n",
        "\n",
        " ### <h3>정답 및 해설</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwZ4nZOGFcx8"
      },
      "source": [
        " 1.  **정답:** INNER JOIN (내부 조인)\n",
        "\n",
        " 2.  **정답:**\n",
        "\n",
        "     * **주요 차이점:** `INNER JOIN`은 두 테이블 모두에 매칭되는 데이터**만** 반환하는 반면, `LEFT JOIN`은 **왼쪽 테이블의 모든 행**을 기준으로 하고 오른쪽 테이블에서 매칭되는 데이터를 가져옵니다(없으면 NULL).\n",
        "\n",
        "     * **결정 기준:** `INNER JOIN`의 결과 행은 **양쪽 테이블 모두 ON 조건 만족** 여부에 따라 결정됩니다. `LEFT JOIN`의 결과 행은 **왼쪽 테이블 기준**으로 결정되며, 오른쪽 테이블 데이터 포함 여부만 ON 조건에 따라 달라집니다.\n",
        "\n",
        "\n",
        "\n",
        " ### 🚀 더 나아가기 (생각해보기)\n",
        "\n",
        "\n",
        "\n",
        " * 사용자(`users`)와 로그(`user_logs`) 테이블이 있을 때, \"로그를 한 번도 남기지 않은 사용자\"를 찾으려면 어떤 JOIN을 사용해야 할까요? (힌트: LEFT JOIN과 WHERE절 조합)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-W7J0m2vFcx8"
      },
      "source": [
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ## 📚 개념 설명 및 코드 실습: 데이터 그룹화 및 분석하기\n",
        "\n",
        "\n",
        "\n",
        " ### 1. 집계 함수 (Aggregate Functions) 🧮\n",
        "\n",
        "\n",
        "\n",
        " 여러 행의 데이터를 바탕으로 **하나의 요약된 값**을 계산하는 함수. `SELECT` 절이나 `HAVING` 절에서 주로 사용.\n",
        "\n",
        "\n",
        "\n",
        " #### 📊 주요 집계 함수\n",
        "\n",
        "\n",
        "\n",
        " | 함수        | 설명                               | 예시                                        |\n",
        " | :---------- | :--------------------------------- | :------------------------------------------ |\n",
        " | `COUNT()`   | 행의 **개수** 계산.                | `COUNT(*)` (전체 행), `COUNT(column)` (NULL 제외) |\n",
        " | `SUM()`     | 숫자 열의 **합계** 계산.           | `SUM(price)`                                |\n",
        " | `AVG()`     | 숫자 열의 **평균** 계산.           | `AVG(age)`                                  |\n",
        " | `MAX()`     | 열의 **최대값** 계산.              | `MAX(score)`                                |\n",
        " | `MIN()`     | 열의 **최소값** 계산.              | `MIN(timestamp)`                            |\n",
        "\n",
        "\n",
        "\n",
        " * **활용**: 전체 사용자 수 계산, 평균 구매 금액 계산, 최고/최저 점수 확인 등 데이터의 **전체적인 특징 파악**에 유용. 🔵"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dfF0ftmFcx8"
      },
      "source": [
        " #### ✨ 집계 함수 연습 ✨\n",
        "\n",
        "\n",
        "\n",
        " `users` 테이블을 사용하여 다음 정보를 계산해 보세요:\n",
        "\n",
        " 1.  전체 사용자 수 (`total_users`)\n",
        "\n",
        " 2.  사용자들의 평균 나이 (`average_age`)\n",
        "\n",
        " 3.  가장 많은 나이 (`max_age`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAy2Nt_UFcx8"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "# TODO: users 테이블에서 COUNT(*), AVG(age), MAX(age)를 계산하는 쿼리를 작성/실행하세요.\n",
        "agg_func_sql = \"\"\"\n",
        "    SQL 쿼리를 작성하세요.\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    print(\"\\n--- 집계 함수 연습 결과 ---\")\n",
        "    agg_results_df = pd.read_sql(agg_func_sql, conn)\n",
        "    print(agg_results_df)\n",
        "except Exception as e:\n",
        "    print(f\"집계 함수 실행 중 오류: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJJRAV6lFcx8"
      },
      "source": [
        " ### 코드예시"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2cCOlEceFcx8"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "agg_func_sql = \"\"\"\n",
        "SELECT\n",
        "    COUNT(*) AS total_users,\n",
        "    AVG(age) AS average_age,\n",
        "    MAX(age) AS max_age\n",
        "FROM users;\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDeRGQ4BFcx8"
      },
      "source": [
        " ### 2. `GROUP BY` 절: 데이터 그룹화 👥📈\n",
        "\n",
        "\n",
        "\n",
        " * **개념**: 특정 열(들)의 **값이 같은 행들을 하나의 그룹으로 묶는** 역할.\n",
        "\n",
        " * **활용**: 각 그룹에 대해 **집계 함수**를 적용하여 그룹별 통계 계산.\n",
        "\n",
        "     * 예: 국가별 사용자 수, 부서별 평균 급여, 상품 카테고리별 판매량 합계 등. 🔵\n",
        "\n",
        " * **구문**:\n",
        "\n",
        "   ```sql\n",
        "\n",
        "   SELECT group_column, aggregate_function(data_column)\n",
        "\n",
        "   FROM table_name\n",
        "\n",
        "   WHERE condition -- (1) 그룹화 전 필터링 (선택 사항)\n",
        "\n",
        "   GROUP BY group_column -- (2) 그룹화 기준 열\n",
        "\n",
        "   ORDER BY ... -- (4) 정렬 (선택 사항)\n",
        "\n",
        "   ```\n",
        "\n",
        " * ![시각 자료 삽입: GROUP BY 작동 방식 도식화 (그룹핑 -> 집계 함수 적용)](https://www.programiz.com/sites/tutorial2program/files/sql-group-by.png)\n",
        "\n",
        " * **주의**: `SELECT` 절에는 `GROUP BY` 기준 열과 집계 함수만 올 수 있음 (일반적으로). MySQL 등 일부 DB는 완화된 규칙 적용하기도 하나, 표준 SQL에서는 주의 필요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6BWFC2hFcx8"
      },
      "source": [
        " #### ✨ `GROUP BY` 연습 ✨\n",
        "\n",
        "\n",
        "\n",
        " `users` 테이블을 사용하여 **국가(`country`)별 사용자 수**를 계산하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6kW61WtBFcx8"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "# TODO: users 테이블을 country 기준으로 그룹화하고, 각 국가별 사용자 수를 COUNT(*)로 계산하세요.\n",
        "#       SELECT 절에는 country와 COUNT(*) 결과(user_count 별칭)가 와야 합니다.\n",
        "groupby_country_sql = \"\"\"\n",
        "    SQL 쿼리를 작성하세요.\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    print(\"\\n--- GROUP BY 국가별 사용자 수 결과 ---\")\n",
        "    country_count_df = pd.read_sql(groupby_country_sql, conn)\n",
        "    print(country_count_df)\n",
        "except Exception as e:\n",
        "    print(f\"GROUP BY 국가 실행 중 오류: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EytGeUs6Fcx9"
      },
      "source": [
        " ### 코드예시"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HiTXZtrFcx9"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "groupby_country_sql = \"\"\"\n",
        "SELECT\n",
        "    country,\n",
        "    COUNT(*) AS user_count\n",
        "FROM users\n",
        "GROUP BY country;\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWKElplOFcx9"
      },
      "source": [
        " #### ✨ `GROUP BY` + `JOIN` 연습 ✨\n",
        "\n",
        "\n",
        "\n",
        " `users` 테이블과 `user_logs` 테이블을 **JOIN** 한 후, **사용자 이름(`name`)별 로그 기록 수**를 계산하세요. (로그가 없는 사용자는 제외됨 - INNER JOIN 사용)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4iJ9cdnXFcx9"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "# TODO: users와 user_logs를 INNER JOIN 하고, 사용자 이름(name)으로 그룹화하여\n",
        "#       각 사용자의 로그 개수(log_count)를 COUNT(*)로 계산하세요.\n",
        "groupby_user_log_sql = \"\"\"\n",
        "    SQL 쿼리를 작성하세요.\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    print(\"\\n--- GROUP BY 사용자별 로그 수 결과 ---\")\n",
        "    user_log_count_df = pd.read_sql(groupby_user_log_sql, conn)\n",
        "    print(user_log_count_df)\n",
        "except Exception as e:\n",
        "    print(f\"GROUP BY 사용자 로그 실행 중 오류: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7vRTlnSFcx9"
      },
      "source": [
        " ### 코드예시"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gdH9lPkSFcx9"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "groupby_user_log_sql = \"\"\"\n",
        "SELECT\n",
        "    u.name,\n",
        "    COUNT(l.log_id) AS log_count -- COUNT(*) 또는 COUNT(l.log_id) 등 사용 가능\n",
        "FROM users u\n",
        "INNER JOIN user_logs l ON u.id = l.user_id\n",
        "GROUP BY u.name -- 사용자 이름 기준으로 그룹화\n",
        "ORDER BY log_count DESC; -- 로그 많은 순 정렬 (선택 사항)\n",
        "\"\"\"\n",
        "# ### 3. `HAVING` 절: 그룹 결과 필터링 ✨\n",
        "#\n",
        "# * **개념**: `GROUP BY`로 그룹화된 **결과**에 대해 **조건**을 적용하여 필터링.\n",
        "# * **`WHERE` vs. `HAVING`**:\n",
        "#     * `WHERE`: **그룹화 전(FROM/JOIN 직후)** 개별 행에 대한 조건 필터링. (1)\n",
        "#     * `HAVING`: **그룹화 후(GROUP BY 직후)** 그룹(집계 결과)에 대한 조건 필터링. (3)\n",
        "# * **구문**:\n",
        "#   ```sql\n",
        "#   SELECT group_column, aggregate_function(data_column)\n",
        "#   FROM table_name\n",
        "#   WHERE condition -- (1) 개별 행 필터링\n",
        "#   GROUP BY group_column -- (2) 그룹화\n",
        "#   HAVING aggregate_condition -- (3) 그룹 결과 필터링\n",
        "#   ORDER BY ... -- (4) 정렬\n",
        "#   ```\n",
        "# * **활용**: \"평균 나이가 30세 이상인 국가\", \"로그 수가 2개 이상인 사용자\" 등 그룹 통계 기반 필터링. 🔵\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhRAY1TGFcx9"
      },
      "source": [
        " #### ✨ `GROUP BY` + `HAVING` 연습 ✨\n",
        "\n",
        "\n",
        "\n",
        " `users` 테이블에서, **사용자 수가 2명 이상인 국가(`country`)** 만 조회하고 해당 국가의 **사용자 수**를 함께 출력하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7kzS72sFcx9"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "# TODO: users 테이블을 country로 그룹화하고, HAVING 절을 사용하여\n",
        "#       사용자 수(COUNT(*))가 2 이상인 그룹만 필터링하여 country와 user_count를 조회하세요.\n",
        "groupby_having_sql = \"\"\"\n",
        "    SQL 쿼리를 작성하세요.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    print(\"\\n--- HAVING 연습 (사용자 2명 이상 국가) 결과 ---\")\n",
        "    having_df = pd.read_sql(groupby_having_sql, conn)\n",
        "    print(having_df)\n",
        "except Exception as e:\n",
        "    print(f\"HAVING 실행 중 오류: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckPhrP6QFcx9"
      },
      "source": [
        " ### 코드예시"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZr9-KMHFcx9"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "groupby_having_sql = \"\"\"\n",
        "SELECT\n",
        "    country,\n",
        "    COUNT(*) AS user_count\n",
        "FROM users\n",
        "GROUP BY country\n",
        "HAVING COUNT(*) >= 2; -- 그룹 결과(user_count)에 대한 조건\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    print(\"\\n--- HAVING 연습 (사용자 2명 이상 국가) 결과 ---\")\n",
        "    having_df = pd.read_sql(groupby_having_sql, conn)\n",
        "    print(having_df)\n",
        "except Exception as e:\n",
        "    print(f\"HAVING 실행 중 오류: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rGyoq9sFcx9"
      },
      "source": [
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ## 💻 실습 2: AI 데이터 분석 (사용자 그룹별 로그 수 집계)\n",
        "\n",
        "\n",
        "\n",
        " **요구사항**:\n",
        "\n",
        "\n",
        "\n",
        " `users` 테이블과 `user_logs` 테이블을 사용하여 다음 분석을 수행하세요.\n",
        "\n",
        " 1.  국가(`country`)가 'Korea'인 사용자들의 로그 기록만 대상으로 합니다. (`WHERE`)\n",
        "\n",
        " 2.  각 사용자의 이름(`name`) 별로 로그 기록 수(`log_count`)를 집계합니다. (`GROUP BY`, `COUNT`)\n",
        "\n",
        " 3.  로그 기록 수가 1개를 초과하는 사용자만 필터링합니다. (`HAVING`)\n",
        "\n",
        " 4.  결과는 사용자 이름 순서로 정렬합니다. (`ORDER BY`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kmloYJLxFcx9"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "# TODO: 위 4가지 요구사항을 만족하는 SQL 쿼리를 작성하고 실행하세요.\n",
        "\n",
        "ai_analysis_sql = \"\"\"\n",
        "    SQL 쿼리를 작성하세요.\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    print(\"\\n--- [실습 2] AI 데이터 분석 결과 ---\")\n",
        "    print(\"(한국 사용자 중 로그 1개 초과 기록한 사람)\")\n",
        "    ai_analysis_df = pd.read_sql(ai_analysis_sql, conn)\n",
        "    print(ai_analysis_df)\n",
        "except Exception as e:\n",
        "    print(f\"AI 데이터 분석 실행 중 오류: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVb02ztpFcx9"
      },
      "source": [
        " ### 코드예시"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hiJKGHWFcx9"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "ai_analysis_sql = \"\"\"\n",
        "SELECT\n",
        "    u.name,\n",
        "    COUNT(l.log_id) AS log_count\n",
        "FROM users u\n",
        "INNER JOIN user_logs l ON u.id = l.user_id -- 1. 사용자 정보와 로그 정보 결합\n",
        "WHERE u.country = 'Korea' -- 2. 한국 사용자 필터링 (그룹화 전)\n",
        "GROUP BY u.name -- 3. 사용자 이름으로 그룹화\n",
        "HAVING COUNT(l.log_id) > 1 -- 4. 로그 수가 1개 초과인 그룹만 필터링 (그룹화 후)\n",
        "ORDER BY u.name; -- 5. 이름 순 정렬\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    print(\"\\n--- [실습 2] AI 데이터 분석 결과 ---\")\n",
        "    print(\"(한국 사용자 중 로그 1개 초과 기록한 사람)\")\n",
        "    ai_analysis_df = pd.read_sql(ai_analysis_sql, conn)\n",
        "    print(ai_analysis_df)\n",
        "except Exception as e:\n",
        "    print(f\"AI 데이터 분석 실행 중 오류: {e}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKIQRR-ZFcx9"
      },
      "source": [
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ## 📚 개념 설명: 인덱싱 (Indexing) - 쿼리 속도 올리기! ⚡️\n",
        "\n",
        "\n",
        "\n",
        " * **개념**: 테이블에서 데이터 **검색 속도를 높이기 위해** 특정 열(들)의 값과 해당 행의 위치 정보를 미리 **정렬된 형태로 저장**해 두는 구조. 책의 **색인(Index)** 과 유사한 역할. 📖\n",
        "\n",
        " * **작동 원리**:\n",
        "\n",
        "     * `WHERE` 절이나 `JOIN` 조건에서 특정 값을 찾을 때, 테이블 전체를 순차적으로 스캔(Full Table Scan 🐌🔴)하는 대신, **정렬된 인덱스**를 먼저 탐색하여 해당 데이터의 위치를 빠르게 찾아냄 (Index Seek/Scan 🚀🔵).\n",
        "\n",
        " * **장점**:\n",
        "\n",
        "     * `SELECT` 쿼리(특히 `WHERE`, `JOIN` 조건 있는) **성능 대폭 향상**. 🚀\n",
        "\n",
        "     * 데이터 정렬(`ORDER BY`) 성능 향상에도 도움.\n",
        "\n",
        " * **단점**:\n",
        "\n",
        "     * 인덱스 저장을 위한 **추가 저장 공간** 필요. 💾\n",
        "\n",
        "     * `INSERT`, `UPDATE`, `DELETE` 시 인덱스도 **갱신**해야 하므로 해당 작업 **성능 저하** 가능성. 🐌🔴 (Trade-off 존재!)\n",
        "\n",
        " * **언제 사용할까?**\n",
        "\n",
        "     * 테이블 크기가 크고 `SELECT` 작업이 빈번할 때. 🔵\n",
        "\n",
        "     * `WHERE` 절이나 `JOIN` 조건에 **자주 사용되는 열**에 생성. (예: `user_id`, `email`, `product_code`) 🔵\n",
        "\n",
        "     * 데이터 변경(쓰기)보다 조회(읽기) 작업이 훨씬 많을 때. 🔵\n",
        "\n",
        " * **주의**:\n",
        "\n",
        "     * 너무 많은 인덱스는 오히려 성능 저하 및 관리 부담 증가. 🔴\n",
        "\n",
        "     * 데이터 분포도(Cardinality)가 낮은 열(예: 성별)에는 효과 적음.\n",
        "\n",
        "     * **기본 키(PK)** 는 대부분의 DB에서 자동으로 인덱스 생성됨. ✨\n",
        "\n",
        "\n",
        "\n",
        " * ![시각 자료 삽입: 인덱스 유무에 따른 데이터 검색 과정 비교 그림](https://velog.velcdn.com/images%2Fguswns3371%2Fpost%2Fdcb61735-e5a1-46f3-a206-89898a4ec9e0%2Fimage.png)\n",
        "\n",
        "\n",
        "\n",
        " > **AI 연관성**: 대규모 학습 데이터셋에서 특정 조건의 데이터를 빠르게 필터링하거나,\n",
        "\n",
        " > 사용자 로그 분석 시 특정 사용자 활동을 신속하게 조회하는 등 AI 관련 작업에서\n",
        "\n",
        " > **데이터 처리 속도**는 매우 중요. 인덱싱은 이를 위한 핵심 최적화 기법 중 하나! 🚀"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4Ck5aNmFcx9"
      },
      "source": [
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ## ❓ 퀴즈 2: 그룹화와 필터링\n",
        "\n",
        "\n",
        "\n",
        " ### 🧐 객관식 문제 2 (난이도: ⭐️⭐️⭐️)\n",
        "\n",
        "\n",
        "\n",
        " SQL 쿼리에서 `WHERE` 절과 `HAVING` 절의 주요 차이점에 대한 설명으로 **가장 올바른** 것은?\n",
        "\n",
        "\n",
        "\n",
        " 1.  `WHERE`는 그룹화 후에, `HAVING`은 그룹화 전에 조건을 적용한다.\n",
        "\n",
        " 2.  `WHERE`는 집계 함수에 대한 조건을, `HAVING`은 개별 행에 대한 조건을 적용한다.\n",
        "\n",
        " 3.  `WHERE`는 `GROUP BY` 없이 사용할 수 없지만, `HAVING`은 단독으로 사용할 수 있다.\n",
        "\n",
        " 4.  `WHERE`는 개별 행을 필터링하고, `HAVING`은 `GROUP BY`로 그룹화된 결과를 필터링한다.\n",
        "\n",
        " 5.  `WHERE`는 `SELECT` 문에서만, `HAVING`은 `UPDATE` 문에서만 사용할 수 있다.\n",
        "\n",
        "\n",
        "\n",
        " ### <h3>정답 및 해설</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPAqpFIzFcx9"
      },
      "source": [
        " **정답: 4번**\n",
        "\n",
        "\n",
        "\n",
        " **해설:**\n",
        "\n",
        " SQL 쿼리 실행 순서를 생각해보면 이해하기 쉽습니다. (FROM → WHERE → GROUP BY → HAVING → SELECT → ORDER BY)\n",
        "\n",
        " * `WHERE` 절은 테이블에서 데이터를 가져와 그룹화하기 **전**에 개별 행에 대한 조건을 적용하여 필터링합니다.\n",
        "\n",
        " * `HAVING` 절은 `GROUP BY`로 데이터가 그룹화된 **후**에, 그룹별 집계 결과(예: `COUNT(*)`, `AVG(age)`)에 대한 조건을 적용하여 그룹 자체를 필터링합니다.\n",
        "\n",
        "\n",
        "\n",
        " 1. 순서가 반대입니다. 🔴\n",
        "\n",
        " 2. 역할이 반대입니다. 🔴 (`WHERE`는 개별 행, `HAVING`은 집계 함수 결과)\n",
        "\n",
        " 3. `WHERE`는 `GROUP BY` 없이 단독 사용 가능하지만, `HAVING`은 일반적으로 `GROUP BY`와 함께 사용됩니다. (예외 경우도 있으나 일반적이지 않음) 🔴\n",
        "\n",
        " 5. 둘 다 주로 `SELECT` 문에서 필터링 목적으로 사용됩니다. 🔴\n",
        "\n",
        "\n",
        "\n",
        " ### 🚀 더 나아가기 (생각해보기)\n",
        "\n",
        "\n",
        "\n",
        " * \"평균 나이가 25세 이상인 국가 중에서, 'Korea'를 제외한 국가들의 사용자 수\"를 계산하려면 `WHERE`와 `HAVING`을 각각 어떻게 사용해야 할까요?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DqACVx2Fcx9"
      },
      "source": [
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ## ❓ F.A.Q (3교시 궁금증 해소)\n",
        "\n",
        "\n",
        "\n",
        " * **Q1: `JOIN`이랑 서브쿼리랑 비슷한 것 같은데, 언제 뭘 써야 하나요?**\n",
        "\n",
        "     * **A1**: 둘 다 여러 테이블 정보를 활용하지만, 사용 방식과 목적이 조금 다릅니다.\n",
        "\n",
        "         * **`JOIN`**: 두 테이블을 **수평적으로 연결**하여 양쪽 테이블의 컬럼을 함께 보고 싶을 때 주로 사용. **관계** 기반 데이터 결합. 🔵 (예: 사용자 정보 + 해당 사용자의 로그 정보)\n",
        "\n",
        "         * **서브쿼리**: 다른 쿼리의 **결과를 활용**하여 현재 쿼리의 조건이나 대상을 지정하고 싶을 때 사용. (예: 평균 나이 계산 → 평균보다 나이 많은 사람 찾기)\n",
        "\n",
        "         * **선택**: 가독성, 성능 등을 고려. 간단한 연결은 `JOIN`이 직관적일 때가 많고, 복잡한 조건 필터링 등은 서브쿼리가 유용할 수 있음. 때로는 서로 대체 가능.\n",
        "\n",
        "\n",
        "\n",
        " * **Q2: `HAVING`은 꼭 `GROUP BY`랑 같이 써야 하나요?**\n",
        "\n",
        "     * **A2**: **거의 항상** 그렇습니다. 🔵 `HAVING`의 목적 자체가 그룹화된 결과에 조건을 거는 것이기 때문입니다. `GROUP BY` 없이 `HAVING`을 쓰면 전체 테이블을 하나의 그룹으로 보고 집계 함수 조건을 거는 것과 유사하게 동작하지만(DB마다 동작 상이 가능), 매우 드문 경우입니다. **`HAVING`은 `GROUP BY`의 파트너**라고 생각하는 것이 좋습니다.\n",
        "\n",
        "\n",
        "\n",
        " * **Q3: 인덱스는 왜 빠른가요? 그냥 다 검색하면 안되나요?**\n",
        "\n",
        "     * **A3**: 책에서 특정 단어를 찾을 때, 처음부터 끝까지 한 페이지씩 넘기는 것(Full Scan 🐌🔴)과 맨 뒤 색인(Index 🚀🔵)을 보고 해당 페이지로 바로 가는 것의 차이를 생각해보세요! 인덱스는 **데이터를 미리 정렬**해두고 **빠른 탐색 알고리즘**(예: B-Tree)을 사용하여 원하는 데이터의 **위치를 신속하게** 찾습니다. 테이블 전체를 읽는 것보다 훨씬 효율적입니다. 데이터가 수백만, 수억 건이 되면 이 차이는 엄청나게 커집니다.\n",
        "\n",
        "\n",
        "\n",
        " * **Q4: 집계 함수는 `COUNT` 말고 또 뭐가 자주 쓰이나요?**\n",
        "\n",
        "     * **A4**: `COUNT`(개수), `SUM`(합계), `AVG`(평균), `MAX`(최대값), `MIN`(최소값)이 가장 기본적이고 널리 쓰입니다. 🔵 이 외에도 표준편차(`STDEV`), 분산(`VAR`) 등 통계 함수나 DB별 특화된 집계 함수들이 있습니다.\n",
        "\n",
        "\n",
        "\n",
        " * **Q5: `LEFT JOIN` 말고 `RIGHT JOIN`도 있나요?**\n",
        "\n",
        "     * **A5**: 네, 있습니다! 🔗 `RIGHT JOIN`은 `LEFT JOIN`과 반대로 **오른쪽 테이블 기준**으로 모든 행을 포함하고 왼쪽 테이블에서 매칭되는 데이터를 가져옵니다. `FULL OUTER JOIN`은 양쪽 테이블의 모든 행을 포함하고 매칭 안되면 NULL로 채웁니다. 하지만 `LEFT JOIN`이 가장 흔하게 사용되며, 테이블 순서를 바꾸면 `RIGHT JOIN`과 같은 결과를 얻을 수 있는 경우가 많습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OXJEZ4zFcx9"
      },
      "source": [
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ## 🔑 3교시 핵심 정리\n",
        "\n",
        "\n",
        "\n",
        " * **`JOIN`**: 여러 테이블 **데이터 연결** 핵심. 🔗\n",
        "\n",
        "     * **`INNER JOIN`**: 양쪽 테이블에 **모두 매칭**되는 행만 결과 포함. 🤝\n",
        "\n",
        "     * **`LEFT JOIN`**: **왼쪽 테이블 기준** 모든 행 포함 (매칭 안되면 NULL). ⬅️+🤝\n",
        "\n",
        "     * **`ON`**: Join **연결 조건** 명시 (보통 PK=FK).\n",
        "\n",
        " * **서브쿼리**: 쿼리 안의 쿼리. 다른 쿼리 결과를 **조건 등으로 활용**. 🤔\n",
        "\n",
        " * **집계 함수**: 여러 행 → **하나의 요약 값** 계산. 🧮 (`COUNT`, `SUM`, `AVG`, `MAX`, `MIN` 등)\n",
        "\n",
        " * **`GROUP BY`**: 특정 열 기준 **데이터 그룹화**. 👥📈 그룹별 집계 함수 적용 가능.\n",
        "\n",
        " * **`HAVING`**: **그룹화된 결과**에 대한 **조건 필터링**. ✨ (`WHERE`는 그룹화 전 개별 행 필터링)\n",
        "\n",
        " * **인덱싱 (Indexing)**: **검색 속도 향상** 핵심. ⚡️ (`SELECT` 성능 개선 🚀 vs 쓰기 성능 저하 🐌 / 추가 공간 필요)\n",
        "\n",
        " * **AI 활용**: `JOIN`(Feature 생성), `GROUP BY`(패턴 분석), `Indexing`(대규모 데이터 처리 속도) 중요. 🤖"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2xkgNuwFcx9"
      },
      "source": [
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ## 💭 3교시 마무리\n",
        "\n",
        "\n",
        "\n",
        " 이번 시간에는 여러 테이블에 흩어진 데이터를 효과적으로 **연결(`JOIN`)** 하고, 데이터를 **그룹으로 묶어 분석(`GROUP BY`, 집계 함수)** 하는 고급 SQL 기법들을 배웠습니다. 그룹화된 결과에 조건을 적용하는 **`HAVING`** 절과 쿼리 성능 개선의 핵심인 **`인덱싱`** 개념도 살펴보았습니다. 간단한 **서브쿼리** 활용법도 맛보았습니다.\n",
        "\n",
        "\n",
        "\n",
        " 특히 `JOIN`과 `GROUP BY`는 AI 모델 학습을 위한 **데이터 전처리(Feature Engineering)** 나 서비스 운영 중 **데이터 분석**에 매우 빈번하게 사용되는 중요한 기술입니다. 오늘 배운 내용을 바탕으로 더 복잡하고 의미 있는 데이터 분석 쿼리를 작성하는 연습을 꾸준히 하시길 바랍니다.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " ### 🚀 더 나아가기 (3교시 복습)\n",
        "\n",
        "\n",
        "\n",
        " * `users` 테이블과 `user_logs` 테이블을 사용하여, \"가장 최근에 로그인한 사용자의 이름\"을 찾는 쿼리를 서브쿼리와 `MAX()` 함수를 조합하여 작성해보세요.\n",
        "\n",
        " * `user_logs` 테이블에 `action` 컬럼에 대한 인덱스를 생성하면 어떤 종류의 쿼리 성능이 향상될지 예상해보세요. (실제 인덱스 생성은 `CREATE INDEX ...` 구문 사용)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hfv1UTwgFcx-"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "# 실습 종료 후 데이터베이스 연결 해제\n",
        "try:\n",
        "    if 'conn' in locals() and conn:\n",
        "        conn.close()\n",
        "        print(\"\\nSQLite 데이터베이스 연결이 해제되었습니다.\")\n",
        "except Exception as e:\n",
        "     print(f\"연결 해제 중 오류: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0u3lFJdDFcx-"
      },
      "source": [
        " # 4교시: NoSQL 데이터베이스 - 유연한 데이터 관리 (MongoDB 예시)\n",
        "\n",
        "\n",
        "\n",
        " ## 🎯 4교시 수업 목표\n",
        "\n",
        "\n",
        "\n",
        " 오늘 수업을 통해 여러분은 다음을 할 수 있게 됩니다:\n",
        "\n",
        "\n",
        "\n",
        " 1.  **NoSQL 데이터베이스**가 등장한 배경과 **RDBMS와의 주요 차이점**(스키마 유연성, 확장성) 설명하기. 🤔🆚\n",
        "\n",
        " 2.  **문서형(Document)** 및 **키-값(Key-Value)** 등 주요 NoSQL 데이터베이스 유형의 **특징**과 **용도** 설명하기. 📄🔑\n",
        "\n",
        " 3.  **AI 서비스**에서 NoSQL 데이터베이스가 **어떤 종류의 데이터**(비정형 로그, 실시간 데이터 등) 처리에 유용한지 예시 들기. 🤖💬\n",
        "\n",
        " 4.  **Python 딕셔너리**를 사용하여 **MongoDB 문서(Document)** 구조를 표현하고 생성하기. 🐍✍️\n",
        "\n",
        " 5.  MongoDB의 기본 구성 요소(**Collection**, **Document**)와 기본 작업(**CRUD**) 개념 이해하기. 🧱⚙️\n",
        "\n",
        "\n",
        "\n",
        " > ✨ **심화 목표**\n",
        "\n",
        " >\n",
        "\n",
        " > * MongoDB 와 Redis의 사용 사례를 비교하고, 언제 어떤 것을 선택하는 것이 더 적합할지 판단하기.\n",
        "\n",
        " > * Python `pymongo` 라이브러리를 사용하여 MongoDB에 연결하고 기본적인 데이터 조작(삽입, 조회) 코드 작성해보기 (선택적 환경 설정 필요).\n",
        "\n",
        " > * NoSQL 데이터베이스의 CAP 정리(Theorem) 개념 이해하기."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8m22ormFcx-"
      },
      "source": [
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ## 📚 개념 설명 (핵심 요약)\n",
        "\n",
        "\n",
        "\n",
        " ### 1. NoSQL 데이터베이스: 왜 필요할까? 🤔🆚 RDBMS\n",
        "\n",
        "\n",
        "\n",
        " 이전까지 우리는 주로 관계형 데이터베이스(RDB)를 다뤘습니다. RDB는 정해진 구조(스키마)에 따라 데이터를 체계적으로 관리하는 데 매우 강력합니다. 하지만 모든 데이터가 깔끔한 표 형태로 딱 떨어지는 것은 아니며, 현대 웹 서비스와 AI 환경에서는 RDB만으로는 해결하기 어려운 문제들이 등장했습니다.\n",
        "\n",
        "\n",
        "\n",
        " * **RDBMS의 한계점 (특정 상황에서)**:\n",
        "\n",
        "     * **스키마 변경 어려움**: 데이터 구조를 바꾸려면 `ALTER TABLE` 등 복잡한 작업 필요. 변화 잦은 서비스에는 부담. 🔴\n",
        "\n",
        "     * **수평적 확장(Scale-out)의 어려움**: 사용자/데이터 폭증 시 여러 서버로 분산하기가 상대적으로 복잡. (Scale-up은 비용 한계) 🔴\n",
        "\n",
        "     * **비정형/반정형 데이터 처리**: 로그, 소셜 미디어 글, 센서 데이터 등 형태가 일정하지 않은 데이터 저장/관리에 부적합. 🔴\n",
        "\n",
        "\n",
        "\n",
        " * **NoSQL (Not Only SQL) 등장 배경**:\n",
        "\n",
        "     * 위와 같은 RDBMS의 한계를 극복하고, **대규모 데이터 처리**, **유연한 데이터 모델링**, **높은 가용성/확장성** 요구에 부응하기 위해 등장. 🚀\n",
        "\n",
        "     * \"SQL만 사용하는 것이 아니다\" 라는 의미. (일부는 SQL 유사 언어 사용)\n",
        "\n",
        "\n",
        "\n",
        " #### 📊 RDBMS vs. NoSQL 비교 (주요 특징)\n",
        "\n",
        "\n",
        "\n",
        " | 특징             | RDBMS (예: MySQL, SQLite)    | NoSQL (예: MongoDB, Redis)       | 설명                                                 |\n",
        "\n",
        " | :--------------- | :--------------------------- | :------------------------------- | :--------------------------------------------------- |\n",
        "\n",
        " | **데이터 모델** | **관계형 (표)** | 문서형, Key-Value, 컬럼형, 그래프형 등 | 다양한 데이터 구조 지원 (NoSQL)                     |\n",
        "\n",
        " | **스키마** | **엄격함 (Fixed)** | **유연함 (Flexible) / 없음** | 데이터 구조 변경 용이 (NoSQL) 🔵                     |\n",
        "\n",
        " | **확장성** | 주로 수직적 확장 (Scale-up)  | 주로 **수평적 확장 (Scale-out)** | 대규모 트래픽/데이터 처리 용이 (NoSQL) 🚀              |\n",
        "\n",
        " | **일관성 (Consistency)** | **강력** (ACID 보장)       | **결과적 일관성 (Eventual)** 등  | 일관성 수준 조절 가능 (NoSQL, Trade-off 존재) ⚠️   |\n",
        "\n",
        " | **데이터 종류** | **정형 데이터** 최적화       | **비정형/반정형/정형** 모두 가능 | 다양한 형태의 데이터 저장 용이 (NoSQL) 🔵            |\n",
        "\n",
        " | **쿼리 언어** | **SQL** (표준)             | DB별 다양한 API / 쿼리 언어      | SQL 외 다양한 인터페이스 사용 (NoSQL)              |\n",
        "\n",
        "\n",
        "\n",
        "   ![시각 자료 삽입: RDBMS Scale-up vs NoSQL Scale-out 비교 그림](https://cdn.hashnode.com/res/hashnode/image/upload/v1670473871742/e3MaJEtZd.png?auto=compress,format&format=webp)\n",
        "\n",
        "\n",
        "\n",
        " * **AI에서의 NoSQL 활용 사례**:\n",
        "\n",
        "     * **비정형/반정형 데이터 저장**: AI 모델 학습/분석용 **로그 데이터**, **센서 데이터**, **텍스트 데이터**(소셜 미디어 글, 기사) 등 저장. 📄\n",
        "\n",
        "     * **빠른 프로토타이핑**: 스키마를 미리 엄격하게 정의할 필요 없어 초기 개발 속도 향상. ⚡️\n",
        "\n",
        "     * **대규모 확장성**: 수백만 사용자 서비스의 데이터 처리, 실시간 AI 추천/분석 등 **확장성**이 중요한 시스템. 📈\n",
        "\n",
        "     * **캐싱**: 자주 접근하는 데이터를 메모리 기반 Key-Value 스토어(Redis)에 저장하여 DB 부하 줄이고 응답 속도 향상. 💨"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJgH8R3YFcx-"
      },
      "source": [
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ## ❓ 퀴즈 1: NoSQL 적합 시나리오\n",
        "\n",
        "\n",
        "\n",
        " ### 🧐 객관식 문제 1 (난이도: ⭐️⭐️⭐️)\n",
        "\n",
        "\n",
        "\n",
        " 다음 중 NoSQL 데이터베이스를 사용하는 것이 RDBMS보다 **더 적합할 가능성이 높은** 시나리오는 무엇인가요?\n",
        "\n",
        "\n",
        "\n",
        " 1.  은행의 계좌 거래 내역처럼 데이터의 정확성과 일관성이 매우 중요한 시스템.\n",
        "\n",
        " 2.  미리 정의된 명확한 구조를 가진 사용자 회원 정보 관리 시스템.\n",
        "\n",
        " 3.  서비스 이용 형태에 따라 저장되는 내용이 사용자마다 다른, 게임 사용자 프로필 데이터 저장.\n",
        "\n",
        " 4.  회사의 부서 정보와 직원 정보 간의 관계를 명확히 표현해야 하는 인사 관리 시스템.\n",
        "\n",
        " 5.  데이터 구조가 거의 변하지 않는 제품 카탈로그 정보 관리.\n",
        "\n",
        "\n",
        "\n",
        " ### <h3>정답 및 해설</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3O3KnsbUFcx-"
      },
      "source": [
        " **정답: 3번**\n",
        "\n",
        "\n",
        "\n",
        " **해설:**\n",
        "\n",
        " 게임 사용자 프로필처럼 저장되는 정보(예: 보유 아이템, 레벨, 친구 목록 등)가 사용자마다 다르고, 서비스가 업데이트되면서 구조가 자주 바뀔 수 있는 경우에는 **스키마 유연성**이 높은 NoSQL(특히 문서형 DB)이 RDBMS보다 유리합니다. 🔵\n",
        "\n",
        " 1, 2, 4, 5번은 데이터 구조가 비교적 명확하고, 데이터 간 관계나 일관성 유지가 중요하므로 RDBMS가 더 적합한 시나리오입니다.\n",
        "\n",
        "\n",
        "\n",
        " ### 🚀 더 나아가기 (생각해보기)\n",
        "\n",
        "\n",
        "\n",
        " * 만약 여러분이 실시간으로 변하는 주식 가격 데이터를 저장하고 빠르게 조회해야 한다면, 어떤 종류의 NoSQL 데이터베이스가 적합할 수 있을까요? (힌트: 빠른 읽기/쓰기)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gf0j7nkAFcx-"
      },
      "source": [
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ## 📚 개념 설명: 주요 NoSQL 유형 소개\n",
        "\n",
        "\n",
        "\n",
        " NoSQL 데이터베이스는 데이터를 저장하고 관리하는 방식에 따라 여러 유형으로 나뉩니다.\n",
        "\n",
        " 그중 대표적인 두 가지 유형을 살펴보겠습니다.\n",
        "\n",
        "\n",
        "\n",
        " ### 1. 문서형 데이터베이스 (Document Database) 📄\n",
        "\n",
        "\n",
        "\n",
        " * **핵심 개념**: 데이터를 **JSON 또는 BSON(Binary JSON)** 과 유사한 **문서(Document)** 형태로 저장. 각 문서는 **필드(Field)-값(Value)** 쌍으로 구성.\n",
        "\n",
        " * **특징**:\n",
        "\n",
        "     * **유연한 스키마**: 각 문서가 서로 다른 구조(필드)를 가질 수 있음. 🔵 서비스 요구사항 변화에 유연하게 대처 가능.\n",
        "\n",
        "     * **개별 문서 단위 처리**: 문서 하나가 독립적인 데이터 단위로 취급됨.\n",
        "\n",
        "     * **내장된(Nested) 구조 표현 용이**: 문서 안에 다른 문서나 배열 포함 가능. 객체 지향적 데이터 표현에 유리. 🔵\n",
        "\n",
        "     * **쿼리**: 문서 내 필드 값이나 구조를 기반으로 쿼리 가능 (예: 특정 필드가 특정 값인 문서 찾기).\n",
        "\n",
        " * **대표 주자**: **MongoDB** ✨ (가장 널리 사용되는 문서 DB), Couchbase\n",
        "\n",
        " * **AI 활용 예시**: 사용자 프로필, 콘텐츠 관리(블로그 글, 상품 정보), IoT 장비 정보, 게임 데이터 등 스키마가 유동적이거나 복잡한 계층 구조 데이터.\n",
        "\n",
        "\n",
        "\n",
        " ### 2. 키-값 데이터베이스 (Key-Value Database) 🔑\n",
        "\n",
        "\n",
        "\n",
        " * **핵심 개념**: 고유한 **키(Key)** 와 그에 해당하는 **값(Value)** 을 쌍으로 저장하는 가장 단순한 형태.\n",
        "\n",
        " * **특징**:\n",
        "\n",
        "     * **단순함**: 데이터 구조가 매우 단순하고 이해하기 쉬움. 🔵\n",
        "\n",
        "     * **빠른 속도**: 특정 키에 대한 값 조회/저장 속도가 매우 빠름. 🚀 (메모리 기반인 경우 특히)\n",
        "\n",
        "     * **확장성**: 구조가 단순하여 수평적 확장이 용이. 🔵\n",
        "\n",
        "     * **값(Value)의 유연성**: 값 부분에는 문자열, 숫자 뿐 아니라 복잡한 객체(직렬화된 형태) 등 무엇이든 저장 가능.\n",
        "\n",
        "     * **쿼리 제한**: 주로 키를 이용한 직접 조회만 효율적. 값의 내용 기반 검색은 비효율적. 🔴\n",
        "\n",
        " * **대표 주자**: **Redis** ✨ (In-memory DB로 캐싱, 세션 관리에 매우 널리 사용), Memcached, AWS DynamoDB (Key-Value 기반이지만 기능 더 풍부)\n",
        "\n",
        " * **AI 활용 예시**: **캐싱**(DB 조회 결과, API 응답 등 임시 저장), **세션 관리**(웹 사용자 로그인 정보), 실시간 순위표, 메시지 큐 등 **빠른 응답 속도**가 중요하고 복잡한 쿼리가 필요 없는 데이터.\n",
        "\n",
        "\n",
        "\n",
        " #### 📊 문서형 vs. 키-값형 (간단 비교)\n",
        "\n",
        "\n",
        "\n",
        " | 특징         | 문서형 (MongoDB)           | 키-값형 (Redis)           |\n",
        " | :----------- | :------------------------- | :------------------------ |\n",
        " | **데이터 단위** | 문서 (JSON/BSON 유사)      | Key-Value 쌍            |\n",
        " | **스키마** | 유연함                     | 없음 (Key와 Value만 존재) |\n",
        " | **쿼리** | 문서 내용 기반 쿼리 가능     | 주로 Key 기반 조회       |\n",
        " | **주요 강점** | 유연한 데이터 모델링       | **매우 빠른 속도**, 단순함 |\n",
        " | **적합 용도** | 다양한 구조의 데이터 저장    | **캐싱**, 세션 관리        |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egJ177uiFcx-"
      },
      "source": [
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ## 💻 코드 실습 1: Python 딕셔너리로 MongoDB 문서 표현하기\n",
        "\n",
        "\n",
        "\n",
        " MongoDB의 문서(Document)는 Python의 **딕셔너리(Dictionary)** 와 매우 유사한 구조를 가집니다.\n",
        "\n",
        " 이번 실습에서는 Python 딕셔너리를 사용하여 MongoDB에 저장될 법한 데이터를 표현해 봅시다. (MongoDB 직접 연결 X)\n",
        "\n",
        "\n",
        "\n",
        " **시나리오**: AI 모델 학습 실험 결과를 MongoDB에 저장한다고 가정."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lAS30wlIFcx-"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "# TODO: 아래 정보를 포함하는 Python 딕셔너리를 'experiment_result' 변수에 생성하세요.\n",
        "#       - experiment_id (문자열): \"exp_0416_bert\"\n",
        "#       - model_name (문자열): \"BERT_large\"\n",
        "#       - dataset (문자열): \"SQuAD_v2\"\n",
        "#       - parameters (딕셔너리): learning_rate (실수, 0.00005), batch_size (정수, 32)\n",
        "#       - metrics (딕셔너리): f1_score (실수, 0.885), exact_match (실수, 0.812)\n",
        "#       - tags (리스트): [\"NLP\", \"Question Answering\", \"Fine-tuning\"]\n",
        "\n",
        "experiment_result = {\n",
        "    \"experiment_id\": \"exp_0416_bert\",\n",
        "    \"model_name\": \"BERT_large\",\n",
        "    \"dataset\": \"SQuAD_v2\",\n",
        "    \"parameters\": { # 값으로 딕셔너리 (내장된 구조)\n",
        "        \"learning_rate\": 0.00005,\n",
        "        \"batch_size\": 32\n",
        "    },\n",
        "    \"metrics\": { # 값으로 딕셔너리\n",
        "        \"f1_score\": 0.885,\n",
        "        \"exact_match\": 0.812\n",
        "    },\n",
        "    \"tags\": [\"NLP\", \"Question Answering\", \"Fine-tuning\"] # 값으로 리스트\n",
        "}\n",
        "\n",
        "# 생성된 딕셔너리(MongoDB 문서 구조와 유사) 출력\n",
        "print(\"--- 생성된 실험 결과 딕셔너리 (MongoDB 문서 예시) ---\")\n",
        "import json # JSON 형태로 예쁘게 출력하기 위해 import\n",
        "print(json.dumps(experiment_result, indent=4, ensure_ascii=False))\n",
        "\n",
        "# 특정 값 접근 예시\n",
        "print(f\"\\n모델 이름: {experiment_result['model_name']}\")\n",
        "print(f\"학습률: {experiment_result['parameters']['learning_rate']}\")\n",
        "print(f\"첫 번째 태그: {experiment_result['tags'][0]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mI99WBWAFcx-"
      },
      "source": [
        " > 위 Python 딕셔너리 `experiment_result`는 MongoDB에 그대로 하나의 **문서(Document)** 로 저장될 수 있습니다.\n",
        "\n",
        " > 스키마가 유연하여 `parameters`나 `metrics`의 하위 필드가 실험마다 달라져도 문제없이 저장 가능합니다. 🔵"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4k0_iXnFcx-"
      },
      "source": [
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ## 📚 개념 설명: MongoDB 기본 개념 소개\n",
        "\n",
        "\n",
        "\n",
        " MongoDB를 사용하기 위해 알아야 할 몇 가지 기본 용어가 있습니다. RDBMS와 비교하면 이해하기 쉽습니다.\n",
        "\n",
        "\n",
        "\n",
        " #### 📊 MongoDB vs. RDBMS 용어 비교\n",
        "\n",
        "\n",
        "\n",
        " ![](https://blog.kakaocdn.net/dn/bMzryO/btqGXmWNRGb/fOeqKJKXcgdwGQYrF5dZok/img.jpg)\n",
        "\n",
        "\n",
        "\n",
        " | MongoDB 용어         | RDBMS 용어 (유사 개념) | 설명                                       |\n",
        " | :------------------- | :--------------------- | :----------------------------------------- |\n",
        " | **Database** | Database               | 데이터베이스. Collection들의 그룹.          |\n",
        " | **Collection** | **Table** | **문서(Document)** 들의 그룹. 테이블과 유사. |\n",
        " | **Document** | **Row (행)** | MongoDB에서 데이터 저장의 기본 단위. JSON/BSON 형태. 행과 유사하지만 **스키마 유연**. ✨ |\n",
        " | **Field** | **Column (열)** | 문서 내의 Key-Value 쌍에서 Key 부분. 열과 유사. |\n",
        " | **Index** | Index                  | 특정 필드 기반으로 조회 성능 향상. (RDBMS와 유사) |\n",
        " | `_id` (Field)        | **Primary Key** | 각 Document를 고유하게 식별하는 값. 자동 생성 가능. 🔑 |\n",
        "\n",
        "\n",
        "\n",
        " * **CRUD 작업**: MongoDB에서도 기본적인 데이터 처리 작업(CRUD)을 수행합니다.\n",
        "\n",
        "     * **C**reate: 새로운 Document 삽입 (`insertOne()`, `insertMany()`)\n",
        "\n",
        "     * **R**ead: 조건에 맞는 Document 조회 (`findOne()`, `find()`)\n",
        "\n",
        "     * **U**pdate: 기존 Document 수정 (`updateOne()`, `updateMany()`)\n",
        "\n",
        "     * **D**elete: Document 삭제 (`deleteOne()`, `deleteMany()`)\n",
        "\n",
        "     * (참고: 실제 명령어는 사용하는 드라이버/라이브러리에 따라 조금씩 다를 수 있음)\n",
        "\n",
        "\n",
        "\n",
        "   ![시각 자료 삽입: MongoDB Database-Collection-Document 계층 구조 그림](https://miro.medium.com/v2/resize:fit:1400/format:webp/0*FFP7nKxraq0vTM_t.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lf1Br47FFcx-"
      },
      "source": [
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ## 💻 코드 실습 2: [선택적] Python `pymongo` 로 MongoDB 기본 작업 시연\n",
        "\n",
        "\n",
        "\n",
        " ⚠️ **사전 준비 필요!** ⚠️\n",
        "\n",
        " 이 실습은 **MongoDB 환경**(예: [MongoDB Atlas](https://www.mongodb.com/cloud/atlas)\n",
        "\n",
        "\n",
        "\n",
        " 무료 계정 생성 또는 로컬 [Docker](https://www.docker.com/) 환경에 MongoDB 설치)이 **미리 준비되어 있어야** 정상적으로 실행됩니다.\n",
        "\n",
        "\n",
        "\n",
        " 환경 준비가 안 된 경우, 코드와 설명을 보며 흐름을 이해하는 데 집중하세요.\n",
        "\n",
        "\n",
        "\n",
        " Python에서 MongoDB를 사용하기 위해 가장 널리 쓰이는 라이브러리는 **`pymongo`** 입니다.\n",
        "\n",
        " (`pip install pymongo` 명령어로 설치 필요)\n",
        "\n",
        "\n",
        "\n",
        " **시나리오**: `pymongo`를 사용하여 MongoDB에 연결하고, 이전 실습에서 만든 `experiment_result` 딕셔너리를 `experiments` 컬렉션에 삽입하고, 다시 조회해 봅니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03J9L0_9Fcx-"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "# (실행 전) pymongo 라이브러리 설치 필요: !pip install pymongo\n",
        "\n",
        "# pymongo import 시도 (설치 안 되어 있으면 오류 발생)\n",
        "try:\n",
        "    import pymongo\n",
        "    print(\"pymongo 라이브러리 로드 성공.\")\n",
        "    PYMONGO_AVAILABLE = True\n",
        "except ImportError:\n",
        "    print(\"오류: pymongo 라이브러리가 설치되지 않았습니다.\")\n",
        "    print(\"실행을 원하면 !pip install pymongo 로 설치하세요.\")\n",
        "    PYMONGO_AVAILABLE = False\n",
        "\n",
        "# --- MongoDB 연결 정보 ---\n",
        "# 실제 환경에서는 보안을 위해 연결 문자열을 코드에 직접 노출하지 않는 것이 좋습니다.\n",
        "# MongoDB Atlas 무료 티어 사용 시 연결 문자열 예시:\n",
        "# MONGODB_URI = \"mongodb+srv://<username>:<password>@<cluster-url>/?retryWrites=true&w=majority\"\n",
        "# 로컬 Docker 환경 예시 (기본 포트 27017):\n",
        "# MONGODB_URI = \"mongodb://localhost:27017/\" # 로컬 환경 가정\n",
        "DB_NAME = \"ai_experiments_db\" # 사용할 데이터베이스 이름\n",
        "COLLECTION_NAME = \"results\" # 사용할 컬렉션 이름\n",
        "\n",
        "# MongoDB 연결 시도 (환경 준비된 경우)\n",
        "client = None # 초기화\n",
        "db = None\n",
        "collection = None\n",
        "\n",
        "if PYMONGO_AVAILABLE:\n",
        "    try:\n",
        "        # 1. MongoDB 연결 (Client 생성)\n",
        "        client = pymongo.MongoClient(MONGODB_URI, serverSelectionTimeoutMS=5000) # 5초 타임아웃\n",
        "        # 연결 성공 확인 (서버 정보 강제 확인)\n",
        "        client.server_info()\n",
        "        print(f\"\\nMongoDB ({MONGODB_URI}) 연결 성공!\")\n",
        "\n",
        "        # 2. 데이터베이스 선택 (없으면 자동 생성됨)\n",
        "        db = client[DB_NAME]\n",
        "        print(f\"데이터베이스 '{DB_NAME}' 선택.\")\n",
        "\n",
        "        # 3. 컬렉션 선택 (없으면 자동 생성됨)\n",
        "        collection = db[COLLECTION_NAME]\n",
        "        print(f\"컬렉션 '{COLLECTION_NAME}' 선택.\")\n",
        "\n",
        "    except pymongo.errors.ConnectionFailure as cf:\n",
        "        print(f\"\\nMongoDB 연결 실패: {cf}\")\n",
        "        print(\"MongoDB 서버가 실행 중인지, 연결 URI가 정확한지 확인하세요.\")\n",
        "        client = None # 연결 실패 시 client 객체 None 처리\n",
        "    except Exception as e:\n",
        "        print(f\"\\nMongoDB 설정 중 오류 발생: {e}\")\n",
        "        client = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sitJUhokFcx-"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "# [선택적 실행] 데이터 삽입 (insertOne) - MongoDB 연결 성공 시\n",
        "if client is not None and collection is not None: # 연결 및 컬렉션 객체가 유효할 때만 실행\n",
        "    try:\n",
        "        # 실습 1에서 만든 딕셔너리 재사용\n",
        "        doc_to_insert = experiment_result.copy() # 원본 유지 위해 복사\n",
        "\n",
        "        # MongoDB는 삽입 시 자동으로 고유한 '_id' 필드를 추가합니다.\n",
        "        # 만약 우리가 직접 '_id'를 지정하고 싶다면 여기서 설정 가능.\n",
        "        # doc_to_insert['_id'] = doc_to_insert['experiment_id'] # 예시: experiment_id를 _id로 사용\n",
        "\n",
        "        print(f\"\\n--- '{COLLECTION_NAME}' 컬렉션에 문서 삽입 시도 ---\")\n",
        "        insert_result = collection.insert_one(doc_to_insert)\n",
        "        print(f\"삽입 성공! 생성된 문서 ID: {insert_result.inserted_id}\")\n",
        "\n",
        "        # 삽입된 문서 개수 확인 (선택적)\n",
        "        print(f\"현재 컬렉션 문서 수: {collection.count_documents({})}\") # {}는 모든 문서 의미\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"문서 삽입 중 오류: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6yTFXkAFcx-"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "# [선택적 실행] 데이터 조회 (findOne) - MongoDB 연결 성공 시\n",
        "if client is not None and collection is not None: # 연결 및 컬렉션 객체가 유효할 때만 실행\n",
        "    try:\n",
        "        # 특정 조건으로 하나의 문서 조회 (model_name 기준)\n",
        "        query_filter = {\"model_name\": \"BERT_large\"}\n",
        "\n",
        "        print(f\"\\n--- '{COLLECTION_NAME}' 컬렉션에서 '{query_filter}' 조건으로 문서 조회 시도 ---\")\n",
        "        found_document = collection.find_one(query_filter)\n",
        "\n",
        "        if found_document:\n",
        "            print(\"문서 조회 성공!\")\n",
        "            # 조회된 문서 예쁘게 출력\n",
        "            print(json.dumps(found_document, indent=4, default=str)) # ObjectId 등 직렬화 위해 default=str\n",
        "        else:\n",
        "            print(\"해당 조건의 문서를 찾을 수 없습니다.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"문서 조회 중 오류: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJmWbQoYFcx-"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "# [선택적 실행] MongoDB 연결 종료\n",
        "if client:\n",
        "    client.close()\n",
        "    print(\"\\nMongoDB 연결 종료됨.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JasLucoFcx-"
      },
      "source": [
        " > **실습 2 요약**:\n",
        "\n",
        " > `pymongo` 라이브러리를 사용하여 MongoDB에 연결하고(`MongoClient`),\n",
        "\n",
        " > 특정 데이터베이스와 컬렉션을 선택한 후,\n",
        "\n",
        " > Python 딕셔너리 형태의 데이터를 `insert_one()`으로 삽입하고,\n",
        "\n",
        " > 특정 조건(`{\"필드명\": 값}`)을 만족하는 문서를 `find_one()`으로 조회할 수 있습니다.\n",
        "\n",
        " > (실제 실행은 MongoDB 환경 설정 필요)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mp-US_NFcx-"
      },
      "source": [
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ## ❓ 퀴즈 2: MongoDB 기본 용어\n",
        "\n",
        "\n",
        "\n",
        " ### ✍️ 단답형 문제 2 (난이도: ⭐️⭐️)\n",
        "\n",
        "\n",
        "\n",
        " MongoDB에서 데이터를 저장하는 기본 단위로, 필드와 값으로 구성된 JSON/BSON 형태의 구조를 무엇이라고 하나요? 또한, 이러한 문서(Document)들의 그룹을 무엇이라고 하나요? (두 용어를 순서대로 작성)\n",
        "\n",
        "\n",
        "\n",
        " ### <h3>정답 및 해설</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79gNETRrFcx-"
      },
      "source": [
        " **정답:** Document (문서), Collection (컬렉션)\n",
        "\n",
        "\n",
        "\n",
        " **해설:** MongoDB의 Document는 RDBMS의 Row(행)와 유사한 개념이지만 스키마가 유연하고, Collection은 RDBMS의 Table과 유사한 개념입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gN-XXroxFcx-"
      },
      "source": [
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ## ❓ F.A.Q (4교시 궁금증 해소)\n",
        "\n",
        "\n",
        "\n",
        " * **Q1: NoSQL은 RDBMS보다 항상 좋은 건가요? 언제 RDBMS를 써야 하죠?**\n",
        "\n",
        "     * **A1**: 아닙니다! **각자 장단점**이 있습니다. ⚖️\n",
        "\n",
        "         * **RDBMS**: 데이터 **구조가 명확**하고, **관계/일관성/정확성**이 매우 중요하며, 복잡한 **JOIN**이나 **트랜잭션**이 필요할 때 여전히 강력합니다. (예: 금융 시스템, 회원 관리) 🔵\n",
        "\n",
        "         * **NoSQL**: **유연한 데이터 구조**, **대규모 데이터/트래픽** 처리, **높은 확장성/가용성**이 필요하거나, 특정 작업(캐싱 등)에 **고성능**이 필요할 때 유리합니다. 🔵\n",
        "\n",
        "         * **결론**: 해결하려는 문제와 데이터의 특성에 맞춰 **적합한 도구를 선택**하는 것이 중요합니다. 👍\n",
        "\n",
        "\n",
        "\n",
        " * **Q2: NoSQL은 ACID 같은 트랜잭션 지원이 안 되나요? 데이터 일관성은 어떻게 하죠?**\n",
        "\n",
        "     * **A2**: 전통적으로 NoSQL은 RDBMS의 엄격한 ACID 트랜잭션보다 **가용성(Availability)이나 성능**을 우선시하는 경우가 많았습니다. 하지만 최근 많은 NoSQL DB(특히 MongoDB)들이 **단일 문서 수준 또는 그 이상의 트랜잭션 기능**을 지원하고 있습니다. 🔵 다만, RDBMS만큼 복잡한 트랜잭션을 보장하지는 못할 수 있으며, '결과적 일관성(Eventual Consistency)' 모델을 따르는 경우도 많습니다. (일시적으로 데이터 불일치가 있을 수 있으나 결국 일관된 상태로 수렴) → 서비스 특성에 따라 일관성 수준을 고려해야 합니다. ⚠️\n",
        "\n",
        "\n",
        "\n",
        " * **Q3: 문서형, Key-Value 말고 다른 NoSQL 종류는 뭐가 있나요?**\n",
        "\n",
        "     * **A3**: **컬럼형(Column-Family)** DB (예: Cassandra, HBase)는 쓰기 작업이 매우 많고 특정 컬럼 기반 분석에 유리합니다. **그래프형(Graph)** DB (예: Neo4j)는 데이터 간의 복잡한 관계(소셜 네트워크, 추천 등)를 표현하고 분석하는 데 특화되어 있습니다. 🔗🌳\n",
        "\n",
        "\n",
        "\n",
        " * **Q4: MongoDB 스키마가 유연하다는 건 무슨 뜻인가요? 아무렇게나 넣어도 되나요?**\n",
        "\n",
        "     * **A4**: 네, 이론적으로는 각 Document가 **서로 다른 필드(구조)** 를 가질 수 있다는 의미입니다. 🔵 예를 들어, 어떤 사용자 문서에는 'hobby' 필드가 있지만 다른 사용자 문서에는 없을 수 있습니다. 이는 개발 초기나 요구사항 변경 시 매우 편리합니다. 하지만 너무 중구난방으로 데이터를 넣으면 나중에 데이터를 이해하고 활용하기 어려워질 수 있습니다. 🔴 따라서 어느 정도 **일관된 구조를 유지**하거나, 필요시 **스키마 유효성 검사(Schema Validation)** 기능을 활용하는 것이 좋습니다. ✨\n",
        "\n",
        "\n",
        "\n",
        " * **Q5: Redis랑 MongoDB는 언제 각각 쓰는 게 좋을까요?**\n",
        "\n",
        "     * **A5**: 둘 다 NoSQL이지만 특성이 다릅니다.\n",
        "\n",
        "         * **Redis (Key-Value, In-memory)**: **속도가 생명**인 작업에 최적! 🚀 **캐싱**, **세션 관리**, 실시간 순위표, 메시지 큐 등. 데이터 구조가 단순하고 빠른 응답이 필요할 때.\n",
        "\n",
        "         * **MongoDB (Document)**: **유연한 구조**의 데이터를 저장하고 **내용 기반 쿼리**가 필요할 때. 📄 사용자 프로필, 콘텐츠 관리, 로그, IoT 데이터 등. Redis보다 복잡한 데이터 저장/조회 가능."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsE1UGTXFcx_"
      },
      "source": [
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ## 🔑 4교시 핵심 정리\n",
        "\n",
        "\n",
        "\n",
        " * **NoSQL 등장 배경**: RDBMS의 한계(스키마 경직성, 수평 확장 어려움, 비정형 데이터 처리) 극복. 🚀\n",
        "\n",
        " * **RDBMS vs NoSQL**:\n",
        "\n",
        "     * **RDB**: 구조 명확, 일관성/무결성 중시 (ACID) → **정형 데이터** 관리.\n",
        "\n",
        "     * **NoSQL**: 스키마 유연, 확장성/성능 중시 (다양한 일관성 모델) → **비정형/대규모 데이터** 관리.\n",
        "\n",
        " * **주요 NoSQL 유형**:\n",
        "\n",
        "     * **문서형 (MongoDB)**: JSON/BSON 문서 단위 저장, **유연한 스키마**, 내장 구조 표현 용이. 📄\n",
        "\n",
        "     * **키-값형 (Redis)**: Key-Value 쌍 저장, **매우 빠른 속도**, 단순함 → **캐싱**, 세션 관리. 🔑💨\n",
        "\n",
        " * **AI 활용**: 비정형 데이터(로그, 텍스트) 저장/분석, 대규모 실시간 서비스, 캐싱 등 RDB 보완. 🤖\n",
        "\n",
        " * **MongoDB 기본**:\n",
        "\n",
        "     * **Database → Collection (≈Table) → Document (≈Row, JSON/Dict)** 계층 구조. 🧱\n",
        "\n",
        "     * **Document**: 데이터 기본 단위, **유연한 구조** 가짐. ✨\n",
        "\n",
        "     * `_id`: Document 고유 식별자 (PK 역할). 🔑\n",
        "\n",
        "     * **CRUD**: `insert`, `find`, `update`, `delete` 기본 작업 수행.\n",
        "\n",
        " * **Python 연동**: `pymongo` 라이브러리 사용 (선택적 실습), Python **딕셔너리**가 MongoDB **문서**와 유사. 🐍"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CPA2Q5-Fcx_"
      },
      "source": [
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ## 💭 4교시 마무리\n",
        "\n",
        "\n",
        "\n",
        " 이번 시간에는 관계형 데이터베이스(RDBMS)와 다른 특징을 가진 **NoSQL 데이터베이스**의 등장 배경과 핵심 개념(유연한 스키마, 확장성)을 배웠습니다. 대표적인 유형인 **문서형(MongoDB)** 과 **키-값형(Redis)** 의 특징과 AI 서비스에서의 활용 사례를 살펴보았습니다.\n",
        "\n",
        "\n",
        "\n",
        " 특히 MongoDB의 기본 구성 요소(Collection, Document)와 CRUD 작업 개념을 이해하고, Python **딕셔너리**를 통해 MongoDB 문서 구조를 표현하는 실습을 진행했습니다. (선택적으로 `pymongo` 라이브러리를 이용한 실제 DB 작업 코드를 시연했습니다.)\n",
        "\n",
        "\n",
        "\n",
        " NoSQL 데이터베이스는 현대 웹 서비스와 AI 환경에서 발생하는 다양하고 방대한 데이터를 효과적으로 처리하는 데 중요한 역할을 합니다. RDBMS와 NoSQL의 특징을 잘 이해하고 상황에 맞게 적절한 데이터베이스를 선택하고 활용하는 능력이 중요합니다.\n",
        "\n",
        "\n",
        "\n",
        " **다음 5교시에는 AI 시대의 핵심 저장소로 떠오르는 Vector DB의 개념과 필요성, 그리고 임베딩 벡터를 저장하고 유사도 검색을 수행하는 방법에 대해 알아보겠습니다.**\n",
        "\n",
        "\n",
        "\n",
        " ### 🚀 더 나아가기 (4교시 복습)\n",
        "\n",
        "\n",
        "\n",
        " * 여러분이 만들고 싶은 AI 서비스(예: 영화 추천, 뉴스 기사 요약)를 생각해보고, 해당 서비스에서 발생할 수 있는 데이터 중 RDBMS와 NoSQL(MongoDB 또는 Redis) 각각에 저장하면 좋을 데이터는 무엇일지 구분해보세요.\n",
        "\n",
        " * MongoDB Atlas 웹사이트를 방문하여 무료 클러스터를 생성하는 과정을 살펴보고, 어떤 설정들이 있는지 확인해보세요. (실제 생성은 선택 사항)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06S5sDD-Fcx_"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "# (선택적 실습에서 사용한) MongoDB 연결 종료 확인\n",
        "try:\n",
        "    if 'client' in locals() and client is not None:\n",
        "        # pymongo의 경우, close() 후에도 객체 자체는 남아있을 수 있으므로,\n",
        "        # 명시적으로 None 처리하거나, 연결 상태를 확인하는 로직이 필요할 수 있습니다.\n",
        "        # 여기서는 간단히 client 객체가 있으면 닫혔다고 가정합니다. (위 코드에서 이미 close 호출)\n",
        "        print(\"\\n(선택적 실습) MongoDB 연결이 종료되었습니다.\")\n",
        "except NameError:\n",
        "    pass # client 객체가 정의되지 않은 경우 (실습 스킵 시)\n",
        "\n",
        "# SQLite 연결 종료 (만약 이전 셀에서 생성/사용했다면)\n",
        "try:\n",
        "    if 'conn' in locals() and conn:\n",
        "        conn.close()\n",
        "        print(\"\\nSQLite 데이터베이스 연결이 해제되었습니다.\")\n",
        "except Exception as e:\n",
        "     print(f\"SQLite 연결 해제 중 오류: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbfScxJDFcx_"
      },
      "source": [
        " # 5교시: Vector DB 핵심 - 임베딩 저장과 AI 검색 (FAISS 실습)\n",
        "\n",
        "\n",
        "\n",
        " ## 🎯 5교시 수업 목표\n",
        "\n",
        "\n",
        "\n",
        " 오늘 수업을 통해 여러분은 다음을 할 수 있게 됩니다:\n",
        "\n",
        "\n",
        "\n",
        " 1.  **벡터 임베딩(Vector Embedding)** 이 무엇인지 개념적으로 설명하고, AI에서 왜 중요한지 이해하기. 🧠🔢\n",
        "\n",
        " 2.  기존 DB(RDB/NoSQL)가 아닌 **Vector DB**가 **의미 기반 검색(Semantic Search)** 을 위해 왜 필요한지 설명하기. 🤔🔍\n",
        "\n",
        " 3.  **유사도 검색(Similarity Search)** 의 기본 원리와 **ANN(Approximate Nearest Neighbor)** 개념 이해하기. ✨↔️\n",
        "\n",
        " 4.  Python 라이브러리 **`faiss-cpu`** 를 사용하여 기본적인 **벡터 인덱스 생성, 벡터 추가(`add`), 벡터 검색(`search`)** 코드 작성 및 실행하기. 💻⌨️\n",
        "\n",
        " 5.  벡터 검색 결과(거리, ID)의 의미를 해석하기. 📊❓\n",
        "\n",
        " 6.  Vector DB가 **RAG, 추천 시스템** 등 최신 AI 서비스 구현에 어떻게 활용되는지 이해하기. 🤖🚀\n",
        "\n",
        "\n",
        "\n",
        " > ✨ **심화 목표**\n",
        "\n",
        " >\n",
        "\n",
        " > * 다양한 유사도 측정 지표(L2 거리, 코사인 유사도 등)의 차이점 이해하기.\n",
        "\n",
        " > * FAISS의 다양한 인덱스 유형(예: `IndexIVFFlat`)의 기본 개념과 사용 목적 알아보기.\n",
        "\n",
        " > * Milvus, Pinecone 등 다른 Vector DB 솔루션들의 특징 비교해보기."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkGjT2cbFcx_"
      },
      "source": [
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ## 📚 개념 설명 (핵심 요약)\n",
        "\n",
        "\n",
        "\n",
        " ### 1. 벡터 임베딩과 Vector DB의 필요성 🧠➡️💾\n",
        "\n",
        "\n",
        "\n",
        " * **벡터 임베딩 (Vector Embedding) 이란?** (개념 복습)\n",
        "\n",
        "     * **핵심**: 텍스트, 이미지, 오디오 등 **비정형 데이터를 AI 모델이 이해할 수 있는 숫자 벡터(고차원 숫자 배열)로 변환**하는 것. ✨\n",
        "\n",
        "     * **의미 함축**: 이 벡터는 단순한 숫자가 아니라, 데이터의 **의미(Semantic Meaning)** 나 **특징(Feature)** 을 **압축**하여 담고 있음. 🔵\n",
        "\n",
        "         * 유사한 의미/특징을 가진 데이터 → 벡터 공간에서 **가까운 위치**에 표현됨.\n",
        "\n",
        "         * 예: \"강아지\" 텍스트와 \"개\" 텍스트는 벡터 공간에서 가까움. \"강아지\"와 \"컴퓨터\"는 멂.\n",
        "\n",
        "     ![시각 자료 삽입: 2D/3D 벡터 공간에 단어/이미지 임베딩 예시](https://developers.google.com/static/machine-learning/crash-course/images/embeddings_2D.png?hl=ko)\n",
        "\n",
        "     * **생성**: 사전 학습된 AI 모델(Embedding Model)을 사용하여 생성. (BERT, Word2Vec, ResNet 등)\n",
        "\n",
        "\n",
        "\n",
        " * **기존 DB의 한계**: RDB/NoSQL은 주로 **정확한 값(Exact Match)** 이나 **범위(Range)** 기반 검색에 강함.\n",
        "\n",
        "     * \"id=123인 사용자 찾기\", \"가격이 10000원 이상인 상품 찾기\" 등.\n",
        "\n",
        "     * 하지만 **\"의미적으로 유사한\"** 데이터를 찾는 데는 비효율적. 🔴\n",
        "\n",
        "         * 예: \"'AI 기술의 미래'와 가장 비슷한 내용을 다룬 다른 문서를 찾아줘\" (키워드 매칭만으론 한계)\n",
        "\n",
        "\n",
        "\n",
        " * **Vector DB 필요성**: **의미 기반 검색 (Semantic Search)** ✨\n",
        "\n",
        "     * 대량의 **벡터 임베딩**을 효율적으로 **저장**하고, 주어진 쿼리 벡터와 **유사한 벡터**들을 **빠르게 검색**하는 데 **특화된** 데이터베이스. 🚀🔵\n",
        "\n",
        "     * **핵심 기능**: **유사도 검색 (Similarity Search)**\n",
        "\n",
        "       ![시각 자료 삽입: 키워드 검색 vs. 의미 기반(벡터) 검색 비교](https://cdn.prod.website-files.com/6795b7c02769d85b3bf50fe1/67ceae1ef701408968827379_67c01232d9ea0f26bb4038ed_672d9024f2a3c344e2de0fd1_6618e37cc0d3539f1e1e88f4_5.png)\n",
        "\n",
        "       ![시각 자료 삽입: 키워드 검색 vs. 의미 기반(벡터) 검색 비교](https://cdn.prod.website-files.com/6795b7c02769d85b3bf50fe1/67ceae1ef701408968827368_67ceaa5fd937c3221c9278d0_stic.webp)\n",
        "\n",
        "\n",
        "\n",
        " * **AI 활용 사례 (Vector DB는 어디에 쓰일까?)**:\n",
        "\n",
        "     * **RAG (Retrieval-Augmented Generation)**: LLM(챗봇)이 답변 생성 시, 관련된 외부 문서 벡터를 검색하여 **정확하고 근거 있는 답변** 생성. (가장 Hot! 🔥)\n",
        "\n",
        "     * **추천 시스템**: 사용자/아이템 선호도를 벡터로 표현, 유사한 벡터를 찾아 개인화 추천. 👍\n",
        "\n",
        "     * **이미지/음성 검색**: 비슷한 이미지/음악 검색 (Shazam, Google Lens 등). 🖼️🎵\n",
        "\n",
        "     * **시맨틱 검색**: 쇼핑몰 상품, 기술 문서 등 의미가 유사한 콘텐츠 검색. 🔍\n",
        "\n",
        "     * **이상 탐지**: 정상 데이터 벡터 분포에서 벗어난 이상 패턴 탐지. 📊⚠️"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1psV0iGFcx_"
      },
      "source": [
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ## ❓ 퀴즈 1: Vector DB의 핵심 역할\n",
        "\n",
        "\n",
        "\n",
        " ### ✍️ 단답형/서술형 문제 1 (난이도: ⭐️⭐️⭐️)\n",
        "\n",
        "\n",
        "\n",
        " 1.  텍스트나 이미지 같은 데이터를 AI 모델이 이해하는 숫자 배열로 변환한 것을 무엇이라고 하나요? (단답형)\n",
        "\n",
        " 2.  Vector DB가 해결하려는 **주요 문제**는 무엇이며, 기존 RDB/NoSQL DB와 **어떤 점**에서 차별화되는지 설명하세요. (서술형)\n",
        "\n",
        "\n",
        "\n",
        " ### <h3>정답 및 해설</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6A5Vv9yGFcx_"
      },
      "source": [
        " 1.  **정답:** 벡터 임베딩 (Vector Embedding) 또는 임베딩 벡터\n",
        "\n",
        " 2.  **정답:**\n",
        "\n",
        "     * **주요 문제:** Vector DB는 대규모 데이터셋에서 **의미적으로 유사한** 데이터를 **빠르게 검색**하는 문제를 해결하려고 합니다.\n",
        "\n",
        "     * **차별점:** 기존 RDB/NoSQL은 주로 **정확한 값**이나 **범위**를 기준으로 데이터를 검색하는 데 강하지만, 데이터 간의 **의미적 유사성**을 직접적으로 다루고 검색하는 데는 비효율적입니다. Vector DB는 **벡터 간의 거리/유사도**를 계산하여 의미가 비슷한 데이터를 찾는 데 특화되어 있습니다. ✨"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jifTuujyFcx_"
      },
      "source": [
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ## 📚 개념 설명: 유사도 검색과 Vector DB 솔루션\n",
        "\n",
        "\n",
        "\n",
        " ### 1. 유사도 검색 (Similarity Search) 원리 ✨↔️\n",
        "\n",
        "\n",
        "\n",
        " * **핵심**: 주어진 쿼리 벡터(Query Vector)와 DB에 저장된 벡터들 간의 **유사성(Similarity)** 또는 **거리(Distance)** 를 계산하여, 가장 유사한(거리가 가까운) 벡터들을 찾는 것.\n",
        "\n",
        " * **유사도/거리 측정 방법**: 벡터 간의 관계를 수치화하는 다양한 지표 사용.\n",
        "\n",
        "\n",
        "\n",
        "     #### 📊 주요 유사도/거리 측정 지표\n",
        "\n",
        "\n",
        "\n",
        "     | 지표                | 설명                                                     | 특징                                   |\n",
        "     | :------------------ | :------------------------------------------------------- | :------------------------------------- |\n",
        "     | **L2 거리 (유클리드 거리)** | 벡터 공간에서 두 점 사이의 **직선 거리**. (가장 일반적)  | 거리가 **작을수록** 유사. 📏 (0 이상)   |\n",
        "     | **코사인 유사도** | 두 벡터 사이 각도의 **코사인 값**. (-1 ~ 1 사이)         | 값이 **클수록** (1에 가까울수록) 유사. ∠ |\n",
        "     | 내적 (Inner Product) | 두 벡터의 각 차원별 곱의 합.                             | 정규화된 벡터에서는 코사인 유사도와 유사. |\n",
        "\n",
        "\n",
        "\n",
        " * **정확한 최근접 이웃 탐색 (Exact Nearest Neighbor Search)**:\n",
        "\n",
        "     * 모든 벡터와 거리를 계산하여 가장 가까운 벡터를 정확히 찾음.\n",
        "\n",
        "     * 데이터가 적을 때는 가능하지만, 수백만~수억 개 벡터에서는 **계산량이 너무 많아 매우 느림**. 🐌🔴\n",
        "\n",
        "\n",
        "\n",
        " ### 2. ANN (Approximate Nearest Neighbor) 기초 🚀\n",
        "\n",
        "\n",
        "\n",
        " * **개념**: 정확한 최근접 이웃 대신, **약간의 정확도 손실**을 감수하더라도 **매우 빠른 속도**로 **'거의'** 가장 가까운 이웃들을 찾는 알고리즘. ✨ (속도 🚀 vs 정확도 trade-off)\n",
        "\n",
        " * **필요성**: 대규모 벡터 데이터셋에서 **실시간 검색**을 가능하게 함. Vector DB의 핵심 기술. 🔵\n",
        "\n",
        " * **작동 방식 (개념적)**: 데이터를 특정 구조(예: 그래프, 트리, 해싱)로 미리 구성하여, 탐색 공간을 줄여서 검색 속도를 높임.\n",
        "\n",
        " * **라이브러리/알고리즘 예시**: FAISS, ScaNN, HNSW, LSH 등.\n",
        "\n",
        "\n",
        "\n",
        " ### 3. Vector DB 솔루션 소개 💾\n",
        "\n",
        "\n",
        "\n",
        " 다양한 Vector DB 솔루션(오픈소스 및 상용 서비스)들이 존재합니다.\n",
        "\n",
        "\n",
        "\n",
        " | 솔루션        | 유형             | 특징                                                      |\n",
        " | :------------- | :--------------- | :-------------------------------------------------------- |\n",
        " | **FAISS** | **라이브러리** | Facebook(Meta) 개발. 고성능 유사도 검색 기능 제공. C++/Python. ✨ |\n",
        " | **Milvus** | 오픈소스 DB      | 대규모 벡터 관리/검색 위한 분산 시스템. 다양한 기능 제공. |\n",
        " | **Pinecone** | 클라우드 서비스   | 사용 편의성 높은 완전 관리형 Vector DB 서비스.             |\n",
        " | **Weaviate** | 오픈소스 DB      | 벡터 + 그래프 데이터 모델 결합. Semantic Search 특화.       |\n",
        " | **Qdrant** | 오픈소스/클라우드 | Rust 기반 고성능. 필터링 검색 기능 강조.                  |\n",
        " | **ChromaDB** | 오픈소스/라이브러리 | Python 중심. 로컬 환경 사용 및 RAG 파이프라인 구축 용이.  |\n",
        "\n",
        "\n",
        "\n",
        " > 오늘은 이 중 가장 기본적이고 널리 쓰이는 라이브러리인 **FAISS**를 사용하여 실습합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juZi9Mi9Fcx_"
      },
      "source": [
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ## 💻 코드 실습: FAISS 로 벡터 저장 및 검색하기\n",
        "\n",
        "\n",
        "\n",
        " **FAISS (Facebook AI Similarity Search)**: 벡터 유사도 검색을 위한 고성능 라이브러리.\n",
        "\n",
        "\n",
        "\n",
        " **⚠️ 사전 준비 필요! ⚠️**\n",
        "\n",
        " * `faiss-cpu` 라이브러리 설치: `pip install faiss-cpu` (CPU 버전)\n",
        "\n",
        " * `numpy` 라이브러리 설치: `pip install numpy` (벡터 데이터 처리용)\n",
        "\n",
        "\n",
        "\n",
        " **실습 목표**:\n",
        "\n",
        " 1.  간단한 샘플 벡터 데이터(NumPy 배열) 생성.\n",
        "\n",
        " 2.  FAISS 인덱스(Index) 생성.\n",
        "\n",
        " 3.  인덱스에 벡터 데이터 추가 (`add`).\n",
        "\n",
        " 4.  쿼리 벡터로 유사 벡터 검색 (`search`).\n",
        "\n",
        " 5.  검색 결과(거리, ID) 확인 및 해석."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "quT5inKZFcx_"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "# 실습 준비: 라이브러리 import 시도\n",
        "\n",
        "try:\n",
        "    import faiss\n",
        "    import numpy as np\n",
        "    print(\"faiss 와 numpy 라이브러리 로드 성공!\")\n",
        "    FAISS_AVAILABLE = True\n",
        "except ImportError as e:\n",
        "    print(f\"오류: 라이브러리 로드 실패 - {e}\")\n",
        "    print(\"실행을 원하면 !pip install faiss-cpu numpy 로 설치하세요.\")\n",
        "    FAISS_AVAILABLE = False\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORDsaA5KFcx_"
      },
      "source": [
        " ### 1. 샘플 벡터 데이터 준비 및 FAISS 인덱스 생성\n",
        "\n",
        "\n",
        "\n",
        " * **샘플 데이터**: 간단한 2차원 벡터 5개를 NumPy 배열로 만듭니다. (실제 임베딩은 수백~수천 차원)\n",
        "\n",
        " * **FAISS 인덱스**: 벡터를 저장하고 검색할 구조. 다양한 종류가 있지만, 가장 기본적인 `IndexFlatL2` 사용.\n",
        "\n",
        "     * `IndexFlatL2`: L2 거리(유클리드 거리)를 사용하여 **정확한(Exact)** 최근접 이웃 검색. (ANN 아님, 데이터 적을 때 사용)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FgOsa8YFcx_"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "# 실습 1: 샘플 벡터 생성 및 인덱스 생성\n",
        "\n",
        "if FAISS_AVAILABLE:\n",
        "    # 1. 샘플 벡터 데이터 생성 (5개의 2차원 벡터)\n",
        "    # 각 행이 하나의 벡터를 나타냄. 데이터 타입은 float32 권장.\n",
        "    dimension = 2 # 벡터 차원\n",
        "    num_vectors = 5 # 벡터 개수\n",
        "\n",
        "    # np.random.rand 로 0~1 사이 랜덤 값 생성 후 float32로 변환\n",
        "    db_vectors = np.random.rand(num_vectors, dimension).astype('float32')\n",
        "    print(\"--- 샘플 DB 벡터 (numpy array) ---\")\n",
        "    print(db_vectors)\n",
        "    print(f\"Shape: {db_vectors.shape}\") # (5, 2)\n",
        "\n",
        "    # 2. FAISS 인덱스 생성 (L2 거리 기반, 정확 검색)\n",
        "    # 인덱스 생성 시 벡터의 차원(dimension)을 알려줘야 함.\n",
        "    index = faiss.IndexFlatL2(dimension)\n",
        "    print(f\"\\n--- FAISS Index 생성 완료 ---\")\n",
        "    print(f\"인덱스 종류: IndexFlatL2\")\n",
        "    print(f\"현재 인덱스된 벡터 수: {index.ntotal}\") # 아직 벡터 추가 안 했으므로 0\n",
        "    print(f\"인덱스가 학습되었는지 여부: {index.is_trained}\") # IndexFlatL2는 별도 학습 불필요\n",
        "\n",
        "else:\n",
        "    print(\"FAISS 라이브러리가 없어 실습을 진행할 수 없습니다.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPoJBH-oFcx_"
      },
      "source": [
        " ### 2. FAISS 인덱스에 벡터 추가 (`add`) ➕\n",
        "\n",
        "\n",
        "\n",
        " 생성된 인덱스에 준비된 벡터 데이터를 추가합니다.\n",
        "\n",
        "\n",
        "\n",
        " * **`index.add(vectors)`**:\n",
        "\n",
        "     * `vectors`: 추가할 벡터들이 담긴 NumPy 배열 (형태: `(벡터 개수, 차원)`).\n",
        "\n",
        "     * 벡터는 인덱스에 추가된 순서대로 **내부 ID (0부터 시작)** 를 부여받음."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lNahqNwDFcx_"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "# 실습 2: 인덱스에 벡터 추가\n",
        "\n",
        "if FAISS_AVAILABLE and 'index' in locals():\n",
        "    try:\n",
        "        print(f\"\\n--- 벡터 추가 전 인덱스 크기: {index.ntotal} ---\")\n",
        "\n",
        "        # 인덱스에 db_vectors 추가\n",
        "        index.add(db_vectors)\n",
        "\n",
        "        print(f\"--- 벡터 추가 후 인덱스 크기: {index.ntotal} ---\") # 5 출력 예상\n",
        "        # 추가된 벡터들은 내부적으로 ID 0, 1, 2, 3, 4 를 부여받음.\n",
        "\n",
        "    except NameError:\n",
        "        print(\"오류: index 또는 db_vectors 객체가 생성되지 않았습니다.\")\n",
        "    except Exception as e:\n",
        "        print(f\"벡터 추가 중 오류: {e}\")\n",
        "else:\n",
        "    print(\"FAISS 라이브러리 또는 인덱스 객체가 없어 실습을 진행할 수 없습니다.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTYXMHDqFcx_"
      },
      "source": [
        " ### 3. FAISS 인덱스에서 벡터 검색 (`search`) 🔍\n",
        "\n",
        "\n",
        "\n",
        " 인덱스에 저장된 벡터들 중에서, 주어진 **쿼리 벡터(Query Vector)** 와 가장 유사한(거리가 가까운) 벡터들을 검색합니다.\n",
        "\n",
        "\n",
        "\n",
        " * **`index.search(query_vectors, k)`**:\n",
        "\n",
        "     * `query_vectors`: 검색 기준이 되는 쿼리 벡터(들). NumPy 배열 형태 (`(쿼리 개수, 차원)`).\n",
        "\n",
        "     * `k`: 각 쿼리 벡터당 찾고 싶은 **가장 가까운 이웃의 수**.\n",
        "\n",
        "     * **반환값**: `(D, I)` 튜플.\n",
        "\n",
        "         * `D`: 각 쿼리 벡터로부터 찾은 k개 이웃 벡터까지의 **거리(Distance)** 배열 (`(쿼리 개수, k)`).\n",
        "\n",
        "         * `I`: 찾은 k개 이웃 벡터의 **내부 ID(Index)** 배열 (`(쿼리 개수, k)`). 0부터 시작.\n",
        "\n",
        "\n",
        "\n",
        " * **결과 해석**: `I` 배열의 ID를 통해 어떤 벡터가 유사한지 식별하고, `D` 배열의 거리 값을 통해 얼마나 유사한지(거리가 작은지) 판단. ✨"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2GD2xwPlFcx_"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "# 실습 3: 유사 벡터 검색\n",
        "\n",
        "if FAISS_AVAILABLE and 'index' in locals() and index.ntotal > 0:\n",
        "    try:\n",
        "        # 1. 검색할 쿼리 벡터 준비 (예: 첫 번째 DB 벡터와 유사한 벡터 찾기)\n",
        "        # 실제로는 사용자 입력 텍스트/이미지를 임베딩한 벡터가 됨.\n",
        "        # 여기서는 DB 벡터 중 하나를 사용 + 약간의 노이즈 추가\n",
        "        query_vector = db_vectors[0:1] + np.random.rand(1, dimension).astype('float32') * 0.1\n",
        "        # query_vector = np.array([[0.1, 0.2]]).astype('float32') # 직접 지정도 가능\n",
        "        print(\"\\n--- 검색할 쿼리 벡터 ---\")\n",
        "        print(query_vector)\n",
        "\n",
        "        # 2. 검색 수행 (가장 가까운 3개 벡터 찾기)\n",
        "        k = 3 # 찾을 이웃 수\n",
        "        print(f\"\\n--- 가장 유사한 {k}개 벡터 검색 수행 ---\")\n",
        "        distances, indices = index.search(query_vector, k)\n",
        "\n",
        "        # 3. 검색 결과 확인\n",
        "        print(\"\\n--- 검색 결과 ---\")\n",
        "        print(\"찾은 벡터들의 ID (indices):\")\n",
        "        print(indices) # shape: (1, k) - 쿼리가 1개였으므로\n",
        "        print(\"쿼리 벡터로부터의 거리 (distances):\")\n",
        "        print(distances) # shape: (1, k) - L2 거리 제곱값일 수 있음 (IndexFlatL2)\n",
        "\n",
        "        # 결과 해석\n",
        "        print(\"\\n--- 결과 해석 ---\")\n",
        "        query_index = 0 # 첫 번째 (그리고 유일한) 쿼리에 대한 결과\n",
        "        print(f\"쿼리 벡터: {query_vector[query_index]}\")\n",
        "        for i in range(k):\n",
        "            neighbor_id = indices[query_index][i] # 찾은 이웃의 ID\n",
        "            neighbor_distance = distances[query_index][i] # 해당 이웃까지의 거리\n",
        "            neighbor_vector = index.reconstruct(neighbor_id) # ID로 원본 벡터 복원 (선택적)\n",
        "            print(f\"{i+1}. 가장 유사한 벡터 ID: {neighbor_id}, 거리: {neighbor_distance:.4f}\")\n",
        "            # print(f\"   (원본 벡터: {neighbor_vector})\") # 필요시 주석 해제\n",
        "\n",
        "            # 보통 ID 0 이 가장 가깝게 나옴 (자기 자신 또는 매우 유사)\n",
        "            if i == 0 and neighbor_id == 0:\n",
        "                print(\"   (쿼리 벡터의 원본인 ID 0 벡터가 가장 가깝게 검색됨)\")\n",
        "\n",
        "    except NameError:\n",
        "        print(\"오류: index 또는 db_vectors 객체가 생성되지 않았습니다.\")\n",
        "    except Exception as e:\n",
        "        print(f\"벡터 검색 중 오류: {e}\")\n",
        "else:\n",
        "    print(\"FAISS 라이브러리, 인덱스 객체, 또는 인덱스된 데이터가 없어 실습을 진행할 수 없습니다.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLzETikLFcx_"
      },
      "source": [
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ## ❓ 퀴즈 2: 유사도 검색 결과 해석\n",
        "\n",
        "\n",
        "\n",
        " ### ✍️ 단답형 문제 2 (난이도: ⭐️⭐️)\n",
        "\n",
        "\n",
        "\n",
        " FAISS `search` 결과에서 반환되는 **거리(Distance)** 값이 **작을수록** 쿼리 벡터와 해당 결과 벡터 간의 **유사도**는 어떻게 된다고 해석할 수 있나요? (사용된 거리 측정 지표가 L2 거리라고 가정)\n",
        "\n",
        "\n",
        "\n",
        " ### <h3>정답 및 해설</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6zjuFzAFcyA"
      },
      "source": [
        " **정답:** 유사도가 **높다** (또는 더 유사하다, 더 가깝다).\n",
        "\n",
        "\n",
        "\n",
        " **해설:** L2 거리(유클리드 거리)는 벡터 공간에서 두 점 사이의 직선 거리를 의미합니다. 따라서 거리가 작을수록 두 벡터가 공간상에서 더 가깝다는 뜻이고, 이는 곧 의미적으로 더 유사하다는 것을 나타냅니다. (코사인 유사도는 반대로 값이 클수록 유사합니다.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owRp7bPsFcyA"
      },
      "source": [
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ## ❓ F.A.Q (5교시 궁금증 해소)\n",
        "\n",
        "\n",
        "\n",
        " * **Q1: Vector DB는 RDB나 NoSQL을 대체하는 건가요?**\n",
        "\n",
        "     * **A1**: 아니요, **보완** 관계입니다. 🤝 Vector DB는 **유사도 검색**에 특화되어 있지만, 정확한 값 검색, 복잡한 필터링, 관계 표현 등은 RDB/NoSQL이 더 강점을 가집니다. 실제 서비스에서는 벡터 데이터는 Vector DB에, 관련 메타데이터(문서 ID, 생성일 등)는 RDB/NoSQL에 저장하고 함께 사용하는 경우가 많습니다. 🔵\n",
        "\n",
        "\n",
        "\n",
        " * **Q2: 벡터 간의 '거리'가 정확히 뭘 의미하나요?**\n",
        "\n",
        "     * **A2**: 벡터 공간에서 두 벡터가 얼마나 **'가까운지' 또는 '다른지'** 를 나타내는 **수치적 척도**입니다. 📏 어떤 거리 측정 지표(L2 거리, 코사인 유사도 등)를 사용하느냐에 따라 계산 방식과 값의 범위가 다릅니다. 일반적으로 L2 거리는 **작을수록**, 코사인 유사도는 **클수록**(1에 가까울수록) 두 벡터가 의미적으로 유사하다고 봅니다. ✨\n",
        "\n",
        "\n",
        "\n",
        " * **Q3: 왜 정확한 검색 대신 근사 검색(ANN)을 사용하나요?**\n",
        "\n",
        "     * **A3**: **속도 때문입니다!** 🚀 수백만, 수억 개 이상의 벡터 전체와 거리를 계산하여 정확히 가장 가까운 것을 찾는 것은 **매우 느립니다** 🐌🔴. ANN은 약간의 정확도(아주 가끔 진짜 정답을 놓칠 수 있음)를 희생하는 대신, **훨씬 빠른 속도**로 '거의 정확한' 결과를 찾아주기 때문에 대규모 실시간 서비스에 필수적입니다. (속도-정확도 Trade-off)\n",
        "\n",
        "\n",
        "\n",
        " * **Q4: FAISS 말고 다른 Vector DB는 언제 쓰나요?**\n",
        "\n",
        "     * **A4**: FAISS는 **라이브러리**이므로, 직접 시스템을 구축하고 관리해야 합니다. 반면 Milvus, Pinecone, Weaviate 등은 **독립적인 데이터베이스 시스템**(오픈소스 또는 클라우드 서비스)으로, 데이터 저장/관리, 분산 처리, API 제공 등 더 많은 기능을 포함하고 있어 **대규모 운영 환경**에 더 적합할 수 있습니다. 🔵 프로젝트 규모, 관리 편의성, 필요한 기능 등을 고려하여 선택합니다.\n",
        "\n",
        "\n",
        "\n",
        " * **Q5: FAISS에서 벡터 ID는 어떻게 관리하나요?**\n",
        "\n",
        "     * **A5**: 기본적으로 FAISS 인덱스에 벡터를 `add`하면 **추가된 순서대로 0부터 시작하는 내부 ID**가 부여됩니다. ✨ 검색 결과(`I` 배열)로 이 내부 ID가 반환됩니다. 만약 원래 데이터의 고유 ID(예: 문서 ID, 이미지 ID)와 매핑하려면, 별도의 매핑 정보(예: Python 딕셔너리나 다른 DB 테이블)를 유지해야 합니다. `IndexIDMap` 같은 FAISS 기능을 사용하여 직접 ID를 매핑할 수도 있습니다. 🔗"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3VPLHAwFcyA"
      },
      "source": [
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ## 🔑 5교시 핵심 정리\n",
        "\n",
        "\n",
        "\n",
        " * **벡터 임베딩**: 데이터(텍스트, 이미지 등) → **의미/특징 담은 숫자 벡터**로 변환 (AI 모델 사용). 🧠🔢\n",
        "\n",
        " * **Vector DB 필요성**: 기존 DB의 한계 극복 → 대규모 벡터 **저장** + **의미 기반 유사도 검색** 최적화. 🚀 (RDB/NoSQL 보완)\n",
        "\n",
        " * **유사도 검색**: 쿼리 벡터와 DB 벡터 간 **거리/유사도** 계산 → 가까운 벡터 찾기. (L2 거리↓, 코사인 유사도↑수록 유사) ✨↔️\n",
        "\n",
        " * **ANN (Approximate Nearest Neighbor)**: **속도** 위해 약간의 정확도 희생 → 대규모 데이터 실시간 검색 가능. ⚡️ (Vector DB 핵심 기술)\n",
        "\n",
        " * **FAISS**: 고성능 벡터 유사도 검색 **라이브러리**. (CPU/GPU 지원)\n",
        "\n",
        "     * **인덱스 생성**: `faiss.IndexFlatL2(dim)` (기본, 정확 검색)\n",
        "\n",
        "     * **벡터 추가**: `index.add(vectors)` (NumPy 배열 입력, 내부 ID 0부터 부여) ➕\n",
        "\n",
        "     * **벡터 검색**: `index.search(query, k)` → `(Distances, Indices)` 반환. 🔍 (결과 해석 중요)\n",
        "\n",
        " * **AI 활용**: **RAG**, 추천, 시맨틱 검색, 이미지 검색 등 **의미**를 다루는 AI 서비스의 핵심 기반 기술. 🤖👍"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MRZ1G85FcyA"
      },
      "source": [
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ## 💭 5교시 마무리\n",
        "\n",
        "\n",
        "\n",
        " 이번 시간에는 AI 시대의 핵심 데이터 기술인 **Vector DB**의 필요성과 기본 원리를 배웠습니다. **벡터 임베딩** 개념을 복습하고, **유사도 검색**과 **ANN**의 개념을 이해했습니다.\n",
        "\n",
        "\n",
        "\n",
        " 특히 Python 라이브러리인 **FAISS**를 사용하여 직접 **샘플 벡터를 생성하고, 인덱스에 추가하며, 유사 벡터를 검색**하는 실습을 통해 Vector DB의 기본적인 작동 방식을 체험했습니다.\n",
        "\n",
        "\n",
        "\n",
        " Vector DB와 유사도 검색 기술은 RAG, 추천 시스템 등 다양한 최신 AI 서비스를 구현하는 데 필수적입니다. 오늘 배운 내용을 바탕으로 앞으로 AI 프로젝트에서 '의미'를 기반으로 데이터를 효과적으로 활용하는 방법을 고민해보시길 바랍니다.\n",
        "\n",
        "\n",
        "\n",
        " **다음 6교시에는 데이터가 AI 모델에 활용되기까지의 여정(ETL)과 대규모 데이터 처리(Big Data) 개념, 그리고 다양한 DB 설계 원칙들을 종합적으로 살펴보겠습니다.**\n",
        "\n",
        "\n",
        "\n",
        " ### 🚀 더 나아가기 (5교시 복습)\n",
        "\n",
        "\n",
        "\n",
        " * FAISS의 `IndexFlatL2` 대신, ANN을 사용하는 인덱스 종류(예: `IndexIVFFlat`)를 검색해보고, 어떤 파라미터들이 필요한지 확인해보세요. (`nlist`, `nprobe` 등)\n",
        "\n",
        " * 코사인 유사도(Cosine Similarity)를 사용하여 검색하는 FAISS 인덱스(`IndexFlatIP` 또는 `IndexFlat(..., faiss.METRIC_INNER_PRODUCT)` + 벡터 정규화)는 어떻게 생성하고 사용하는지 알아보세요.\n",
        "\n",
        " * 실제 텍스트나 이미지 데이터를 임베딩 벡터로 변환해주는 사전 학습된 모델(Hugging Face Transformers 라이브러리 등 활용)을 찾아보고, 간단하게 사용해보세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQp9j-vIFcyA"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "# (FAISS 실습에서 사용한) DB 연결 객체가 없으므로 종료 코드는 불필요.\n",
        "# 혹시 이전 교시의 conn 객체가 남아있을 수 있으니 확인 및 종료.\n",
        "try:\n",
        "    if 'conn' in locals() and conn:\n",
        "        conn.close()\n",
        "        print(\"\\n(이전 교시) SQLite 데이터베이스 연결이 해제되었습니다.\")\n",
        "except Exception as e:\n",
        "     pass # 오류 발생해도 조용히 넘어감\n",
        "\n",
        "print(\"\\n5교시 내용 완료.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fpIu6x0FcyA"
      },
      "source": [
        " # 6교시: 데이터 관리 확장 - DW, ETL, Big Data 개념과 DB 설계 원칙\n",
        "\n",
        "\n",
        "\n",
        " ## 🎯 6교시 수업 목표\n",
        "\n",
        "\n",
        "\n",
        " 오늘 수업을 통해 여러분은 다음을 할 수 있게 됩니다:\n",
        "\n",
        "\n",
        "\n",
        " 1.  **데이터 웨어하우스(DW)** 의 개념과 **운영 DB와의 차이점**(분석 목적) 설명하기. 🤔🏦\n",
        "\n",
        " 2.  **ETL(추출-변환-로드)** 프로세스의 각 단계를 이해하고, **AI 모델 데이터 준비** 과정에서의 중요성 설명하기. ⚙️✨\n",
        "\n",
        " 3.  **빅데이터(Big Data)** 의 특징(**3V**)과 주요 기술(**Hadoop, Spark** 등 이름 인지) 개념적으로 이해하기. 🌊📈\n",
        "\n",
        " 4.  **RDBMS**와 **Vector DB**의 **설계 목표 차이**(정규화 vs. 성능 최적화)를 **복습**하고 비교 설명하기. ⚖️🎨\n",
        "\n",
        " 5.  RDBMS 스키마와 Vector DB 저장 정보 예시를 보고 **설계 방식의 차이점**을 **분석**하고 설명하기 (개념적). ↔️\n",
        "\n",
        "\n",
        "\n",
        " > ✨ **심화 목표**\n",
        "\n",
        " >\n",
        "\n",
        " > * 데이터 레이크(Data Lake)와 데이터 웨어하우스(DW)의 차이점 비교 설명하기.\n",
        "\n",
        " > * ETL 도구(Airflow, Talend 등)의 종류와 역할 알아보기.\n",
        "\n",
        " > * 다양한 Vector DB 인덱스 유형에 따른 성능/메모리 트레이드오프 이해하기."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XxP6kSkFcyA"
      },
      "source": [
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ## 📚 개념 설명 (핵심 요약)\n",
        "\n",
        "\n",
        "\n",
        " 이전 시간까지 다양한 종류의 데이터베이스와 기본적인 사용법을 배웠습니다.\n",
        "\n",
        " 이번 시간에는 데이터가 실제로 어떻게 흘러가고 분석/활용되는지 더 넓은 관점에서 살펴봅니다.\n",
        "\n",
        " 데이터 웨어하우스(DW), ETL 프로세스, 빅데이터 개념을 이해하고,\n",
        "\n",
        " 다양한 DB 설계 원칙들을 복습하며 트레이드오프를 인지하는 데 초점을 맞춥니다.\n",
        "\n",
        "\n",
        "\n",
        " ### 1. 데이터 웨어하우스 (Data Warehouse, DW) 🏦\n",
        "\n",
        "\n",
        "\n",
        " * **개념**: 의사 결정을 지원하기 위해, 다양한 **운영 시스템(Operational DB 등)** 에서 데이터를 **수집, 통합, 변환**하여 **주제 중심적**으로 저장하는 **분석용 데이터 저장소**. 📈\n",
        "\n",
        " * **목적**: 비즈니스 인텔리전스(BI), 리포팅, 데이터 분석 등 **정보 기반 의사 결정 지원**. 🤔💡\n",
        "\n",
        " * **운영 DB (OLTP) vs. DW (OLAP)**:\n",
        "\n",
        "\n",
        "\n",
        " #### 📊 운영 DB(OLTP) vs. 데이터 웨어하우스(OLAP)\n",
        "\n",
        "\n",
        "\n",
        "| 특징             | 운영 DB (OLTP¹)                     | 데이터 웨어하우스 (OLAP²)             |\n",
        "| :--------------- | :----------------------------------- | :------------------------------------ |\n",
        "| **주요 목적** | **실시간 거래 처리**, 서비스 운영       | **분석 및 리포팅**, 의사 결정 지원     |\n",
        "| **데이터** | 현재 시점, 상세 데이터               | **과거 데이터 포함**, 요약/집계 데이터 |\n",
        "| **작업 유형** | 빠른 읽기/쓰기 (단순 트랜잭션)        | **복잡한 쿼리**, 읽기 위주 (분석)       |\n",
        "| **데이터 구조** | 정규화 수준 높음 (중복 최소화)       | 비정규화/부분 정규화 가능 (성능 위해) |\n",
        "| **사용자** | 서비스 이용자, 운영 담당자          | **데이터 분석가**, 의사 결정권자        |\n",
        "\n",
        "\n",
        "\n",
        "     ¹ OLTP: Online Transaction Processing\n",
        "\n",
        "     ² OLAP: Online Analytical Processing\n",
        "\n",
        "\n",
        "\n",
        "   ![시각 자료 삽입: 운영 DB -> ETL -> DW -> BI/분석 도구 아키텍처 그림](https://brainstation-23.com/wp-content/uploads/2021/10/1.png)\n",
        "\n",
        " * **AI 연관성**: DW에 잘 정리된 과거 데이터를 사용하여 **AI 모델 학습**을 하거나, 비즈니스 분석 결과를 **AI 예측 모델의 Feature**로 활용 가능. 🤖"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agZ1qG5kFcyA"
      },
      "source": [
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ## ❓ 퀴즈 1: 데이터 웨어하우스의 목적\n",
        "\n",
        "\n",
        "\n",
        " ### 🧐 객관식 문제 1 (난이도: ⭐️⭐️)\n",
        "\n",
        "\n",
        "\n",
        " 데이터 웨어하우스(Data Warehouse)의 **주된** 목적은 무엇인가요?\n",
        "\n",
        "\n",
        "\n",
        " 1.  실시간으로 발생하는 웹 서비스의 사용자 요청을 최대한 빠르게 처리하는 것.\n",
        "\n",
        " 2.  다양한 소스에서 수집된 데이터를 분석 및 리포팅하여 의사 결정을 지원하는 것.\n",
        "\n",
        " 3.  데이터의 중복을 완벽하게 제거하기 위해 최고 수준의 정규화를 적용하는 것.\n",
        "\n",
        " 4.  데이터베이스 스키마를 최대한 유연하게 만들어 잦은 변경에 쉽게 대응하는 것.\n",
        "\n",
        " 5.  최신 시점의 상세한 트랜잭션 데이터를 저장하고 관리하는 것.\n",
        "\n",
        "\n",
        "\n",
        " ### <h3>정답 및 해설</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDLkJJL5FcyA"
      },
      "source": [
        " **정답: 2번**\n",
        "\n",
        "\n",
        "\n",
        " **해설:** 데이터 웨어하우스의 핵심 목적은 여러 운영 시스템에서 데이터를 모아 **분석**하고, 그 결과를 바탕으로 **의사 결정**을 돕는 것입니다. 🔵\n",
        "\n",
        " 1번과 5번은 운영 DB(OLTP)의 특징에 가깝습니다. 🔴\n",
        "\n",
        " 3번은 운영 DB 설계 시 고려 사항이며, DW는 분석 성능을 위해 반정규화를 하기도 합니다. 🔴\n",
        "\n",
        " 4번은 NoSQL DB의 특징에 가깝습니다. 🔴"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zamfnnCOFcyA"
      },
      "source": [
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ## 📚 개념 설명: 데이터의 여정 - ETL 프로세스 ⚙️\n",
        "\n",
        "\n",
        "\n",
        " 데이터는 원천(Source)에서 바로 분석이나 AI 모델 학습에 사용되기 어려운 경우가 많습니다.\n",
        "\n",
        " 이 데이터를 사용 가능한 형태로 **변환**하고 **목적지(Destination)** 로 옮기는 과정을 **ETL**이라고 합니다.\n",
        "\n",
        "\n",
        "\n",
        " * **ETL**: **Extract (추출)** → **Transform (변환)** → **Load (로드)** 의 약자.\n",
        "\n",
        "     ![시각 자료 삽입: ETL 프로세스 흐름도 (Source DBs -> Extract -> Transform -> Load -> Target DW/DB)](https://cloudyuga.guru/wp-content/uploads/2024/12/ETL-Figure.png)\n",
        "\n",
        "\n",
        "\n",
        " * **1. 추출 (Extract)** 📥\n",
        "\n",
        "     * **개념**: 다양한 원천 시스템(운영 DB, 로그 파일, API, 센서 등)에서 필요한 데이터를 **가져오는** 단계.\n",
        "\n",
        "     * **고려 사항**: 데이터 소스 종류, 추출 주기(실시간/배치), 변경 데이터만 추출(CDC) 등.\n",
        "\n",
        "\n",
        "\n",
        " * **2. 변환 (Transform)** ✨🔧\n",
        "\n",
        "     * **개념**: 추출된 데이터를 **사용 목적에 맞게 가공하고 변환**하는 **가장 핵심적인** 단계. ✨\n",
        "\n",
        "     * **주요 작업**:\n",
        "\n",
        "         * **데이터 정제 (Cleansing)**: 오류 수정, 결측치 처리, 단위 표준화 등.\n",
        "\n",
        "         * **데이터 통합 (Integration)**: 여러 소스의 데이터 결합 (JOIN 등).\n",
        "\n",
        "         * **데이터 형식 변환**: 날짜 형식 변경, 코드 값 변환 등.\n",
        "\n",
        "         * **계산 및 집계**: 새로운 파생 변수 생성, 요약/통계 정보 계산.\n",
        "\n",
        "         * **구조 변경**: 데이터 형식 변경 (예: JSON → 테이블), 정규화/반정규화 등.\n",
        "\n",
        "     * **AI 연관성**: **AI 모델 학습 데이터 준비**에서 가장 많은 시간이 소요되는 부분! 🤖 Feature Engineering, 데이터 스케일링, 레이블링 등이 이 단계에서 수행될 수 있음. 🔵\n",
        "\n",
        "\n",
        "\n",
        " * **3. 로드 (Load)** 💾\n",
        "\n",
        "     * **개념**: 변환된 데이터를 최종 목적지(데이터 웨어하우스, 데이터 마트, 운영 DB, Vector DB 등)에 **저장(적재)**하는 단계.\n",
        "\n",
        "     * **고려 사항**: 전체 로드(Full Load) vs 증분 로드(Incremental Load), 로딩 성능, 데이터 검증 등.\n",
        "\n",
        "\n",
        "\n",
        " * **중요성**: ETL 프로세스를 잘 설계하고 구축해야 **데이터의 품질과 신뢰성**을 확보하고, **효율적인 분석 및 AI 모델링**이 가능해짐. 🔵 (Garbage In, Garbage Out 방지!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sd8GgoJNFcyA"
      },
      "source": [
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ## 📚 개념 설명: 빅데이터 (Big Data) 와 기술 개요 🌊📈\n",
        "\n",
        "\n",
        "\n",
        " 현대 사회에서는 이전과는 비교할 수 없을 정도로 **엄청난 양과 속도, 다양성**을 가진 데이터가 생성되고 있습니다. 이를 **빅데이터**라고 부릅니다.\n",
        "\n",
        "\n",
        "\n",
        " * **빅데이터 특징 (3V)**: (최근에는 4V, 5V 등 추가 정의도 있음)\n",
        "\n",
        "\n",
        "\n",
        "  #### 📊 빅데이터의 3가지 특징 (3V)\n",
        "\n",
        "\n",
        "\n",
        "  | 특징        | 설명                                        | 예시                                          |\n",
        "  | :---------- | :------------------------------------------ | :-------------------------------------------- |\n",
        "  | **Volume (양)** | 생성/저장되는 데이터의 **규모**가 매우 큼.   | 페타바이트(PB), 엑사바이트(EB) 단위 데이터   |\n",
        "  | **Velocity (속도)** | 데이터가 생성되고 처리되는 **속도**가 매우 빠름. | 실시간 스트리밍 데이터 (센서, 로그, 금융 거래) |\n",
        "  | **Variety (다양성)** | 데이터의 **형태**가 매우 다양함.           | 정형(DB 테이블), 반정형(JSON, XML), 비정형(텍스트, 이미지, 영상) |\n",
        "\n",
        "\n",
        "\n",
        "  ![시각 자료 삽입: 3V 개념 시각화 도표](https://blog.kakaocdn.net/dn/bnwdg5/btqZ2cUwiaD/ag3WwRlkCpx5V0U2AfKaYk/img.png)\n",
        "\n",
        "\n",
        "\n",
        " * **도전 과제**: 기존의 데이터 처리 방식(단일 서버 RDBMS 등)으로는 빅데이터를 **효율적으로 저장, 처리, 분석하기 어려움**. 🔴 (처리 시간, 비용, 확장성 문제)\n",
        "\n",
        "\n",
        "\n",
        " * **주요 기술 (이름 인지 수준)**: 빅데이터 문제를 해결하기 위한 기술들.\n",
        "\n",
        "     * **분산 파일 시스템 (Distributed File System)**: 대용량 파일을 여러 서버에 **나누어 저장**. (예: **HDFS** - Hadoop Distributed File System) 💾💾💾\n",
        "\n",
        "     * **분산 처리 프레임워크 (Distributed Processing Framework)**: 대규모 데이터를 여러 서버에서 **병렬로 처리**. (예: **MapReduce**, **Apache Spark** ✨) ⚙️⚙️⚙️\n",
        "\n",
        "     * **NoSQL 데이터베이스**: 대규모 데이터 저장 및 빠른 처리/확장성 지원. (앞서 배움)\n",
        "\n",
        "     * **클라우드 플랫폼**: AWS, GCP, Azure 등에서 빅데이터 처리 위한 다양한 서비스 제공. ☁️\n",
        "\n",
        "\n",
        "\n",
        " * **AI 연관성**: AI, 특히 딥러닝 모델은 **대규모 데이터(빅데이터)** 를 학습할 때 더 좋은 성능을 보이는 경우가 많음. 🤖 빅데이터 처리 기술은 AI 모델 학습 데이터 준비 및 분석에 필수적으로 활용됨. 🔵"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4Xutcu2FcyA"
      },
      "source": [
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ## ❓ 퀴즈 2: ETL 약자 확인\n",
        "\n",
        "\n",
        "\n",
        " ### ✍️ 단답형 문제 2 (난이도: ⭐️)\n",
        "\n",
        "\n",
        "\n",
        " ETL 프로세스는 데이터 처리의 중요한 단계를 나타냅니다. ETL은 각각 무엇의 약자인가요? (세 단어를 순서대로 작성)\n",
        "\n",
        "\n",
        "\n",
        " ### <h3>정답 및 해설</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cX7J4i8eFcyA"
      },
      "source": [
        " **정답:** Extract (추출), Transform (변환), Load (로드)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7R5idMAFcyA"
      },
      "source": [
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ## 📚 개념 설명: DB 설계 원칙 복습 및 비교 🤔⚖️\n",
        "\n",
        "\n",
        "\n",
        " 이전 시간들에서 배운 다양한 데이터베이스들의 설계 목표는 조금씩 다릅니다.\n",
        "\n",
        " 상황에 맞는 DB를 선택하고 설계하는 것이 중요합니다.\n",
        "\n",
        "\n",
        "\n",
        " * **RDBMS 설계 원칙 (복습)**:\n",
        "\n",
        "     * **핵심 목표**: 데이터 **중복 최소화** 및 **무결성/일관성** 극대화. ✨\n",
        "\n",
        "     * **주요 기법**: **정규화 (Normalization)**. 🔵\n",
        "\n",
        "         * 1NF → 2NF → 3NF 과정을 통해 중복 및 이상 현상 제거 시도.\n",
        "\n",
        "         * 결과: 테이블이 여러 개로 분리됨 → 데이터 일관성 향상, 저장 공간 효율화.\n",
        "\n",
        "         * 단점: 여러 테이블 JOIN 필요 → 복잡한 조회 시 성능 저하 가능성. 🔴\n",
        "\n",
        "\n",
        "\n",
        " * **Vector DB 설계 고려 사항 (복습)**:\n",
        "\n",
        "     * **핵심 목표**: 대규모 벡터 데이터의 **빠른 유사도 검색** 성능 최적화. 🚀\n",
        "\n",
        "     * **주요 고려 사항**:\n",
        "\n",
        "         * **벡터 저장**: 고차원 벡터 자체를 효율적으로 저장.\n",
        "\n",
        "         * **메타데이터 연결**: 벡터와 관련된 원본 데이터 정보(예: 문서 ID, 텍스트 내용, 생성일)를 어떻게 연결할 것인가?\n",
        "\n",
        "             * 방법 1: Vector DB 내에 메타데이터 함께 저장 (지원하는 경우).\n",
        "\n",
        "             * 방법 2: Vector DB에는 벡터와 **고유 ID**만 저장하고, 상세 메타데이터는 **별도의 RDB/NoSQL DB**에 저장 후 ID로 연결(JOIN). ✨ (Hybrid 구조)\n",
        "\n",
        "         * **인덱스 선택 및 튜닝**: ANN 알고리즘 기반 인덱스 유형(FAISS의 `IndexIVFFlat` 등)과 파라미터(`nlist`, `nprobe` 등)를 데이터 특성과 요구 성능(속도 vs 정확도)에 맞게 선택/조정. ⚙️ (성능에 매우 큰 영향!)\n",
        "\n",
        "         * **Trade-off**: 검색 속도 향상 ↔️ 인덱스 구축 시간/메모리 사용량 / 검색 정확도. ⚖️\n",
        "\n",
        "\n",
        "\n",
        " * **설계 목표의 차이**:\n",
        "\n",
        "     * RDBMS(정규화)는 **데이터의 정합성/일관성**을 최우선으로 고려하는 경향.\n",
        "\n",
        "     * Vector DB는 **검색 성능(속도/처리량)** 을 최우선으로 고려하는 경향.\n",
        "\n",
        "     * NoSQL은 **유연성/확장성/특정 워크로드 성능**을 우선시하는 경향.\n",
        "\n",
        "\n",
        "\n",
        " > **결론**: 어떤 DB를 사용하든, **데이터의 특성**과 **서비스의 요구사항**(성능, 일관성, 확장성 등)을 고려하여 **적절한 설계 원칙**과 **트레이드오프**를 이해하고 적용해야 합니다. 🔵"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kG7BVL3KFcyA"
      },
      "source": [
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ## 💻 실습 1: [개념 비교] RDBMS 스키마 vs. Vector DB 저장 정보 분석\n",
        "\n",
        "\n",
        "\n",
        " **시나리오**: 뉴스 기사 텍스트를 저장하고, 특정 기사와 내용이 유사한 다른 기사를 찾는 AI 서비스를 만든다고 가정합시다.\n",
        "\n",
        "\n",
        "\n",
        " 아래는 이 시나리오를 위해 RDBMS와 Vector DB를 **함께 사용하는 하이브리드 방식**을 고려할 때, 각 DB에 어떤 정보가 저장될지 보여주는 예시입니다. 두 방식의 차이점을 비교 분석해 보세요. (코딩 X, 개념적 비교)\n",
        "\n",
        "\n",
        "\n",
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ### 1. RDBMS (예: PostgreSQL) - 메타데이터 저장용\n",
        "\n",
        "\n",
        "\n",
        " **`articles` 테이블 스키마:**\n",
        "\n",
        "\n",
        "\n",
        "| Column Name     | Data Type        | Constraints                   | Description         |\n",
        "| :-------------- | :--------------- | :---------------------------- | :------------------ |\n",
        "| `article_id`    | `SERIAL`         | `PRIMARY KEY`                 | 기사 고유 ID (자동 증가) |\n",
        "| `title`         | `VARCHAR(255)`   | `NOT NULL`                    | 기사 제목           |\n",
        "| `content`       | `TEXT`           |                               | 기사 본문 (길 수 있음) |\n",
        "| `category`      | `VARCHAR(50)`    |                               | 기사 카테고리       |\n",
        "| `published_date`| `TIMESTAMP`      |                               | 발행 일시           |\n",
        "| `source`        | `VARCHAR(100)`   |                               | 출처 언론사         |\n",
        "\n",
        "\n",
        "\n",
        " * **특징**:\n",
        "\n",
        "     * 각 기사의 상세 정보(텍스트 내용 포함)를 **정형화된 구조**로 저장.\n",
        "\n",
        "     * `article_id`를 **기본 키(PK)** 로 사용하여 각 기사를 고유하게 식별.\n",
        "\n",
        "     * 필요시 다른 테이블(예: `authors` 테이블)과 **관계(FK)** 를 맺을 수 있음.\n",
        "\n",
        "     * 데이터의 **일관성**과 **정확성** 유지에 유리. 🔵\n",
        "\n",
        "\n",
        "\n",
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ### 2. Vector DB (예: FAISS + 별도 매핑 정보 또는 Milvus/Pinecone 등) - 유사도 검색용\n",
        "\n",
        "\n",
        "\n",
        " **저장 정보 (개념적):**\n",
        "\n",
        "\n",
        "\n",
        " | 정보 유형             | 예시 데이터                               | 설명                                                       |\n",
        " | :-------------------- | :---------------------------------------- | :--------------------------------------------------------- |\n",
        " | **벡터 ID (Vector ID)** | `1`, `2`, `3`, ... (또는 RDBMS의 `article_id` 사용) | 각 벡터를 식별하는 고유 ID. RDBMS의 PK와 연결되는 역할. 🔑 |\n",
        " | **벡터 임베딩** | `[0.12, -0.45, ..., 0.88]` (고차원 배열)   | 기사 내용(`content`)을 AI 모델로 변환한 **의미 벡터**. 🧠🔢   |\n",
        " | (선택적) 메타데이터   | `{\"category\": \"IT\", \"source\": \"ABC News\"}` | 빠른 필터링 등을 위해 Vector DB 내에 함께 저장하기도 함.   |\n",
        "\n",
        "\n",
        "\n",
        " * **특징**:\n",
        "\n",
        "     * 기사 내용 자체가 아닌, 내용의 **의미를 함축한 벡터**를 저장.\n",
        "\n",
        "     * **빠른 유사도 검색**에 최적화된 인덱스 구조 사용 (ANN 등). 🚀\n",
        "\n",
        "     * 벡터 ID를 통해 RDBMS의 **상세 메타데이터와 연결**. 🔗\n",
        "\n",
        "     * 주로 **검색 성능**을 최우선 목표로 설계. 🔵\n",
        "\n",
        "\n",
        "\n",
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ### 🤔 비교 분석 질문\n",
        "\n",
        "\n",
        "\n",
        " 1.  RDBMS와 Vector DB는 각각 **어떤 종류의 데이터**를 주로 저장하나요?\n",
        "\n",
        " 2.  \"특정 키워드('AI')가 포함된 기사 목록\"을 찾는 작업은 어떤 DB에서 더 효율적일까요? 이유는?\n",
        "\n",
        " 3.  \"A 기사와 내용이 가장 유사한 기사 5개\"를 찾는 작업은 어떤 DB에서 더 효율적일까요? 이유는?\n",
        "\n",
        " 4.  두 DB를 함께 사용할 때, **`article_id`**(또는 Vector ID)는 어떤 중요한 역할을 하나요?\n",
        "\n",
        "\n",
        "\n",
        " ### <h3>정답 및 해설 (개념적 설명)</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZ7EP9c5FcyA"
      },
      "source": [
        " 1.  **RDBMS**: 기사의 **상세 메타데이터**(제목, 본문 텍스트, 카테고리, 날짜 등)처럼 **구조화된 정보**를 주로 저장합니다.\n",
        "\n",
        "     **Vector DB**: 기사 내용의 **의미를 나타내는 벡터 임베딩**과 해당 벡터를 식별하는 **ID**를 주로 저장합니다. (부가적인 메타데이터 저장 가능)\n",
        "\n",
        "\n",
        "\n",
        " 2.  **RDBMS**에서 더 효율적일 수 있습니다. RDBMS는 텍스트 내용에 대한 **키워드 검색**(예: `WHERE content LIKE '%AI%'`) 기능을 잘 지원하며, 필요시 전문 검색(Full-text search) 인덱스를 활용할 수도 있습니다. Vector DB는 키워드 일치보다는 의미 유사성 검색에 특화되어 있습니다.\n",
        "\n",
        "\n",
        "\n",
        " 3.  **Vector DB**에서 훨씬 효율적입니다. 🚀 Vector DB의 핵심 기능이 바로 **유사도 검색**이기 때문입니다. A 기사의 벡터 임베딩을 쿼리로 사용하여 벡터 공간에서 가장 가까운(유사한) 다른 기사 벡터들을 빠르게 찾을 수 있습니다. RDBMS에서는 이런 의미 기반 유사도 검색을 직접 효율적으로 수행하기 어렵습니다.\n",
        "\n",
        "\n",
        "\n",
        " 4.  **연결 고리(Bridge)** 역할을 합니다. 🔗 Vector DB에서 유사한 벡터를 찾으면 그 결과로 벡터 ID(예: RDBMS의 `article_id`)를 얻게 됩니다. 이 ID를 사용하여 RDBMS의 `articles` 테이블을 조회하면, 해당 기사의 제목, 본문 내용 등 **상세 정보를 최종적으로 가져올 수 있습니다**. 즉, 두 종류의 DB에 나뉘어 저장된 정보를 하나로 합쳐 사용자에게 보여주는 데 사용됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_cw2lmsFcyB"
      },
      "source": [
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ## ❓ F.A.Q (6교시 궁금증 해소)\n",
        "\n",
        "\n",
        "\n",
        " * **Q1: 데이터 웨어하우스(DW)랑 데이터 레이크(Data Lake)는 다른 건가요?**\n",
        "\n",
        "     * **A1**: 네, 다릅니다. 🌊 **데이터 레이크**는 정형/반정형/비정형 데이터를 **원본 형태 그대로** 일단 저장하는 거대한 저장소입니다 (Schema-on-Read). 반면 **DW**는 데이터를 **정제/변환**하여 **구조화된 형태**로 저장하여 분석을 용이하게 합니다 (Schema-on-Write). 데이터 레이크는 원본 보존 및 유연성에, DW는 분석 편의성/성능에 강점이 있습니다. 최근에는 두 개념을 결합한 레이크하우스(Lakehouse) 아키텍처도 등장했습니다.\n",
        "\n",
        "\n",
        "\n",
        " * **Q2: ETL은 꼭 필요한 과정인가요? 데이터를 그냥 바로 쓰면 안 되나요?**\n",
        "\n",
        "     * **A2**: **대부분의 경우 필요합니다.** ✨ 원천 데이터는 오류가 있거나 형식이 다르거나 불필요한 정보가 섞여 있는 등 **그대로 사용하기 어려운( 지저분한 Dirty)** 경우가 많습니다. ETL의 **변환(Transform)** 과정을 통해 데이터를 **정제하고 표준화**해야 분석 결과의 신뢰성을 높이고 AI 모델의 성능을 제대로 끌어올릴 수 있습니다. (Garbage In, Garbage Out!)\n",
        "\n",
        "\n",
        "\n",
        " * **Q3: Hadoop이랑 Spark는 뭐가 다른 건가요?**\n",
        "\n",
        "     * **A3**: 둘 다 **빅데이터 분산 처리** 기술이지만, 처리 방식에 차이가 있습니다. ⚙️ **Hadoop(MapReduce)** 은 주로 디스크 기반으로 처리하여 대용량 배치 처리에 강점이 있었지만 느린 편이었습니다. 🐌 **Spark**는 **메모리 기반 처리**를 도입하여 Hadoop보다 훨씬 빠른 속도🚀를 제공하며, 스트리밍, 머신러닝 등 다양한 처리를 지원하여 현재 빅데이터 처리의 **사실상 표준**으로 자리 잡았습니다. Spark는 HDFS 외 다른 저장소와도 연동 가능합니다.\n",
        "\n",
        "\n",
        "\n",
        " * **Q4: DB 설계할 때 정규화랑 성능 중 뭐가 더 중요한가요?**\n",
        "\n",
        "     * **A4**: **정답은 없습니다. 상황에 따라 다릅니다!** ⚖️ 초기 설계 시에는 **정규화**를 통해 데이터 무결성을 확보하는 것이 좋습니다. 🔵 하지만 서비스 운영 중 특정 쿼리의 **성능**이 매우 중요하고 느리다면, **반정규화**(의도적으로 중복 허용 또는 테이블 합병)나 **인덱싱** 등을 통해 성능 개선을 고려해야 합니다. 🔴 중요한 것은 각 선택의 **장단점(Trade-off)** 을 이해하고, **서비스의 요구사항**에 맞춰 균형점을 찾는 것입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tY6PxVYFcyB"
      },
      "source": [
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ## 🔑 6교시 핵심 정리\n",
        "\n",
        "\n",
        "\n",
        " * **데이터 웨어하우스 (DW)**: 다양한 소스 데이터를 **통합/변환**하여 저장하는 **분석 목적**의 데이터 저장소. (운영 DB와 구분됨) 🏦📈\n",
        "\n",
        " * **ETL (Extract-Transform-Load)**: 데이터 여정의 핵심 프로세스. **추출 → 변환 → 로드**. ⚙️\n",
        "\n",
        "     * **Transform (변환)**: 데이터 정제, 통합, 계산 등 가장 중요! (AI 데이터 준비 핵심) ✨🔧\n",
        "\n",
        " * **빅데이터 (Big Data)**: **3V**(Volume, Velocity, Variety) 특징을 가진 거대 데이터. 🌊\n",
        "\n",
        "     * 기존 방식 처리 어려움 → **분산 기술**(HDFS, Spark 등) 활용. 🚀\n",
        "\n",
        " * **DB 설계 원칙 복습**:\n",
        "\n",
        "     * **RDBMS (정규화)**: **중복 최소화, 일관성/무결성** 목표. ✨ (JOIN 증가 가능성)\n",
        "\n",
        "     * **Vector DB**: **빠른 유사도 검색 성능** 목표. 🚀 (메타데이터 연결, 인덱스 튜닝 중요)\n",
        "\n",
        "     * **Trade-off**: 설계 목표에 따라 장단점 발생 → **요구사항 기반 균형** 필요. ⚖️\n",
        "\n",
        " * **하이브리드 설계**: RDBMS/NoSQL(메타데이터) + Vector DB(벡터) 조합 사용 흔함. ↔️"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaIIo8hKFcyB"
      },
      "source": [
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ## 💭 6교시 마무리\n",
        "\n",
        "\n",
        "\n",
        " 이번 시간에는 데이터가 생성되어 분석 및 활용되기까지의 **더 넓은 여정**을 살펴보았습니다. 분석을 위한 데이터 저장소인 **데이터 웨어하우스(DW)**, 데이터 준비 과정의 핵심인 **ETL 프로세스**, 그리고 대규모 데이터 시대의 **빅데이터** 개념과 관련 기술들을 간략히 소개했습니다.\n",
        "\n",
        "\n",
        "\n",
        " 또한, RDBMS와 Vector DB의 **설계 목표 차이**를 복습하고, 실제 시나리오에서 두 DB가 어떻게 **정보를 나누어 저장하고 연결**될 수 있는지 개념적으로 비교 분석해보았습니다. 이를 통해 상황에 맞는 DB 설계와 **트레이드오프**를 고려하는 것의 중요성을 다시 한번 확인했습니다.\n",
        "\n",
        "\n",
        "\n",
        " AI 모델의 성능은 결국 **데이터의 품질과 관리 방식**에 크게 의존합니다. 오늘 배운 내용들이 여러분이 AI 프로젝트에서 데이터를 바라보는 시야를 넓히는 데 도움이 되었기를 바랍니다.\n",
        "\n",
        "\n",
        "\n",
        " **다음 7교시(원래 8교시)에는 지금까지 배운 내용을 바탕으로, 실제 AI 서비스(예: RAG 챗봇)를 위한 데이터 파이프라인과 DB 통합 설계를 종합적으로 실습하고, 기본적인 보안 고려 사항을 되짚어보며 과정을 마무리하겠습니다.**\n",
        "\n",
        "\n",
        "\n",
        " ### 🚀 더 나아가기 (6교시 복습)\n",
        "\n",
        "\n",
        "\n",
        " * 간단한 Python 코드를 사용하여 가상의 CSV 파일에서 데이터를 읽어와(Extract), 특정 조건에 따라 데이터를 필터링하고(Transform), 그 결과를 다른 CSV 파일로 저장하는(Load) 초간단 ETL 파이프라인을 직접 작성해보세요. (Pandas 라이브러리 활용)\n",
        "\n",
        " * Apache Spark 공식 웹사이트나 문서를 방문하여 Spark가 어떤 종류의 데이터 처리 작업(배치, 스트리밍, ML 등)을 지원하는지 살펴보세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BP6ohKSoFcyB"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "# 이 교시는 별도의 Python 라이브러리나 DB 연결을 사용하지 않았으므로, 종료 코드는 불필요합니다.\n",
        "# 혹시 이전 교시의 conn 객체가 남아있을 수 있으니 확인 및 종료.\n",
        "try:\n",
        "    if 'conn' in locals() and conn:\n",
        "        conn.close()\n",
        "        print(\"\\n(이전 교시) SQLite 데이터베이스 연결이 해제되었습니다.\")\n",
        "except Exception as e:\n",
        "     pass # 오류 발생해도 조용히 넘어감\n",
        "\n",
        "print(\"\\n6교시 내용 완료.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oRxK621FcyB"
      },
      "source": [
        " # 7교시: AI 파이프라인과 DB 통합 - 설계 실습 및 종합\n",
        "\n",
        "\n",
        "\n",
        " ## 🎯 7교시 수업 목표\n",
        "\n",
        "\n",
        "\n",
        " 오늘 수업을 통해 여러분은 다음을 할 수 있게 됩니다:\n",
        "\n",
        "\n",
        "\n",
        " 1.  **머신러닝(ML) 데이터 파이프라인**의 주요 단계를 이해하고, 각 단계에서 **데이터베이스의 역할** 설명하기. 🌊⚙️💾\n",
        "\n",
        " 2.  **하이브리드 데이터베이스 아키텍처**(예: RDBMS + Vector DB)의 개념을 이해하고, **AI 서비스(RAG)** 에 적용하는 방법 설명하기. ↔️🧱\n",
        "\n",
        " 3.  주어진 AI 서비스(RAG 챗봇) 요구사항에 맞춰 필요한 **데이터 흐름을 분석**하고, 적절한 **DB 스키마/정보를 개념적으로 설계(스케치)**하기. 🎨✍️\n",
        "\n",
        " 4.  **SQL Injection** 공격의 기본 원리를 이해하고, **예방**의 중요성 인지하기. 🛡️🚫\n",
        "\n",
        " 5.  과정 전체에서 배운 **핵심 기술**(SQL, NoSQL, Vector DB 등)을 **요약**하고, 향후 학습 방향 설정하기. 🗺️✨\n",
        "\n",
        "\n",
        "\n",
        " > ✨ **심화 목표**\n",
        "\n",
        " >\n",
        "\n",
        " > * 다양한 데이터 파이프라인 구축 도구(Airflow, Kubeflow 등)의 역할 이해하기.\n",
        "\n",
        " > * RAG 외 다른 AI 서비스(예: 추천 시스템)의 데이터 아키텍처 설계해보기.\n",
        "\n",
        " > * SQL Injection 외 다른 데이터베이스 보안 위협(접근 통제, 암호화 등) 종류 알아보기."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQs_5akKFcyB"
      },
      "source": [
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ## 📚 개념 설명 (핵심 요약)\n",
        "\n",
        "\n",
        "\n",
        " ### 1. 머신러닝(ML) 데이터 파이프라인 🌊⚙️💾\n",
        "\n",
        "\n",
        "\n",
        " AI 모델을 개발하고 운영하는 과정은 단순히 모델 코드만 작성하는 것이 아닙니다.\n",
        "\n",
        " **데이터**가 중심이 되어 여러 단계를 거쳐 흘러가는 **파이프라인(Pipeline)** 형태로 진행됩니다.\n",
        "\n",
        " 데이터베이스는 이 파이프라인의 여러 단계에서 핵심적인 역할을 수행합니다.\n",
        "\n",
        "\n",
        "\n",
        " * **개념**: 원천 데이터(Raw Data)에서 시작하여 AI 모델 학습 및 서비스 적용에 필요한 데이터로 **변환 및 이동**되는 일련의 **자동화된 과정**. (데이터 공장의 조립 라인과 유사 🏭)\n",
        "\n",
        "\n",
        "\n",
        " * **주요 단계 및 DB 역할**:\n",
        "\n",
        "\n",
        "\n",
        "     #### 📊 ML 데이터 파이프라인 단계별 DB 역할\n",
        "\n",
        "\n",
        "\n",
        "  | 단계                     | 설명                                                         | DB 역할 예시                                                                 | 관련 DB 기술 예시        |\n",
        "  | :----------------------- | :----------------------------------------------------------- | :--------------------------------------------------------------------------- | :--------------------- |\n",
        "  | **1. 데이터 수집 (Collect)** | 다양한 소스(DB, 파일, API, 센서 등)에서 원본 데이터 확보.         | 소스 데이터 저장소 (RDB, NoSQL 등)                                               | RDBMS, NoSQL, Data Lake |\n",
        "  | **2. 데이터 전처리/ETL** | 데이터 정제, 변환, Feature Engineering 등 (6교시 ETL 복습). ✨ | 원본 데이터 조회, **변환된 데이터/Feature 저장**.                                | RDBMS, DW, NoSQL       |\n",
        "  | **3. 데이터 저장 (Store)** | 전처리된 데이터를 모델 학습/분석에 용이하도록 저장.          | **학습 데이터셋 저장소**, Feature Store¹.                                       | RDBMS, DW, Vector DB   |\n",
        "  | **4. 모델 학습 (Train)** | 저장된 데이터를 사용하여 AI 모델 훈련.                       | 학습 데이터 **조회**.                                                          | (모든 DB 가능)         |\n",
        "  | **5. 결과 저장/배포** | 학습된 모델 정보, 평가 결과, 예측 결과 등 저장 및 서빙 준비. | **모델 메타데이터**, **예측 결과 로그**, 서빙용 캐시 등 저장.                   | RDBMS, NoSQL, Vector DB |\n",
        "\n",
        "\n",
        "\n",
        "     ¹ Feature Store: ML Feature를 저장, 관리, 공유하기 위한 중앙 저장소.\n",
        "\n",
        "\n",
        "\n",
        " * **AI 연관성**: 효과적인 데이터 파이프라인 구축은 AI 모델 개발의 **생산성, 재현성, 품질**을 높이는 데 매우 중요합니다. 🔵 DB는 이 파이프라인의 **데이터 흐름을 관리하고 지원**하는 핵심 인프라입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XRmNgSEFcyB"
      },
      "source": [
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ## ❓ 퀴즈 1: 데이터 파이프라인 단계\n",
        "\n",
        "\n",
        "\n",
        " ### ✍️ 단답형 문제 1 (난이도: ⭐️⭐️)\n",
        "\n",
        "\n",
        "\n",
        " 머신러닝 데이터 파이프라인의 주요 단계를 순서대로 3가지 이상 나열해 보세요. (예: 데이터 수집 → ... )\n",
        "\n",
        "\n",
        "\n",
        " ### <h3>정답 및 해설</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlMaBg_3FcyB"
      },
      "source": [
        " **정답 예시:** (아래 단계 중 3가지 이상 순서대로 나열)\n",
        "\n",
        " 1.  데이터 수집 (Collect)\n",
        "\n",
        " 2.  데이터 전처리 / ETL (Preprocess / Transform)\n",
        "\n",
        " 3.  데이터 저장 (Store)\n",
        "\n",
        " 4.  모델 학습 (Train)\n",
        "\n",
        " 5.  결과 저장 / 배포 (Store Results / Deploy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6diQ9cXFcyC"
      },
      "source": [
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ## 📚 개념 설명: 하이브리드 아키텍처와 RAG 예시 ↔️🧱🤖\n",
        "\n",
        "\n",
        "\n",
        " * **하이브리드 데이터베이스 아키텍처 (Hybrid DB Architecture)**:\n",
        "\n",
        "     * **개념**: 단일 종류의 데이터베이스만 사용하는 대신, **여러 종류의 DB**(예: RDBMS + NoSQL + Vector DB)를 **조합**하여 각 DB의 **강점을 활용**하는 설계 방식. 🔵\n",
        "\n",
        "     * **필요성**: 현대 애플리케이션(특히 AI 서비스)은 다양한 종류의 데이터와 요구사항(성능, 일관성, 유연성 등)을 가짐 → **하나의 DB로 모든 것을 만족시키기 어려움**. 🔴\n",
        "\n",
        "     * **장점**: 각 데이터 유형 및 처리 요구사항에 **최적화된 DB** 사용 → 전체 시스템 성능 및 효율성 향상. ✨\n",
        "\n",
        "     * **단점**: 시스템 복잡도 증가, 데이터 동기화 및 관리 어려움 증가 가능성. ⚠️\n",
        "\n",
        "\n",
        "\n",
        " * **AI 서비스 적용 예시: RAG 챗봇 (복습)**\n",
        "\n",
        "     * **RAG (Retrieval-Augmented Generation)**: 외부 지식 소스를 **검색(Retrieval)** 하여 그 정보를 바탕으로 LLM이 **답변을 생성(Generation)** 하는 기술. (5교시 Vector DB 참고)\n",
        "\n",
        "     * **데이터 흐름**:\n",
        "\n",
        "         1.  **사용자 질문** 입력.\n",
        "\n",
        "         2.  질문을 **벡터 임베딩**으로 변환.\n",
        "\n",
        "         3.  **Vector DB**에서 질문 벡터와 **유사한 문서 벡터 검색** → 관련 문서 **ID 목록** 획득. 🚀 (빠른 의미 검색)\n",
        "\n",
        "         4.  획득한 문서 ID를 사용하여 **RDBMS (또는 NoSQL)** 에서 해당 문서의 **실제 텍스트 내용** 및 메타데이터 조회. 🔍 (정확한 내용 조회)\n",
        "\n",
        "         5.  검색된 문서 내용 + 원래 질문 → **LLM 프롬프트** 구성.\n",
        "\n",
        "         6.  **LLM**이 프롬프트를 기반으로 최종 **답변 생성**. 🧠\n",
        "\n",
        "         7.  (선택적) 사용자 질문, LLM 답변, 사용된 문서 ID 등을 **로그 DB(RDBMS 또는 NoSQL)** 에 저장. 💾\n",
        "\n",
        "     * **하이브리드 구조**:\n",
        "\n",
        "         * **Vector DB**: 문서 벡터 저장, **빠른 유사도 검색** 담당.\n",
        "\n",
        "         * **RDBMS/NoSQL**: 원본 문서 내용, 메타데이터, 사용자 정보, 채팅 로그 등 **구조화/비구조화 데이터 저장 및 관리** 담당.\n",
        "\n",
        "         * ➡️ 각 DB가 **가장 잘하는 역할**을 분담하여 RAG 시스템 구현! 🔵"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4Lzx89fFcyC"
      },
      "source": [
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ## 💻 실습 1: [설계 스케치] RAG 챗봇 데이터 흐름 및 DB 설계 🎨✍️\n",
        "\n",
        "\n",
        "\n",
        " 위에서 설명한 **RAG 챗봇의 데이터 흐름**을 바탕으로, 각 단계에서 필요한 데이터와 이를 저장/관리하기 위한 **DB 스키마 또는 정보**를 **개념적으로 설계**해 보세요. 어떤 종류의 DB를 사용할지도 함께 고려합니다. (코딩 X, 텍스트/개념도 스케치)\n",
        "\n",
        "\n",
        "\n",
        " **설계 목표**: 사용자 질문 처리부터 답변 생성, 로그 기록까지 필요한 데이터를 어떻게 저장하고 연결할지 구상하기.\n",
        "\n",
        "\n",
        "\n",
        " **가이드**:\n",
        "\n",
        "\n",
        "\n",
        " 1.  **Vector DB**: 어떤 정보(벡터, ID 등)를 저장해야 할까요? ID는 무엇과 연결되어야 할까요?\n",
        "\n",
        " 2.  **RDBMS (또는 NoSQL)**: 원본 문서를 저장할 테이블(`documents`?)은 어떤 컬럼들을 가져야 할까요? (문서 ID, 내용, 출처 등)\n",
        "\n",
        " 3.  **RDBMS (또는 NoSQL)**: 채팅 로그를 저장할 테이블(`chat_logs`?)은 어떤 정보를 담아야 할까요? (로그 ID, 사용자 ID, 질문, 답변, 참조 문서 ID 목록 등)\n",
        "\n",
        " 4.  (선택적) 사용자 정보를 저장할 `users` 테이블은 어떤 모습일까요? 로그 테이블과 어떻게 연결될까요?\n",
        "\n",
        " 5.  각 테이블/정보 간의 **연결(관계)** 은 어떤 키(ID)를 통해 이루어질까요?\n",
        "\n",
        "\n",
        "\n",
        " > 여기에 여러분의 설계 스케치를 자유롭게 작성해보세요. (텍스트 설명, 간단한 표, 화살표 등 활용)\n",
        "\n",
        " > 예:\n",
        "\n",
        " > ```\n",
        "\n",
        " > **Vector DB (문서 임베딩 저장)**\n",
        "\n",
        " > - vector_id (INTEGER, PK, documents.doc_id 와 동일 값 사용)\n",
        "\n",
        " > - embedding (VECTOR, 고차원 벡터)\n",
        "\n",
        " >\n",
        "\n",
        " > **RDBMS - `documents` 테이블 (원본 문서 저장)**\n",
        "\n",
        " > - doc_id (INTEGER, PK)\n",
        "\n",
        " > - title (TEXT)\n",
        "\n",
        " > - content (TEXT)\n",
        "\n",
        " > - source (TEXT)\n",
        "\n",
        " > - created_at (TIMESTAMP)\n",
        "\n",
        " >\n",
        "\n",
        " > **RDBMS - `chat_logs` 테이블 (채팅 기록 저장)**\n",
        "\n",
        " > - log_id (INTEGER, PK)\n",
        "\n",
        " > - user_id (INTEGER, FK - users.user_id 참조)\n",
        "\n",
        " > - user_query (TEXT)\n",
        "\n",
        " > - llm_response (TEXT)\n",
        "\n",
        " > - retrieved_doc_ids (TEXT, 콤마로 구분된 doc_id 리스트 또는 JSON 형태)\n",
        "\n",
        " > - timestamp (TIMESTAMP)\n",
        "\n",
        " >\n",
        "\n",
        " > ... 이런 식으로 필요한 테이블과 컬럼, 관계를 구상해봅니다.\n",
        "\n",
        " > ```\n",
        "\n",
        "\n",
        "\n",
        " ### <h3>설계 예시 (참고용)</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5r1DCssFFcyC"
      },
      "source": [
        " ```text\n",
        "\n",
        "  [ 사용자 ] ----> [ RAG 챗봇 애플리케이션 ] <-----> [ LLM ]\n",
        "\n",
        "      |                    |         ^\n",
        "\n",
        "      |                    |         |  (Prompt + Retrieved Docs)\n",
        "\n",
        "      |                    V         |\n",
        "\n",
        "      |          [ Python Backend / API ]\n",
        "\n",
        "      |             /       |       \\\n",
        "\n",
        "      | (Query)    /        |        \\  (Logging)\n",
        "\n",
        "      |           /         |         \\\n",
        "\n",
        "      V          V          |          V\n",
        "\n",
        " [ 1. Vector DB ]  [ 2. RDBMS/NoSQL (Docs) ] [ 3. RDBMS/NoSQL (Logs) ]\n",
        "\n",
        "  - Purpose: 유사 문서 검색 - Purpose: 문서 내용/메타 조회 - Purpose: 대화 기록 저장\n",
        "\n",
        "  - Schema:            - Schema (`documents`):      - Schema (`chat_logs`):\n",
        "\n",
        "    - vector_id (PK, =doc_id) - doc_id (PK)             - log_id (PK)\n",
        "\n",
        "    - embedding (VECTOR)      - title (TEXT)            - user_id (FK -> users.id)\n",
        "\n",
        "                              - content (TEXT)          - user_query (TEXT)\n",
        "\n",
        "                              - category (TEXT)         - llm_response (TEXT)\n",
        "\n",
        "                              - source (TEXT)           - retrieved_doc_ids (TEXT/JSON)\n",
        "\n",
        "                              - ...                     - timestamp (TIMESTAMP)\n",
        "\n",
        "                              - ...                     - feedback (INTEGER, optional)\n",
        "\n",
        "                                                        - ...\n",
        "\n",
        "\n",
        "\n",
        " [ 4. RDBMS/NoSQL (Users - Optional) ]\n",
        "\n",
        "  - Purpose: 사용자 정보 관리\n",
        "\n",
        "  - Schema (`users`):\n",
        "\n",
        "    - user_id (PK)\n",
        "\n",
        "    - username (TEXT)\n",
        "\n",
        "    - registration_date (TIMESTAMP)\n",
        "\n",
        "    - ...\n",
        "\n",
        " ```\n",
        "\n",
        "\n",
        "\n",
        " **데이터 흐름 및 DB 역할:**\n",
        "\n",
        "\n",
        "\n",
        " 1.  **사용자 질문** -> Python 백엔드.\n",
        "\n",
        " 2.  질문 **임베딩** -> **Vector DB** `search()` -> `vector_id` (문서 ID) 목록 획득. (유사도 검색)\n",
        "\n",
        " 3.  획득한 `vector_id` 목록 -> **RDBMS/NoSQL (Docs)** 에서 `SELECT content FROM documents WHERE doc_id IN (...)` -> 문서 내용 획득. (내용 조회)\n",
        "\n",
        " 4.  질문 + 문서 내용 -> **LLM** 프롬프트 전달 -> 답변 생성.\n",
        "\n",
        " 5.  질문, 답변, 참조 문서 ID 등 -> **RDBMS/NoSQL (Logs)** 에 `INSERT INTO chat_logs ...`. (로그 저장)\n",
        "\n",
        " 6.  필요시 **RDBMS/NoSQL (Users)** 에서 사용자 정보 조회/활용."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zs8f9oc0FcyC"
      },
      "source": [
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ## 📚 개념 설명: 기본 보안 고려사항 - SQL Injection 🛡️🚫\n",
        "\n",
        "\n",
        "\n",
        " 데이터베이스를 사용하는 시스템을 만들 때는 **보안**을 반드시 고려해야 합니다.\n",
        "\n",
        " 다양한 보안 위협 중, 가장 기본적이고 흔한 웹 애플리케이션 공격 중 하나가 **SQL Injection** 입니다.\n",
        "\n",
        "\n",
        "\n",
        " * **SQL Injection (SQL 삽입 공격)**:\n",
        "\n",
        "     * **개념**: 공격자가 웹 애플리케이션의 **입력값(예: 로그인 ID/PW, 검색어)** 에 **악의적인 SQL 코드 조각**을 삽입하여, 개발자가 의도하지 않은 SQL 문이 데이터베이스에서 실행되도록 만드는 공격. 😱🔴\n",
        "\n",
        "     * **원인**: 사용자의 입력값을 **검증하거나 처리하지 않고 그대로 SQL 쿼리 문자열에 합쳐서** 사용할 때 발생. 🚫\n",
        "\n",
        "     * **위험성**:\n",
        "\n",
        "         * 데이터베이스 정보 **유출** (예: 사용자 개인정보, 관리자 계정). 🔓\n",
        "\n",
        "         * 데이터 **변조 또는 삭제**. 💥\n",
        "\n",
        "         * 서버 **명령 실행** 등 시스템 장악까지 가능. 💀\n",
        "\n",
        "     ![시각 자료 삽입: SQL Injection 공격 원리 도식화 (입력값 -> 쿼리 문자열 결합 -> 악성 쿼리 실행)](https://www.cloudflare.com/img/learning/security/threats/sql-injection-attack/sql-injection-example-form-field.png)\n",
        "\n",
        "     ![시각 자료 삽입: SQL Injection 공격 원리 도식화 (입력값 -> 쿼리 문자열 결합 -> 악성 쿼리 실행)](https://www.cloudflare.com/img/learning/security/threats/sql-injection-attack/sql-injection-infographic.png)\n",
        "\n",
        "\n",
        "\n",
        " * **취약한 코드 예시 (Python + sqlite3)**:\n",
        "\n",
        "   ```python\n",
        "\n",
        "   # 절대 이렇게 사용하면 안 됩니다! 🔴🔴🔴\n",
        "\n",
        "   user_input_id = \"admin' OR '1'='1\" # 악의적인 입력값 예시\n",
        "\n",
        "   query = \"SELECT * FROM users WHERE user_id = '\" + user_input_id + \"'\" # 입력값을 문자열에 직접 합침!\n",
        "\n",
        "   cursor.execute(query) # 의도: user_id='admin' 인 사용자 찾기\n",
        "\n",
        "                          # 실제 실행: SELECT * FROM users WHERE user_id = 'admin' OR '1'='1'\n",
        "\n",
        "                          # 결과: 모든 사용자 정보 유출 가능! 😱\n",
        "\n",
        "   ```\n",
        "\n",
        "\n",
        "\n",
        " * **예방 방법 (가장 중요!)**: ✨\n",
        "\n",
        "     * **준비된 구문 (Prepared Statements) / 매개변수화된 쿼리 (Parameterized Queries)** 사용! 🔵🔵🔵\n",
        "\n",
        "         * **개념**: SQL 쿼리의 **틀(템플릿)** 은 미리 만들어두고, 실제 **사용자 입력값은 별도의 매개변수로 안전하게 전달**하는 방식. DB 드라이버가 알아서 값을 이스케이프(Escape) 처리하는 등 위험을 방지해 줌.\n",
        "\n",
        "         * **Python `sqlite3` 예시**: `?` 플레이스홀더 사용.\n",
        "\n",
        "           ```python\n",
        "\n",
        "           user_input_id = \"admin' OR '1'='1\" # 악의적 입력값\n",
        "\n",
        "           # 쿼리 템플릿에는 ? 사용\n",
        "\n",
        "           query = \"SELECT * FROM users WHERE user_id = ?\"\n",
        "\n",
        "           # execute 메서드의 두 번째 인자로 값을 튜플 형태로 전달\n",
        "\n",
        "           cursor.execute(query, (user_input_id,)) # ✨ 안전한 방식!\n",
        "\n",
        "           # DB 드라이버가 user_input_id 값을 안전하게 처리하여 'admin' OR '1'='1' 이라는\n",
        "\n",
        "           # *문자열 자체* 를 user_id로 갖는 사용자를 찾으려고 시도함 (의도대로 동작).\n",
        "\n",
        "           ```\n",
        "\n",
        "     * **입력값 검증 (Input Validation)**: 사용자 입력값이 예상된 형식/타입인지 확인. (근본 해결책은 아님)\n",
        "\n",
        "     * **최소 권한 원칙**: DB 계정에 꼭 필요한 권한만 부여.\n",
        "\n",
        "     * **웹 방화벽 (WAF)** 사용.\n",
        "\n",
        "\n",
        "\n",
        " > **핵심**: 사용자 입력값을 SQL 쿼리에 **절대 직접 문자열로 합치지 말고**, 항상 **매개변수화된 쿼리(`?` 플레이스홀더 등)** 를 사용하세요! ✨🔵"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_xFkyIZFcyC"
      },
      "source": [
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ## ❓ 퀴즈 2: SQL Injection 예방\n",
        "\n",
        "\n",
        "\n",
        " ### 🧐 객관식/단답형 문제 2 (난이도: ⭐️⭐️⭐️)\n",
        "\n",
        "\n",
        "\n",
        " SQL Injection 공격을 막기 위한 **가장 중요하고 효과적인** 방법은 무엇인가요? (가장 적절한 것을 하나 고르거나, 핵심 용어를 답하세요.)\n",
        "\n",
        "\n",
        "\n",
        " 1.  모든 사용자 입력값을 Base64로 인코딩한다.\n",
        "\n",
        " 2.  데이터베이스 연결 비밀번호를 매우 복잡하게 설정한다.\n",
        "\n",
        " 3.  웹 서버의 방화벽 설정을 강화한다.\n",
        "\n",
        " 4.  매개변수화된 쿼리 (Parameterized Query) 또는 준비된 구문 (Prepared Statement)을 사용한다.\n",
        "\n",
        " 5.  오류 메시지를 사용자에게 자세히 보여주지 않는다.\n",
        "\n",
        "\n",
        "\n",
        " (또는, 핵심 예방 기법의 이름을 적으세요: `[ 빈칸 ]`)\n",
        "\n",
        "\n",
        "\n",
        " ### <h3>정답 및 해설</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrFg3D8xFcyC"
      },
      "source": [
        " **정답: 4번** 또는 **매개변수화된 쿼리 (Parameterized Query)** / **준비된 구문 (Prepared Statement)**\n",
        "\n",
        "\n",
        "\n",
        " **해설:**\n",
        "\n",
        " SQL Injection의 근본 원인은 사용자 입력값이 SQL 코드의 일부로 해석되는 것입니다. 매개변수화된 쿼리는 사용자 입력을 SQL 코드와 명확히 분리하여 전달하므로, 입력값이 코드로 실행되는 것을 원천적으로 차단하는 가장 효과적인 방법입니다. 🔵🔵🔵\n",
        "\n",
        " 다른 보기들도 보안의 일부 요소일 수 있지만(2, 3, 5), SQL Injection 자체를 막는 가장 직접적이고 중요한 방법은 아닙니다. 1번은 SQL Injection 예방책이 아닙니다.\n",
        "\n",
        "\n",
        "\n",
        " ### 🚀 더 나아가기 (생각해보기)\n",
        "\n",
        "\n",
        "\n",
        " * Python의 다른 DB 라이브러리(예: `psycopg2` for PostgreSQL, `mysql-connector-python` for MySQL)에서는 매개변수화된 쿼리를 어떻게 사용하는지 간단히 검색해보세요. (플레이스홀더 문법이 `?` 대신 `%s` 등 다를 수 있습니다.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJet17A7FcyC"
      },
      "source": [
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ## 🔑 7교시 핵심 정리\n",
        "\n",
        "\n",
        "\n",
        " * **ML 데이터 파이프라인**: 데이터 **수집 → 전처리(ETL) → 저장 → 학습 → 결과 저장**의 자동화된 흐름. DB는 각 단계 데이터 관리 핵심. 🌊⚙️💾\n",
        "\n",
        " * **하이브리드 아키텍처**: **여러 종류 DB 조합** 사용 (예: RDB + Vector DB). 각 DB 강점 활용 → AI 서비스 최적화. ↔️🧱 (RAG 예시: Vector DB(검색) + RDB(내용 조회))\n",
        "\n",
        " * **AI 서비스 데이터 설계**: 서비스 **데이터 흐름** 분석 → 각 단계 필요 데이터 정의 → **적합한 DB** 선택 및 스키마/정보 **설계(스케치)**. 🎨✍️ (연결 ID 중요!)\n",
        "\n",
        " * **SQL Injection**: 사용자 입력 통해 **악성 SQL 실행**시키는 공격. 데이터 유출/변조 등 위험. 😱🔴\n",
        "\n",
        " * **SQL Injection 예방**: **매개변수화된 쿼리 (`?` 플레이스홀더 등) 사용**이 가장 중요! ✨🔵 (입력값 직접 쿼리에 합치지 않기!)\n",
        "\n",
        " * **보안**: DB 사용 시 **기본적인 보안 원칙**(SQL Injection 방지, 최소 권한 등) 준수 필수. 🛡️"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gq-mn--XFcyC"
      },
      "source": [
        " ---\n",
        "\n",
        "\n",
        "\n",
        " ## 🏁 과정 전체 요약 및 마무리\n",
        "\n",
        "\n",
        "\n",
        " 지난 7교시 동안 우리는 AI 개발 및 서비스 운영에 필수적인 **데이터베이스**의 세계를 탐험했습니다.\n",
        "\n",
        "\n",
        "\n",
        " * **1교시**: DB의 **필요성**과 **기본 SQL**(SELECT, INSERT, UPDATE, DELETE, WHERE) 사용법.\n",
        "\n",
        " * **2교시**: **관계형 DB 설계**(테이블, 키, 관계)와 **정규화** 기초.\n",
        "\n",
        " * **3교시**: 고급 SQL - **`JOIN`**(테이블 연결), **`GROUP BY` / `HAVING`**(그룹 분석), **인덱싱** 개념.\n",
        "\n",
        " * **4교시**: **NoSQL DB**(MongoDB, Redis) 개념, **유연한 스키마**와 **확장성**의 중요성.\n",
        "\n",
        " * **5교시**: **Vector DB** 개념, **의미 기반 검색**, **FAISS** 실습 (인덱스 생성, 추가, 검색).\n",
        "\n",
        " * **6교시**: 데이터 관리 확장 - **DW**, **ETL**, **빅데이터** 개념, DB **설계 원칙** 복습.\n",
        "\n",
        " * **7교시**: **ML 데이터 파이프라인**, **하이브리드 아키텍처** 설계 (RAG 예시), **SQL Injection** 보안.\n",
        "\n",
        "\n",
        "\n",
        " 이 과정을 통해 여러분은 다양한 데이터베이스 기술의 **핵심 개념**을 이해하고, **기본적인 SQL 작성 능력**과 **Python을 이용한 DB 연동**(비록 4교시가 축소되었지만 개념은 전달됨) 및 **AI 서비스 관점에서의 DB 설계** 기초를 다졌습니다.\n",
        "\n",
        "\n",
        "\n",
        " 데이터베이스 기술은 매우 방대하고 깊이 있는 분야입니다. 오늘 배운 내용을 발판 삼아 앞으로 더 심도 있는 학습을 이어가시길 바랍니다.\n",
        "\n",
        "\n",
        "\n",
        " ### 🚀 향후 학습 방향 제안\n",
        "\n",
        "\n",
        "\n",
        " * **SQL 심화**: 복잡한 JOIN, 윈도우 함수(Window Functions), 서브쿼리 고급 활용, 성능 튜닝 등.\n",
        "\n",
        " * **DB 모델링 심화**: 정규화/반정규화 심층 이해, 대규모 시스템 위한 데이터 모델링 기법.\n",
        "\n",
        " * **특정 DB Deep Dive**: PostgreSQL, MySQL, MongoDB, Redis, Elasticsearch, Vector DB(Milvus, Pinecone 등) 중 관심 분야 선택하여 깊이 학습.\n",
        "\n",
        " * **클라우드 데이터베이스**: AWS RDS/DynamoDB/OpenSearch, GCP Cloud SQL/Bigtable/Vertex AI Vector Search 등 클라우드 환경 DB 서비스 학습 및 활용.\n",
        "\n",
        " * **데이터 엔지니어링**: 데이터 파이프라인 구축(Airflow 등), 데이터 처리(Spark 등), 데이터 웨어하우징/레이크 구축 등 더 넓은 데이터 인프라 기술 학습.\n",
        "\n",
        " * **데이터베이스 보안**: 접근 통제, 암호화, 감사 로깅 등 심층적인 보안 기술 학습.\n",
        "\n",
        "\n",
        "\n",
        " **그동안 수고 많으셨습니다! 여러분의 AI 개발 여정에 데이터베이스 역량이 든든한 기반이 되기를 응원합니다.** 🎉"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJIlo9AFFcyC"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "# 모든 세션 완료. DB 연결 객체가 있다면 종료.\n",
        "try:\n",
        "    if 'conn' in locals() and conn:\n",
        "        conn.close()\n",
        "        print(\"\\n모든 실습 완료. SQLite 데이터베이스 연결이 해제되었습니다.\")\n",
        "except Exception as e:\n",
        "     pass # 오류 발생해도 조용히 넘어감\n",
        "\n",
        "print(\"\\n데이터베이스 기초 과정 완료.\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": 3
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}